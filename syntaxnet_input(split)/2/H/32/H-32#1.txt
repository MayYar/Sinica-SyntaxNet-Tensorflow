Input: Current approaches to identifying definitional sentences in the context of Question Answering mainly involve the use of linguistic or syntactic patterns to identify informative nuggets .
Parse:
involve VB ROOT
 +-- approaches NNS nsubj
 |   +-- Current JJ amod
 |   +-- to IN prep
 |       +-- identifying VBG pcomp
 |           +-- sentences NNS dobj
 |           |   +-- definitional JJ amod
 |           +-- in IN prep
 |               +-- context NN pobj
 |                   +-- the DT det
 |                   +-- of IN prep
 |                       +-- Answering NNP pobj
 |                           +-- Question NNP nn
 +-- mainly RB advmod
 +-- use NN dobj
 |   +-- the DT det
 |   +-- of IN prep
 |   |   +-- patterns NNS pobj
 |   |       +-- linguistic JJ amod
 |   |           +-- or CC cc
 |   |           +-- syntactic JJ conj
 |   +-- identify VB infmod
 |       +-- to TO aux
 |       +-- nuggets NNS dobj
 |           +-- informative JJ amod
 +-- . . punct
Input: This is insufficient as they do not address the novelty factor that a definitional nugget must also possess .
Parse:
insufficient JJ ROOT
 +-- This DT nsubj
 +-- is VBZ cop
 +-- address VB advcl
 |   +-- as IN mark
 |   +-- they PRP nsubj
 |   +-- do VBP aux
 |   +-- not RB neg
 |   +-- factor NN dobj
 |       +-- the DT det
 |       +-- novelty NN nn
 |       +-- possess VB rcmod
 |           +-- that IN dobj
 |           +-- nugget NN nsubj
 |           |   +-- a DT det
 |           |   +-- definitional JJ amod
 |           +-- must MD aux
 |           +-- also RB advmod
 +-- . . punct
Input: This paper proposes to address the deficiency by building a Human Interest Model from external knowledge .
Parse:
proposes VBZ ROOT
 +-- paper NN nsubj
 |   +-- This DT det
 +-- address VB xcomp
 |   +-- to TO aux
 |   +-- deficiency NN dobj
 |   |   +-- the DT det
 |   +-- by IN prep
 |       +-- building VBG pcomp
 |           +-- Model NNP dobj
 |           |   +-- a DT det
 |           |   +-- Interest NNP nn
 |           |       +-- Human NNP nn
 |           +-- from IN prep
 |               +-- knowledge NN pobj
 |                   +-- external JJ amod
 +-- . . punct
Input: It is hoped that such a model will allow the computation of human interest in the sentence with respect to the topic .
Parse:
hoped VBN ROOT
 +-- It PRP nsubjpass
 +-- is VBZ auxpass
 +-- allow VB ccomp
 |   +-- that IN mark
 |   +-- model NN nsubj
 |   |   +-- such PDT predet
 |   |   +-- a DT det
 |   +-- will MD aux
 |   +-- computation NN dobj
 |   |   +-- the DT det
 |   |   +-- of IN prep
 |   |       +-- interest NN pobj
 |   |           +-- human JJ amod
 |   +-- in IN prep
 |   |   +-- sentence NN pobj
 |   |       +-- the DT det
 |   +-- with IN prep
 |       +-- respect NN pobj
 |           +-- to IN prep
 |               +-- topic NN pobj
 |                   +-- the DT det
 +-- . . punct
Input: We compare and contrast our model with current definitional question answering models to show that interestingness plays an important factor in definitional question answering .
Parse:
compare VBP ROOT
 +-- We PRP nsubj
 +-- and CC cc
 +-- contrast VB conj
 +-- model NN dobj
 |   +-- our PRP$ poss
 +-- with IN prep
 |   +-- answering VBG pcomp
 |       +-- question NN nsubj
 |       |   +-- current JJ amod
 |       |   +-- definitional JJ amod
 |       +-- models NNS dobj
 |       +-- show VB xcomp
 |           +-- to TO aux
 |           +-- plays VBZ ccomp
 |               +-- that IN mark
 |               +-- interestingness NN nsubj
 |               +-- factor NN dobj
 |                   +-- an DT det
 |                   +-- important JJ amod
 |                   +-- in IN prep
 |                       +-- question NN pobj
 |                           +-- definitional JJ amod
 |                           +-- answering VBG partmod
 +-- . . punct
Input: H.3.3 -LRB- Information Search and Retrieval -RRB-
Parse:
Search NNP ROOT
 +-- H.3.3 CD dep
 +-- -LRB- -LRB- punct
 +-- Information NN nn
 +-- and CC cc
 +-- Retrieval NN conj
 +-- -RRB- -RRB- punct
