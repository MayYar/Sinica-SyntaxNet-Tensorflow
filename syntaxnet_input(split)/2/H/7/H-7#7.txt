Input: Content based user profile learning is an important problem and is the key to providing personal recommendations to a user , especially for recommending new items with a small number of ratings .
Parse:
problem NN ROOT
 +-- learning NN nsubj
 |   +-- based VBN amod
 |   |   +-- Content NN dep
 |   +-- profile NN nn
 |       +-- user NN nn
 +-- is VBZ cop
 +-- an DT det
 +-- important JJ amod
 +-- and CC cc
 +-- key NN conj
 |   +-- is VBZ cop
 |   +-- the DT det
 |   +-- to IN prep
 |       +-- providing VBG pcomp
 |           +-- recommendations NNS dobj
 |           |   +-- personal JJ amod
 |           +-- to IN prep
 |           |   +-- user NN pobj
 |           |       +-- a DT det
 |           +-- , , punct
 |           +-- for IN prep
 |               +-- especially RB advmod
 |               +-- recommending VBG pcomp
 |                   +-- items NNS dobj
 |                       +-- new JJ amod
 |                       +-- with IN prep
 |                           +-- number NN pobj
 |                               +-- a DT det
 |                               +-- small JJ amod
 |                               +-- of IN prep
 |                                   +-- ratings NNS pobj
 +-- . . punct
Input: The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors .
Parse:
becoming VBG ROOT
 +-- approach NN nsubj
 |   +-- The DT det
 |   +-- Bayesian JJ amod
 |   +-- hierarchical JJ amod
 |   +-- modeling NN nn
 +-- is VBZ aux
 +-- approach NN xcomp
 |   +-- an DT det
 |   +-- important JJ amod
 |   +-- profile NN nn
 |   |   +-- user NN nn
 |   +-- learning VBG nn
 |   +-- to IN prep
 |       +-- due IN mwe
 |       +-- ability NN pobj
 |           +-- its PRP$ poss
 |           +-- justified JJ amod
 |           |   +-- theoretically RB advmod
 |           +-- help VB infmod
 |               +-- to TO aux
 |               +-- user NN dobj
 |               |   +-- one CD num
 |               +-- through IN prep
 |               |   +-- transfer NN pobj
 |               |       +-- information NN nn
 |               |       +-- from IN prep
 |               |           +-- users NNS pobj
 |               |               +-- the DT det
 |               |               +-- other JJ amod
 |               +-- by IN prep
 |                   +-- way NN pobj
 |                       +-- of IN prep
 |                           +-- hyperpriors NNS pobj
 +-- . . punct
Input: This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM .
Parse:
examined VBD ROOT
 +-- paper NN nsubj
 |   +-- This DT det
 +-- weakness NN dobj
 |   +-- the DT det
 |   +-- of IN prep
 |       +-- approach NN pobj
 |           +-- the DT det
 |           +-- popular JJ amod
 |           +-- based VBN amod
 |           |   +-- EM NNP dep
 |           +-- learning NN amod
 |           +-- for IN prep
 |               +-- models NNS pobj
 |                   +-- Bayesian JJ amod
 |                   +-- hierarchical JJ amod
 |                   +-- linear JJ amod
 +-- and CC cc
 +-- proposed VBD conj
 |   +-- technique NN dobj
 |       +-- a DT det
 |       +-- better JJR amod
 |       +-- learning NN nn
 |       +-- called VBN partmod
 |           +-- EM NNP dep
 |               +-- Modified NNP nn
 +-- . . punct
Input: We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm .
Parse:
showed VBD ROOT
 +-- We PRP nsubj
 +-- efficient JJ ccomp
 |   +-- that IN mark
 |   +-- technique NN nsubj
 |   |   +-- the DT det
 |   |   +-- new JJ amod
 |   +-- is VBZ cop
 |   +-- theoretically RB advmod
 |   +-- computationally RB advmod
 |   |   +-- more RBR advmod
 |   +-- than IN prep
 |       +-- algorithm NNP pobj
 |           +-- the DT det
 |           +-- standard NN amod
 |           +-- EM NNP nn
 +-- . . punct
Input: Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse , by which we mean the ratio of related user feature pairs to unrelated pairs is small .
Parse:
demonstrated VBD ROOT
 +-- Evaluation NN nsubj
 |   +-- on IN prep
 |       +-- sets NNS pobj
 |           +-- the DT det
 |           +-- MovieLens NNPS nn
 |           |   +-- and CC cc
 |           |   +-- Netflix NNP conj
 |           +-- data NNS nn
 +-- effectiveness NN dobj
 |   +-- the DT det
 |   +-- of IN prep
 |       +-- technique NN pobj
 |           +-- the DT det
 |           +-- new JJ amod
 +-- sparse JJ advcl
 |   +-- when WRB advmod
 |   +-- data NN nsubj
 |   |   +-- the DT det
 |   +-- is VBZ cop
 +-- , , punct
 +-- mean VBP ccomp
 |   +-- by IN prep
 |   |   +-- which WDT pobj
 |   +-- we PRP nsubj
 |   +-- small JJ ccomp
 |       +-- ratio NN nsubj
 |       |   +-- the DT det
 |       |   +-- of IN prep
 |       |   |   +-- pairs NNS pobj
 |       |   |       +-- related JJ amod
 |       |   |       +-- feature NN nn
 |       |   |           +-- user NN nn
 |       |   +-- to IN prep
 |       |       +-- pairs NNS pobj
 |       |           +-- unrelated JJ amod
 |       +-- is VBZ cop
 +-- . . punct
Input: Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold .
Parse:
showed VBD ROOT
 +-- Evaluation NN nsubj
 |   +-- on IN prep
 |       +-- set NN pobj
 |           +-- the DT det
 |           +-- Reuters NNP nn
 |           +-- data NNS nn
 +-- performed VBD ccomp
 |   +-- that IN mark
 |   +-- technique NN nsubj
 |   |   +-- the DT det
 |   |   +-- new JJ amod
 |   +-- similar JJ advmod
 |   |   +-- to IN prep
 |   |       +-- algorithm NNP pobj
 |   |           +-- the DT det
 |   |           +-- standard NN amod
 |   |           +-- EM NNP nn
 |   +-- hold VB advcl
 |       +-- when WRB advmod
 |       +-- condition NN nsubj
 |       |   +-- the DT det
 |       |   +-- sparseness NN nn
 |       +-- does VBZ aux
 |       +-- not RB neg
 +-- . . punct
Input: In general , it is better to use the new algorithm since it is as simple as standard EM , the performance is either better or similar to EM , and the computation complexity is lower at each iteration .
Parse:
better JJR ROOT
 +-- In IN prep
 |   +-- general JJ pobj
 +-- , , punct
 +-- it PRP nsubj
 +-- is VBZ cop
 +-- use VB xcomp
 |   +-- to TO aux
 |   +-- algorithm NN dobj
 |       +-- the DT det
 |       +-- new JJ amod
 +-- simple JJ advcl
 |   +-- since IN mark
 |   +-- it PRP nsubj
 |   +-- is VBZ cop
 |   +-- as RB advmod
 |   +-- as IN prep
 |       +-- EM NNP pobj
 |           +-- standard JJ amod
 +-- better JJR ccomp
 |   +-- performance NN nsubj
 |   |   +-- the DT det
 |   +-- is VBZ cop
 |   +-- either CC preconj
 |   +-- or CC cc
 |   +-- similar JJ conj
 |   |   +-- to IN prep
 |   |       +-- EM NNP pobj
 |   +-- , , punct
 |   +-- and CC cc
 |   +-- lower JJR conj
 |       +-- complexity NN nsubj
 |       |   +-- the DT det
 |       |   +-- computation NN nn
 |       +-- is VBZ cop
 |       +-- at IN prep
 |           +-- iteration NN pobj
 |               +-- each DT det
 +-- . . punct
Input: It is worth mentioning that even if the original problem space is not sparse , sparseness can be created artificially when a recommendation system uses user specific feature selection techniques to reduce the noise and user model complexity .
Parse:
worth JJ ROOT
 +-- It PRP nsubj
 +-- is VBZ cop
 +-- mentioning VBG dep
 |   +-- created VBN ccomp
 |       +-- that IN mark
 |       +-- sparse JJ advcl
 |       |   +-- even RB advmod
 |       |   +-- if IN mark
 |       |   +-- space NN nsubj
 |       |   |   +-- the DT det
 |       |   |   +-- original JJ amod
 |       |   |   +-- problem NN nn
 |       |   +-- is VBZ cop
 |       |   +-- not RB neg
 |       +-- , , punct
 |       +-- sparseness NN nsubjpass
 |       +-- can MD aux
 |       +-- be VB auxpass
 |       +-- artificially RB advmod
 |       +-- uses VBZ advcl
 |           +-- when WRB advmod
 |           +-- system NN nsubj
 |           |   +-- a DT det
 |           |   +-- recommendation NN nn
 |           +-- techniques NNS dobj
 |           |   +-- feature NN nn
 |           |   |   +-- user NN nn
 |           |   |   +-- specific JJ amod
 |           |   +-- selection NN nn
 |           +-- reduce VB xcomp
 |               +-- to TO aux
 |               +-- complexity NN dobj
 |                   +-- the DT det
 |                   +-- noise NN nn
 |                       +-- and CC cc
 |                       +-- model NN conj
 |                           +-- user NN nn
 +-- . . punct
Input: The proposed technique can also be adapted to improve the learning in such a scenario .
Parse:
adapted VBN ROOT
 +-- technique NN nsubjpass
 |   +-- The DT det
 |   +-- proposed VBN amod
 +-- can MD aux
 +-- also RB advmod
 +-- be VB auxpass
 +-- improve VB xcomp
 |   +-- to TO aux
 |   +-- learning NN dobj
 |       +-- the DT det
 |       +-- in IN prep
 |           +-- scenario NN pobj
 |               +-- such PDT predet
 |               +-- a DT det
 +-- . . punct
Input: We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU .
Parse:
demonstrated VBD ROOT
 +-- We PRP nsubj
 +-- also RB advmod
 +-- learn VB ccomp
 |   +-- that IN mark
 |   +-- technique NN nsubj
 |   |   +-- the DT det
 |   |   +-- proposed VBN amod
 |   +-- can MD aux
 |   +-- profiles NNS dobj
 |   |   +-- million CD num
 |   |   |   +-- half PDT quantmod
 |   |   |   +-- a DT quantmod
 |   |   +-- user NN nn
 |   +-- from IN prep
 |       +-- ratings NNS pobj
 |           +-- million CD num
 |           |   +-- 100 CD number
 |           +-- in IN prep
 |               +-- hours NNS pobj
 |                   +-- a DT det
 |                   +-- few JJ amod
 |                   +-- with IN prep
 |                       +-- CPU NN pobj
 |                           +-- a DT det
 |                           +-- single JJ amod
 +-- . . punct
Input: The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system , even though the literature have demonstrated the effectiveness of the models in many applications .
Parse:
important JJ ROOT
 +-- research NN nsubj
 |   +-- The DT det
 +-- is VBZ cop
 +-- concern NN advcl
 |   +-- because IN mark
 |   +-- scalability NN nsubj
 |   +-- is VBZ cop
 |   +-- a DT det
 |   +-- major JJ amod
 |   +-- for IN prep
 |   |   +-- researchers NNS pobj
 |   +-- using VBG advcl
 |       +-- when WRB advmod
 |       +-- approach NN dobj
 |       |   +-- the DT det
 |       |   +-- Bayesian JJ amod
 |       |   +-- hierarchical JJ amod
 |       |   +-- linear JJ amod
 |       |   +-- modeling NN nn
 |       +-- build VB xcomp
 |       |   +-- to TO aux
 |       |   +-- system NN dobj
 |       |       +-- a DT det
 |       |       +-- practical JJ amod
 |       |       +-- scale NN nn
 |       |           +-- large JJ amod
 |       +-- , , punct
 |       +-- demonstrated VBN advcl
 |           +-- even RB advmod
 |           +-- though IN mark
 |           +-- literature NN nsubj
 |           |   +-- the DT det
 |           +-- have VBP aux
 |           +-- effectiveness NN dobj
 |               +-- the DT det
 |               +-- of IN prep
 |               |   +-- models NNS pobj
 |               |       +-- the DT det
 |               +-- in IN prep
 |                   +-- applications NNS pobj
 |                       +-- many JJ amod
 +-- . . punct
Input: Our work is one major step on the road to make Bayesian hierarchical linear models more practical .
Parse:
step NN ROOT
 +-- work NN nsubj
 |   +-- Our PRP$ poss
 +-- is VBZ cop
 +-- one CD num
 +-- major JJ amod
 +-- on IN prep
 |   +-- road NN pobj
 |       +-- the DT det
 +-- make VB infmod
 |   +-- to TO aux
 |   +-- practical JJ xcomp
 |       +-- models NNS nsubj
 |       |   +-- Bayesian JJ amod
 |       |   +-- hierarchical JJ amod
 |       |   +-- linear JJ amod
 |       +-- more RBR advmod
 +-- . . punct
Input: The proposed new technique can be easily adapted to run on a cluster of machines , and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users .
Parse:
adapted VBN ROOT
 +-- technique NN nsubjpass
 |   +-- The DT det
 |   +-- proposed VBN amod
 |   +-- new JJ amod
 +-- can MD aux
 +-- be VB auxpass
 +-- easily RB advmod
 +-- run VB xcomp
 |   +-- to TO aux
 |   +-- on IN prep
 |   |   +-- cluster NN pobj
 |   |       +-- a DT det
 |   |       +-- of IN prep
 |   |           +-- machines NNS pobj
 |   +-- , , punct
 |   +-- and CC cc
 |   +-- thus RB advmod
 |   +-- further RB advmod
 |   +-- speed NN dep
 |       +-- up RP prt
 |       +-- process NN dobj
 |           +-- the DT det
 |           +-- learning NN nn
 |           +-- handle VB infmod
 |               +-- to TO aux
 |               +-- system NN dobj
 |               |   +-- a DT det
 |               |   +-- larger JJR amod
 |               |   +-- scale NN nn
 |               +-- with IN prep
 |                   +-- hundreds NNS pobj
 |                       +-- of IN prep
 |                           +-- millions NNS pobj
 |                               +-- of IN prep
 |                                   +-- users NNS pobj
 +-- . . punct
Input: The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems .
Parse:
has VBZ ROOT
 +-- research NN nsubj
 |   +-- The DT det
 +-- potential NN dobj
 |   +-- much JJ amod
 |   +-- benefit VB infmod
 |       +-- to TO aux
 |       +-- people NNS dobj
 |           +-- using VBG partmod
 |               +-- algorithm NNP dobj
 |               |   +-- EM NNP nn
 |               +-- on IN prep
 |                   +-- problems NNS pobj
 |                       +-- many JJ amod
 |                       +-- other JJ amod
 |                       +-- IR NNP nn
 |                       +-- well RB cc
 |                       |   +-- as RB advmod
 |                       |   +-- as IN mwe
 |                       +-- problems NNS conj
 |                           +-- learning NN nn
 |                               +-- machine NN nn
 +-- . . punct
Input: EM algorithm is a commonly used machine learning technique .
Parse:
technique NN ROOT
 +-- algorithm NNP nsubj
 |   +-- EM NNP nn
 +-- is VBZ cop
 +-- a DT det
 +-- used VBN amod
 |   +-- commonly RB advmod
 +-- learning VBG nn
 |   +-- machine NN nn
 +-- . . punct
Input: It is used to find model parameters in many IR problems where the training data is very sparse .
Parse:
used VBN ROOT
 +-- It PRP nsubjpass
 +-- is VBZ auxpass
 +-- find VB xcomp
 |   +-- to TO aux
 |   +-- parameters NNS dobj
 |       +-- model NN nn
 |       +-- in IN prep
 |           +-- problems NNS pobj
 |               +-- many JJ amod
 |               +-- IR NNP nn
 |               +-- sparse JJ rcmod
 |                   +-- where WRB advmod
 |                   +-- data NN nsubj
 |                   |   +-- the DT det
 |                   |   +-- training NN nn
 |                   +-- is VBZ cop
 |                   +-- very RB advmod
 +-- . . punct
Input: Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering , the new idea of using analytical solution instead of numerical solution for unrelated user feature pairs at the M step could be adapted to many other problems. .
Parse:
adapted VBN ROOT
 +-- focusing VBG advcl
 |   +-- Although IN mark
 |   +-- we PRP nsubj
 |   +-- are VBP aux
 |   +-- on IN prep
 |   |   +-- models NNS pobj
 |   |       +-- the DT det
 |   |       +-- Bayesian JJ amod
 |   |       +-- hierarchical JJ amod
 |   |       +-- linear JJ amod
 |   +-- for IN prep
 |       +-- recommendation NN pobj
 |           +-- and CC cc
 |           +-- filtering NN conj
 +-- , , punct
 +-- idea NN nsubjpass
 |   +-- the DT det
 |   +-- new JJ amod
 |   +-- of IN prep
 |       +-- using VBG pcomp
 |           +-- solution NN dobj
 |           |   +-- analytical JJ amod
 |           |   +-- of IN prep
 |           |       +-- instead RB advmod
 |           |       +-- solution NN pobj
 |           |           +-- numerical JJ amod
 |           |           +-- for IN prep
 |           |               +-- pairs NNS pobj
 |           |                   +-- unrelated JJ amod
 |           |                   +-- feature NN nn
 |           |                       +-- user NN nn
 |           +-- at IN prep
 |               +-- step NN pobj
 |                   +-- the DT det
 |                   +-- M NNP nn
 +-- could MD aux
 +-- be VB auxpass
 +-- to IN prep
 |   +-- problems. NNS pobj
 |       +-- many JJ amod
 |       +-- other JJ amod
 +-- . . punct
