Input: We present a new family of query generation language models for retrieval based on Poisson distribution .
Parse:
present VBP ROOT
 +-- We PRP nsubj
 +-- family NN dobj
 |   +-- a DT det
 |   +-- new JJ amod
 |   +-- of IN prep
 |       +-- models NNS pobj
 |           +-- language NN nn
 |               +-- generation NN nn
 |                   +-- query NN nn
 +-- for IN prep
 |   +-- retrieval NN pobj
 |       +-- based VBN partmod
 |           +-- on IN prep
 |               +-- distribution NN pobj
 |                   +-- Poisson NNP nn
 +-- . . punct
Input: We derive several smoothing methods for this family of models , including single stage smoothing and two stage smoothing .
Parse:
derive VBP ROOT
 +-- We PRP nsubj
 +-- methods NNS dobj
 |   +-- several JJ amod
 |   +-- smoothing VBG nn
 |   +-- for IN prep
 |   |   +-- family NN pobj
 |   |       +-- this DT det
 |   |       +-- of IN prep
 |   |           +-- models NNS pobj
 |   +-- , , punct
 |   +-- including VBG prep
 |       +-- smoothing VBG pobj
 |           +-- single JJ amod
 |           +-- stage NN nn
 |           +-- and CC cc
 |           +-- smoothing VBG conj
 |               +-- two CD num
 |               +-- stage NN nn
 +-- . . punct
Input: We compare the new models with the popular multinomial retrieval models both analytically and experimentally .
Parse:
compare VBP ROOT
 +-- We PRP nsubj
 +-- models NNS dobj
 |   +-- the DT det
 |   +-- new JJ amod
 +-- with IN prep
 |   +-- models NNS pobj
 |       +-- the DT det
 |       +-- popular JJ amod
 |       +-- multinomial JJ amod
 |       +-- retrieval NN nn
 |       +-- both CC dep
 |           +-- analytically RB dep
 |           +-- and CC cc
 |           +-- experimentally RB conj
 +-- . . punct
Input: Our analysis shows that while our new models and multinomial models are equivalent under some assumptions , they are generally different with some important differences .
Parse:
shows VBZ ROOT
 +-- analysis NN nsubj
 |   +-- Our PRP$ poss
 +-- different JJ ccomp
 |   +-- that IN mark
 |   +-- equivalent JJ advcl
 |   |   +-- while IN mark
 |   |   +-- models NNS nsubj
 |   |   |   +-- our PRP$ poss
 |   |   |   +-- new JJ amod
 |   |   |   +-- and CC cc
 |   |   |   +-- models NNS conj
 |   |   |       +-- multinomial JJ amod
 |   |   +-- are VBP cop
 |   |   +-- under IN prep
 |   |       +-- assumptions NNS pobj
 |   |           +-- some DT det
 |   +-- , , punct
 |   +-- they PRP nsubj
 |   +-- are VBP cop
 |   +-- generally RB advmod
 |   +-- with IN prep
 |       +-- differences NNS pobj
 |           +-- some DT det
 |           +-- important JJ amod
 +-- . . punct
Input: In particular , we show that Poisson has an advantage over multinomial in naturally accommodating per term smoothing .
Parse:
show VBP ROOT
 +-- In IN prep
 |   +-- particular JJ pobj
 +-- , , punct
 +-- we PRP nsubj
 +-- has VBZ ccomp
 |   +-- that IN mark
 |   +-- Poisson NNP nsubj
 |   +-- advantage NN dobj
 |   |   +-- an DT det
 |   |   +-- over IN prep
 |   |       +-- multinomial NN pobj
 |   +-- in IN prep
 |       +-- accommodating VBG pcomp
 |           +-- naturally RB advmod
 |           +-- per IN prep
 |               +-- smoothing VBG pobj
 |                   +-- term NN nn
 +-- . . punct
Input: We exploit this property to develop a new per term smoothing algorithm for Poisson language models , which is shown to outperform term independent smoothing for both Poisson and multinomial models .
Parse:
exploit VBP ROOT
 +-- We PRP nsubj
 +-- property NN dobj
 |   +-- this DT det
 |   +-- develop VB infmod
 |       +-- to TO aux
 |       +-- algorithm NNP dobj
 |           +-- a DT det
 |           +-- new JJ amod
 |           |   +-- per IN prep
 |           |       +-- term NN pobj
 |           +-- smoothing VBG nn
 |           +-- for IN prep
 |               +-- models NNS pobj
 |                   +-- Poisson NNP nn
 |                   +-- language NN nn
 |                   +-- , , punct
 |                   +-- shown VBN rcmod
 |                       +-- which WDT nsubjpass
 |                       +-- is VBZ auxpass
 |                       +-- outperform VB xcomp
 |                           +-- to TO aux
 |                           +-- smoothing VBG dobj
 |                               +-- term NN nn
 |                               +-- independent JJ amod
 |                               +-- for IN prep
 |                                   +-- Poisson NNP pobj
 |                                       +-- both CC preconj
 |                                       +-- and CC cc
 |                                       +-- models NNS conj
 |                                           +-- multinomial JJ amod
 +-- . . punct
Input: Furthermore , we show that a mixture background model for Poisson can be used to improve the performance and robustness over the standard Poisson background model .
Parse:
show VBP ROOT
 +-- Furthermore RB advmod
 +-- , , punct
 +-- we PRP nsubj
 +-- used VBN ccomp
 |   +-- that IN mark
 |   +-- model NN nsubjpass
 |   |   +-- a DT det
 |   |   +-- mixture NN amod
 |   |   +-- background NN nn
 |   |   +-- for IN prep
 |   |       +-- Poisson NNP pobj
 |   +-- can MD aux
 |   +-- be VB auxpass
 |   +-- improve VB xcomp
 |       +-- to TO aux
 |       +-- performance NN dobj
 |           +-- the DT det
 |           +-- and CC cc
 |           +-- robustness NN conj
 |           +-- over IN prep
 |               +-- model NN pobj
 |                   +-- the DT det
 |                   +-- standard JJ amod
 |                   +-- Poisson NNP nn
 |                   +-- background NN nn
 +-- . . punct
Input: Our work opens up many interesting directions for further exploration in this new family of models .
Parse:
opens VBZ ROOT
 +-- work NN nsubj
 |   +-- Our PRP$ poss
 +-- up RP prt
 +-- directions NNS dobj
 |   +-- many JJ amod
 |   +-- interesting JJ amod
 |   +-- for IN prep
 |       +-- exploration NN pobj
 |           +-- further JJ amod
 |           +-- in IN prep
 |               +-- family NN pobj
 |                   +-- this DT det
 |                   +-- new JJ amod
 |                   +-- of IN prep
 |                       +-- models NNS pobj
 +-- . . punct
Input: Further exploring the flexibilities over multinomial language models , such as length normalization and pseudo feedback could be good future work .
Parse:
work NN ROOT
 +-- exploring VBG csubj
 |   +-- Further RB advmod
 |   +-- flexibilities NNS dobj
 |       +-- the DT det
 |       +-- over IN prep
 |           +-- models NNS pobj
 |               +-- multinomial JJ amod
 |               +-- language NN nn
 |               +-- , , punct
 |               +-- as IN prep
 |                   +-- such JJ mwe
 |                   +-- normalization NN pobj
 |                       +-- length NN amod
 |                       +-- and CC cc
 |                       +-- feedback NN conj
 |                           +-- pseudo NN nn
 +-- could MD aux
 +-- be VB cop
 +-- good JJ amod
 +-- future JJ amod
 +-- . . punct
Input: It is also appealing to find robust methods to learn the per term smoothing coefficients without additional computation cost. .
Parse:
appealing VBG ROOT
 +-- It PRP nsubj
 +-- is VBZ aux
 +-- also RB advmod
 +-- find VB xcomp
 |   +-- to TO aux
 |   +-- learn VB xcomp
 |       +-- methods NNS nsubj
 |       |   +-- robust JJ amod
 |       +-- to TO aux
 |       +-- coefficients NNS dobj
 |       |   +-- the DT det
 |       |   |   +-- per IN prep
 |       |   |       +-- term NN pobj
 |       |   +-- smoothing VBG amod
 |       +-- without IN prep
 |           +-- cost. NN pobj
 |               +-- additional JJ amod
 |               +-- computation NN nn
 +-- . . punct
