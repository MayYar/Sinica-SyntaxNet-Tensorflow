
1
Input: Personalization is the future of the Web , and it has achieved great success in industrial applications .
Parse:
future NN ROOT
 +-- Personalization NN nsubj
 +-- is VBZ cop
 +-- the DT det
 +-- of IN prep
 |   +-- Web NN pobj
 |       +-- the DT det
 +-- , , punct
 +-- and CC cc
 +-- achieved VBN conj
 |   +-- it PRP nsubj
 |   +-- has VBZ aux
 |   +-- success NN dobj
 |       +-- great JJ amod
 |       +-- in IN prep
 |           +-- applications NNS pobj
 |               +-- industrial JJ amod
 +-- . . punct

2
Input: For example , online stores , such as Amazon and Netflix , provide customized recommendations for additional products or services based on a user '' s history .
Parse:
provide VB ROOT
 +-- For IN prep
 |   +-- example NN pobj
 +-- , , punct
 +-- stores NNS nsubj
 |   +-- online JJ amod
 |   +-- , , punct
 |   +-- as IN prep
 |       +-- such JJ mwe
 |       +-- Amazon NNP pobj
 |           +-- and CC cc
 |           +-- Netflix NNP conj
 +-- recommendations NNS dobj
 |   +-- customized JJ amod
 +-- for IN prep
 |   +-- products NNS pobj
 |       +-- additional JJ amod
 |       +-- or CC cc
 |       +-- services NNS conj
 |       +-- based VBN partmod
 |           +-- on IN prep
 |               +-- history NN pobj
 |                   +-- user NN poss
 |                       +-- a DT det
 |                       +-- '' '' punct
 |                       +-- s POS possessive
 +-- . . punct

3
Input: Recent offerings such as My MSN , My Yahoo ! , My Google , and Google News have attracted much attention due to their potential ability to infer a user '' s interests from his her history .
Parse:
attracted VBN ROOT
 +-- offerings NNS nsubj
 |   +-- Recent JJ amod
 |   +-- as IN prep
 |       +-- such JJ mwe
 |       +-- MSN NNP pobj
 |           +-- My PRP$ poss
 |           +-- , , punct
 |           +-- Yahoo NNP appos
 |           |   +-- My PRP$ poss
 |           +-- ! . punct
 |           +-- Google NNP conj
 |           |   +-- My PRP$ poss
 |           +-- and CC cc
 |           +-- News NNP conj
 |               +-- Google NNP nn
 +-- have VBP aux
 +-- attention NN dobj
 |   +-- much JJ amod
 +-- to IN prep
 |   +-- due IN mwe
 |   +-- ability NN pobj
 |       +-- their PRP$ poss
 |       +-- potential JJ amod
 |       +-- infer VB infmod
 |           +-- to TO aux
 |           +-- interests NNS dobj
 |           |   +-- user NN poss
 |           |       +-- a DT det
 |           |       +-- '' '' punct
 |           |       +-- s POS possessive
 |           +-- from IN prep
 |               +-- history NN pobj
 |                   +-- his PRP$ poss
 |                   +-- her PRP$ poss
 +-- . . punct

4
Input: One major personalization topic studied in the information retrieval community is content based personal recommendation systems1 .
Parse:
content JJ ROOT
 +-- topic NN nsubj
 |   +-- One CD num
 |   +-- major JJ amod
 |   +-- personalization NN nn
 |   +-- studied VBN partmod
 |       +-- in IN prep
 |           +-- community NN pobj
 |               +-- the DT det
 |               +-- retrieval NN nn
 |                   +-- information NN nn
 +-- is VBZ cop
 +-- based VBN prep
 |   +-- recommendation NN pobj
 |       +-- personal JJ amod
 |       +-- systems1 CD dep
 +-- . . punct

5
Input: These systems learn user specific profiles from user feedback so that they can recommend information tailored to each individual user '' s interest without requiring the user to make an explicit query .
Parse:
learn VBP ROOT
 +-- systems NNS nsubj
 |   +-- These DT det
 +-- profiles NNS dobj
 |   +-- user NN nn
 |   +-- specific JJ amod
 +-- from IN prep
 |   +-- feedback NN pobj
 |       +-- user NN nn
 +-- recommend VB advcl
 |   +-- so IN mark
 |   +-- that IN mark
 |   +-- they PRP nsubj
 |   +-- can MD aux
 |   +-- information NN dobj
 |   |   +-- tailored VBN partmod
 |   |       +-- to IN prep
 |   |           +-- interest NN pobj
 |   |               +-- user NN poss
 |   |                   +-- each DT det
 |   |                   +-- individual JJ amod
 |   |                   +-- '' '' punct
 |   |                   +-- s POS possessive
 |   +-- without IN prep
 |       +-- requiring VBG pcomp
 |           +-- user NN dobj
 |           |   +-- the DT det
 |           +-- make VB xcomp
 |               +-- to TO aux
 |               +-- query NN dobj
 |                   +-- an DT det
 |                   +-- explicit JJ amod
 +-- . . punct

6
Input: Learning the user profiles is the core problem for these systems .
Parse:
problem NN ROOT
 +-- Learning VBG csubj
 |   +-- profiles NNS dobj
 |       +-- the DT det
 |       +-- user NN nn
 +-- is VBZ cop
 +-- the DT det
 +-- core JJ nn
 +-- for IN prep
 |   +-- systems NNS pobj
 |       +-- these DT det
 +-- . . punct

7
Input: A user profile is usually a classifier that can identify whether a document is relevant to the user or not , or a regression model that tells how relevant a document is to the user .
Parse:
classifier NN ROOT
 +-- profile NN nsubj
 |   +-- A DT det
 |   +-- user NN nn
 +-- is VBZ cop
 +-- usually RB advmod
 +-- a DT det
 +-- identify VB rcmod
 |   +-- that WDT nsubj
 |   +-- can MD aux
 |   +-- relevant JJ ccomp
 |       +-- whether IN mark
 |       +-- document NN nsubj
 |       |   +-- a DT det
 |       +-- is VBZ cop
 |       +-- to IN prep
 |           +-- user NN pobj
 |               +-- the DT det
 |               +-- or CC cc
 |               +-- not RB conj
 |               +-- , , punct
 |               +-- model NN conj
 |                   +-- a DT det
 |                   +-- regression NN amod
 |                   +-- tells VBZ rcmod
 |                       +-- that WDT nsubj
 |                       +-- is VBZ ccomp
 |                           +-- relevant JJ dep
 |                           |   +-- how WRB advmod
 |                           +-- document NN nsubj
 |                           |   +-- a DT det
 |                           +-- to IN prep
 |                               +-- user NN pobj
 |                                   +-- the DT det
 +-- . . punct

8
Input: One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small .
Parse:
is VBZ ROOT
 +-- challenge NN nsubj
 |   +-- One CD num
 |   +-- major JJ amod
 |   +-- of IN prep
 |       +-- building VBG pcomp
 |           +-- system NN dobj
 |               +-- a DT det
 |               +-- recommendation NN nn
 |                   +-- or CC cc
 |                   +-- personalization NN conj
 +-- is VBZ ccomp
 |   +-- that IN mark
 |   +-- profile NN nsubj
 |   |   +-- the DT det
 |   |   +-- learned VBD partmod
 |   |       +-- for IN prep
 |   |           +-- user NN pobj
 |   |               +-- a DT det
 |   |               +-- particular JJ amod
 |   +-- usually RB advmod
 |   +-- of IN prep
 |   |   +-- quality NN pobj
 |   |       +-- low JJ amod
 |   +-- small JJ advcl
 |       +-- when WRB advmod
 |       +-- amount NN nsubj
 |       |   +-- the DT det
 |       |   +-- of IN prep
 |       |       +-- data NNS pobj
 |       |           +-- from IN prep
 |       |               +-- user NN pobj
 |       |                   +-- that DT det
 |       |                   +-- particular JJ amod
 |       +-- is VBZ cop
 +-- . . punct

9
Input: This is known as the cold start problem .
Parse:
known VBN ROOT
 +-- This DT nsubjpass
 +-- is VBZ auxpass
 +-- as IN prep
 |   +-- problem NN pobj
 |       +-- the DT det
 |       +-- start NN nn
 |           +-- cold JJ amod
 +-- . . punct

10
Input: This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile .
Parse:
means VBZ ROOT
 +-- This DT nsubj
 +-- endure VB ccomp
 |   +-- that IN mark
 |   +-- user NN nsubj
 |   |   +-- any DT det
 |   |   +-- new JJ amod
 |   +-- must MD aux
 |   +-- performance NN dobj
 |   |   +-- poor JJ amod
 |   |   +-- initial JJ amod
 |   +-- provided VBN advcl
 |       +-- until IN mark
 |       +-- feedback NN nsubjpass
 |       |   +-- sufficient JJ amod
 |       |   +-- from IN prep
 |       |       +-- user NN pobj
 |       |           +-- that DT det
 |       +-- is VBZ auxpass
 |       +-- learn VB xcomp
 |           +-- to TO aux
 |           +-- profile NN dobj
 |               +-- a DT det
 |               +-- reliable JJ amod
 |               +-- user NN nn
 +-- . . punct

11
Input: There has been much research on improving classification accuracy when the amount of labeled training data is small .
Parse:
research NN ROOT
 +-- There EX expl
 +-- has VBZ aux
 +-- been VBN cop
 +-- much JJ amod
 +-- on IN prep
 |   +-- improving VBG pcomp
 |       +-- accuracy NN dobj
 |       |   +-- classification NN nn
 |       +-- small JJ advcl
 |           +-- when WRB advmod
 |           +-- amount NN nsubj
 |           |   +-- the DT det
 |           |   +-- of IN prep
 |           |       +-- data NNS pobj
 |           |           +-- labeled VBN amod
 |           |           +-- training NN nn
 |           +-- is VBZ cop
 +-- . . punct

12
Input: The semi supervised learning approach combines unlabeled and labeled data together to achieve this goal -LRB- 26 -RRB- .
Parse:
combines VBZ ROOT
 +-- approach NN nsubj
 |   +-- The DT det
 |   +-- supervised VBD amod
 |   |   +-- semi NN dep
 |   +-- learning VBG amod
 +-- data NNS dobj
 |   +-- unlabeled JJ amod
 |       +-- and CC cc
 |       +-- labeled VBN conj
 +-- together RB advmod
 +-- achieve VB xcomp
 |   +-- to TO aux
 |   +-- goal NN dobj
 |       +-- this DT det
 |       +-- -LRB- -LRB- punct
 |       +-- 26 CD dep
 |       +-- -RRB- -RRB- punct
 +-- . . punct

13
Input: Another approach is using domain knowledge .
Parse:
using VBG ROOT
 +-- approach NN nsubj
 |   +-- Another DT det
 +-- is VBZ aux
 +-- knowledge NN dobj
 |   +-- domain NN nn
 +-- . . punct

14
Input: Researchers have modified different learning algorithms , such as Na ? ? veBayes -LRB- 17 -RRB- , logistic regression -LRB- 7 -RRB- , and SVMs -LRB- 22 -RRB- , to integrate domain knowledge into a text classifier .
Parse:
modified VBN ROOT
 +-- Researchers NNS nsubj
 +-- have VBP aux
 +-- algorithms NNS dobj
 |   +-- different JJ amod
 |   +-- learning NN amod
 |   +-- , , punct
 |   +-- as IN prep
 |       +-- such JJ mwe
 |       +-- Na NNP pobj
 +-- ? . punct
 +-- ? , punct
 +-- veBayes NNS dobj
 |   +-- -LRB- -LRB- punct
 |   +-- 17 CD dep
 |   +-- -RRB- -RRB- punct
 |   +-- , , punct
 |   +-- regression NN conj
 |   |   +-- logistic JJ amod
 |   |   +-- -LRB- -LRB- punct
 |   |   +-- 7 CD dep
 |   |   +-- -RRB- -RRB- punct
 |   +-- and CC cc
 |   +-- SVMs NNS conj
 |       +-- -LRB- -LRB- punct
 |       +-- 22 CD dep
 |       +-- -RRB- -RRB- punct
 +-- , , punct
 +-- integrate VB xcomp
 |   +-- to TO aux
 |   +-- knowledge NN dobj
 |   |   +-- domain NN nn
 |   +-- into IN prep
 |       +-- classifier NN pobj
 |           +-- a DT det
 |           +-- text NN nn
 +-- . . punct

15
Input: The third approach is borrowing training data from other resources -LRB- 5 -RRB- -LRB- 7 -RRB- .
Parse:
borrowing VBG ROOT
 +-- approach NN nsubj
 |   +-- The DT det
 |   +-- third JJ amod
 +-- is VBZ aux
 +-- data NNS dobj
 |   +-- training NN nn
 |   +-- from IN prep
 |       +-- resources NNS pobj
 |           +-- other JJ amod
 |           +-- -LRB- -LRB- punct
 |           +-- 5 CD dep
 |           +-- -RRB- -RRB- punct
 |           +-- 7 CD dep
 +-- . . punct

16
Input: The effectiveness of these different approaches is mixed , due to how well the underlying model assumption fits the data .
Parse:
mixed JJ ROOT
 +-- effectiveness NN nsubj
 |   +-- The DT det
 |   +-- of IN prep
 |       +-- approaches NNS pobj
 |           +-- these DT det
 |           +-- different JJ amod
 +-- is VBZ cop
 +-- , , punct
 +-- to IN prep
 |   +-- due IN mwe
 |   +-- fits VBZ pcomp
 |       +-- well RB advmod
 |       |   +-- how WRB advmod
 |       +-- assumption NN nsubj
 |       |   +-- the DT det
 |       |   +-- model NN nn
 |       |       +-- underlying JJ amod
 |       +-- data NNS dobj
 |           +-- the DT det
 +-- . . punct

17
Input: One well received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach .
Parse:
received VBD ROOT
 +-- One CD nsubj
 +-- well RB advmod
 +-- approach NN dobj
 |   +-- improve VB infmod
 |       +-- to TO aux
 |       +-- performance NN dobj
 |           +-- recommendation NN nn
 |           +-- system NN nn
 |           +-- for IN prep
 |               +-- user NN pobj
 |                   +-- a DT det
 |                   +-- particular JJ amod
 +-- borrowing VBG xcomp
 |   +-- is VBZ aux
 |   +-- information NN dobj
 |   |   +-- from IN prep
 |   |       +-- users NNS pobj
 |   |           +-- other JJ amod
 |   +-- through IN prep
 |       +-- approach NN pobj
 |           +-- a DT det
 |           +-- Bayesian JJ amod
 |           +-- modeling NN nn
 |               +-- hierarchical JJ amod
 +-- . . punct

18
Input: Several researchers have demonstrated that this approach effectively trades off between shared and user specific information , thus alleviating poor initial performance for each user -LRB- 27 -RRB- -LRB- 25 -RRB- .
Parse:
demonstrated VBN ROOT
 +-- researchers NNS nsubj
 |   +-- Several JJ amod
 +-- have VBP aux
 +-- trades VBZ ccomp
 |   +-- that IN mark
 |   +-- approach NN nsubj
 |   |   +-- this DT det
 |   +-- effectively RB advmod
 |   +-- off RP prt
 |   +-- between IN prep
 |   |   +-- information NN pobj
 |   |       +-- shared VBN amod
 |   |       |   +-- and CC cc
 |   |       |   +-- user NN conj
 |   |       +-- specific JJ amod
 |   +-- , , punct
 |   +-- alleviating VBG xcomp
 |       +-- thus RB advmod
 |       +-- performance NN dobj
 |           +-- poor JJ amod
 |           +-- initial JJ amod
 |           +-- for IN prep
 |           |   +-- user NN pobj
 |           |       +-- each DT det
 |           +-- -LRB- -LRB- punct
 |           +-- 27 CD dep
 |           +-- -RRB- -RRB- punct
 |           +-- 25 CD dep
 +-- . . punct

19
Input: In order to learn a Bayesian hierarchical model , the system usually tries to find the most likely model parameters for the given data .
Parse:
tries VBZ ROOT
 +-- In IN prep
 |   +-- order NN pobj
 |       +-- learn VB infmod
 |           +-- to TO aux
 |           +-- model NN dobj
 |               +-- a DT det
 |               +-- Bayesian JJ amod
 |               +-- hierarchical JJ amod
 +-- , , punct
 +-- system NN nsubj
 |   +-- the DT det
 +-- usually RB advmod
 +-- find VB xcomp
 |   +-- to TO aux
 |   +-- parameters NNS dobj
 |       +-- the DT det
 |       +-- likely JJ amod
 |       |   +-- most RBS advmod
 |       +-- model NN nn
 |       +-- for IN prep
 |           +-- data NNS pobj
 |               +-- the DT det
 |               +-- given VBN amod
 +-- . . punct

20
Input: A mature recommendation system usually works for millions of users .
Parse:
works VBZ ROOT
 +-- system NN nsubj
 |   +-- A DT det
 |   +-- mature JJ amod
 |   +-- recommendation NN nn
 +-- usually RB advmod
 +-- for IN prep
 |   +-- millions NNS pobj
 |       +-- of IN prep
 |           +-- users NNS pobj
 +-- . . punct

21
Input: It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users .
Parse:
known VBN ROOT
 +-- It PRP nsubjpass
 +-- is VBZ auxpass
 +-- well RB advmod
 +-- expensive JJ ccomp
 |   +-- that IN mark
 |   +-- learning VBG csubj
 |   |   +-- parameters NNS dobj
 |   |       +-- the DT det
 |   |       +-- optimal JJ amod
 |   |       +-- of IN prep
 |   |           +-- model NN pobj
 |   |               +-- a DT det
 |   |               +-- Bayesian JJ amod
 |   |               +-- hierarchical JJ amod
 |   +-- is VBZ cop
 |   +-- computationally RB advmod
 |   +-- are VBP advcl
 |       +-- when WRB advmod
 |       +-- there EX expl
 |       +-- thousands NNS nsubj
 |           +-- or CC cc
 |           +-- millions NNS conj
 |           +-- of IN prep
 |               +-- users NNS pobj
 +-- . . punct

22
Input: The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee .
Parse:
technique NN ROOT
 +-- algorithm NNP nsubj
 |   +-- The DT det
 |   +-- EM NNP nn
 +-- is VBZ cop
 +-- a DT det
 +-- used VBN amod
 |   +-- commonly RB advmod
 +-- for IN prep
 |   +-- learning VBG pobj
 |       +-- parameter NN nn
 +-- to IN prep
 |   +-- due IN mwe
 |   +-- guarantee NN pobj
 |       +-- its PRP$ poss
 |       +-- simplicity NN nn
 |           +-- and CC cc
 |           +-- convergence NN conj
 +-- . . punct

23
Input: However , a content based recommendation system often handles documents in a very high dimensional space , in which each document is represented by a very sparse vector .
Parse:
handles VBZ ROOT
 +-- However RB advmod
 +-- , , punct
 +-- system NN nsubj
 |   +-- a DT det
 |   +-- based VBN amod
 |   |   +-- content NN dep
 |   +-- recommendation NN nn
 +-- often RB advmod
 +-- documents NNS dobj
 +-- in IN prep
 |   +-- space NN pobj
 |       +-- a DT det
 |       +-- high JJ amod
 |       |   +-- very RB advmod
 |       +-- dimensional JJ amod
 |       +-- , , punct
 |       +-- represented VBN rcmod
 |           +-- in IN prep
 |           |   +-- which WDT pobj
 |           +-- document NN nsubjpass
 |           |   +-- each DT det
 |           +-- is VBZ auxpass
 |           +-- by IN prep
 |               +-- vector NN pobj
 |                   +-- a DT det
 |                   +-- sparse JJ amod
 |                       +-- very RB advmod
 +-- . . punct

24
Input: With careful analysis of the EM algorithm in this scenario -LRB- Section 4 -RRB- , we find that the EM tering , or item based collaborative filtering .
Parse:
find VBP ROOT
 +-- With IN prep
 |   +-- analysis NN pobj
 |       +-- careful JJ amod
 |       +-- of IN prep
 |           +-- algorithm NNP pobj
 |               +-- the DT det
 |               +-- EM NNP nn
 |               +-- in IN prep
 |               |   +-- scenario NN pobj
 |               |       +-- this DT det
 |               +-- -LRB- -LRB- punct
 |               +-- Section NN dep
 |               |   +-- 4 CD num
 |               +-- -RRB- -RRB- punct
 +-- , , punct
 +-- we PRP nsubj
 +-- based VBN ccomp
 |   +-- that IN mark
 |   +-- tering NN nsubj
 |   |   +-- the DT det
 |   |   +-- EM NNP nn
 |   |   +-- , , punct
 |   |   +-- or CC cc
 |   |   +-- item NN conj
 |   +-- filtering NN dobj
 |       +-- collaborative JJ amod
 +-- . . punct

25
Input: In this paper , the words filtering and recommendation are used interchangeably .
Parse:
used VBN ROOT
 +-- In IN prep
 |   +-- paper NN pobj
 |       +-- this DT det
 +-- , , punct
 +-- filtering VBG nsubjpass
 |   +-- the DT det
 |   +-- words NNS nn
 |   +-- and CC cc
 |   +-- recommendation NN conj
 +-- are VBP auxpass
 +-- interchangeably RB advmod
 +-- . . punct

26
Input: algorithm converges very slowly due to the sparseness of the input variables .
Parse:
converges NNS ROOT
 +-- algorithm NN nsubj
 +-- slowly RB advmod
 |   +-- very RB advmod
 +-- to IN prep
 |   +-- due IN mwe
 |   +-- sparseness NN pobj
 |       +-- the DT det
 |       +-- of IN prep
 |           +-- variables NNS pobj
 |               +-- the DT det
 |               +-- input NN nn
 +-- . . punct

27
Input: We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O -LRB- MK -RRB- , where M is the number of users and K is the number of dimensions .
Parse:
find VBP ROOT
 +-- We PRP nsubj
 +-- also RB advmod
 +-- expensive JJ ccomp
 |   +-- that IN mark
 |   +-- updating VBG csubj
 |   |   +-- parameter NN dobj
 |   |   |   +-- the DT det
 |   |   |   +-- model NN amod
 |   |   +-- at IN prep
 |   |       +-- iteration NN pobj
 |   |           +-- each DT det
 |   |           +-- EM NNP nn
 |   +-- is VBZ cop
 |   +-- also RB advmod
 |   +-- with IN prep
 |       +-- complexity NN pobj
 |           +-- computational JJ amod
 |           +-- of IN prep
 |           |   +-- O NNP pobj
 |           |       +-- -LRB- -LRB- punct
 |           |       +-- MK NNP dep
 |           |       +-- -RRB- -RRB- punct
 |           +-- , , punct
 |           +-- number NN rcmod
 |               +-- where WRB advmod
 |               +-- M NNP nsubj
 |               +-- is VBZ cop
 |               +-- the DT det
 |               +-- of IN prep
 |               |   +-- users NNS pobj
 |               +-- and CC cc
 |               +-- number NN conj
 |                   +-- K NNP nsubj
 |                   +-- is VBZ cop
 |                   +-- the DT det
 |                   +-- of IN prep
 |                       +-- dimensions NNS pobj
 +-- . . punct

28
Input: This paper modifies the standard EM algorithm to create an improved learning algorithm , which we call the Modified EM algorithm .
Parse:
modifies VBZ ROOT
 +-- paper NN nsubj
 |   +-- This DT det
 +-- algorithm NNP dobj
 |   +-- the DT det
 |   +-- standard JJ amod
 |   +-- EM NNP nn
 +-- create VB xcomp
 |   +-- to TO aux
 |   +-- algorithm NN dobj
 |       +-- an DT det
 |       +-- improved JJ amod
 |       +-- learning NN amod
 |       +-- , , punct
 |       +-- call VBP rcmod
 |           +-- which WDT dobj
 |           +-- we PRP nsubj
 |           +-- algorithm NNP dobj
 |               +-- the DT det
 |               +-- Modified NNP nn
 |               +-- EM NNP nn
 +-- . . punct

29
Input: The basic idea is that instead of calculating the numerical solution for all the user profile parameters , we derive the analytical solution of the parameters for some feature dimensions , and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters .
Parse:
is VBZ ROOT
 +-- idea NN nsubj
 |   +-- The DT det
 |   +-- basic JJ amod
 +-- derive VBP ccomp
 |   +-- that IN mark
 |   +-- of IN prep
 |   |   +-- instead RB advmod
 |   |   +-- calculating VBG pcomp
 |   |       +-- solution NN dobj
 |   |           +-- the DT det
 |   |           +-- numerical JJ amod
 |   |           +-- for IN prep
 |   |               +-- parameters NNS pobj
 |   |                   +-- all PDT predet
 |   |                   +-- the DT det
 |   |                   +-- profile NN nn
 |   |                       +-- user NN nn
 |   +-- , , punct
 |   +-- we PRP nsubj
 |   +-- solution NN dobj
 |   |   +-- the DT det
 |   |   +-- analytical JJ amod
 |   |   +-- of IN prep
 |   |       +-- parameters NNS pobj
 |   |           +-- the DT det
 |   |           +-- for IN prep
 |   |               +-- dimensions NNS pobj
 |   |                   +-- some DT det
 |   |                   +-- feature NN nn
 |   +-- and CC cc
 |   +-- use VB conj
 |       +-- at IN prep
 |       |   +-- step NN pobj
 |       |       +-- the DT det
 |       |       +-- M NNP nn
 |       +-- solution NN dobj
 |           +-- the DT det
 |           +-- analytical JJ amod
 |           +-- of IN prep
 |               +-- instead RB advmod
 |               +-- solution NN pobj
 |                   +-- the DT det
 |                   +-- numerical JJ amod
 |                   +-- estimated VBN partmod
 |                       +-- at IN prep
 |                           +-- step NN pobj
 |                               +-- E JJ nn
 |                               +-- for IN prep
 |                                   +-- parameters NNS pobj
 |                                       +-- those DT det
 +-- . . punct

30
Input: This greatly reduces the computation at a single EM iteration , and also has the benefit of increasing the convergence speed of the learning algorithm .
Parse:
reduces VBZ ROOT
 +-- This DT nsubj
 +-- greatly RB advmod
 +-- computation NN dobj
 |   +-- the DT det
 +-- at IN prep
 |   +-- iteration NN pobj
 |       +-- a DT det
 |       +-- single JJ amod
 |       +-- EM NNP nn
 +-- , , punct
 +-- and CC cc
 +-- also RB advmod
 +-- has VBZ conj
 |   +-- benefit NN dobj
 |       +-- the DT det
 |       +-- of IN prep
 |           +-- increasing VBG pcomp
 |               +-- speed NN dobj
 |                   +-- the DT det
 |                   +-- convergence NN nn
 |                   +-- of IN prep
 |                       +-- algorithm NN pobj
 |                           +-- the DT det
 |                           +-- learning NN amod
 +-- . . punct

31
Input: The proposed technique is not only well supported by theory , but also by experimental results .
Parse:
is VBZ ROOT
 +-- technique NN nsubj
 |   +-- The DT det
 |   +-- proposed VBN amod
 +-- only RB dep
 |   +-- not RB neg
 |   +-- supported VBN dep
 |   |   +-- well RB advmod
 |   |   +-- by IN prep
 |   |       +-- theory NN pobj
 |   +-- , , punct
 |   +-- also RB cc
 |   |   +-- but CC cc
 |   +-- by IN conj
 |       +-- results NNS pobj
 |           +-- experimental JJ amod
 +-- . . punct

32
Input: The organization of the remaining parts of this paper is as follows
Parse:
is VBZ ROOT
 +-- organization NN nsubj
 |   +-- The DT det
 |   +-- of IN prep
 |       +-- parts NNS pobj
 |           +-- the DT det
 |           +-- remaining VBG amod
 |           +-- of IN prep
 |               +-- paper NN pobj
 |                   +-- this DT det
 +-- follows VBZ advcl
     +-- as IN mark

33
Input: Section 4 describes how to learn the model parameters using the standard EM algorithm , along with using the new technique proposed in this paper .
Parse:
describes VBZ ROOT
 +-- Section NN nsubj
 |   +-- 4 CD num
 +-- learn VB ccomp
 |   +-- how WRB advmod
 |   +-- to TO aux
 |   +-- parameters NNS dobj
 |   |   +-- the DT det
 |   |   +-- model NN nn
 |   +-- using VBG xcomp
 |       +-- algorithm NNP dobj
 |           +-- the DT det
 |           +-- standard NN amod
 |           +-- EM NNP nn
 |           +-- , , punct
 |           +-- along IN prep
 |               +-- with IN pcomp
 |                   +-- using VBG pcomp
 |                       +-- technique NN dobj
 |                           +-- the DT det
 |                           +-- new JJ amod
 |                           +-- proposed VBN partmod
 |                               +-- in IN prep
 |                                   +-- paper NN pobj
 |                                       +-- this DT det
 +-- . . punct

34
Input: The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6 .
Parse:
reported VBN ROOT
 +-- setting NN nsubjpass
 |   +-- The DT det
 |   +-- experimental JJ amod
 |   +-- and CC cc
 |   +-- results NNS conj
 |   +-- used VBN partmod
 |       +-- validate VB xcomp
 |           +-- to TO aux
 |           +-- technique NN dobj
 |               +-- the DT det
 |               +-- proposed VBN amod
 |               +-- learning NN nn
 +-- are VBP auxpass
 +-- in IN prep
 |   +-- Sections NNPS pobj
 |       +-- 5 CD num
 |       +-- and CC cc
 |       +-- 6 CD conj
 +-- . . punct

35
Input: Section 7 summarizes and offers concluding remarks. .
Parse:
summarizes NNS ROOT
 +-- Section NN nsubj
 |   +-- 7 CD num
 +-- and CC cc
 +-- offers VBZ conj
 +-- remarks. NNS dobj
 |   +-- concluding NN nn
 +-- . . punct
