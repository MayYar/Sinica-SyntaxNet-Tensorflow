
1
Input: In this section , we describe our experiment results .
Parse:
describe VBP ROOT
 +-- In IN prep
 |   +-- section NN pobj
 |       +-- this DT det
 +-- , , punct
 +-- we PRP nsubj
 +-- results NNS dobj
 |   +-- our PRP$ poss
 |   +-- experiment NN nn
 +-- . . punct

2
Input: We first describe our experiment setup and present an overview of various methods '' performance .
Parse:
describe VBP ROOT
 +-- We PRP nsubj
 +-- first RB advmod
 +-- setup NN dobj
 |   +-- our PRP$ poss
 |   +-- experiment NN nn
 +-- and CC cc
 +-- present VB conj
 |   +-- overview NN dobj
 |       +-- an DT det
 |       +-- of IN prep
 |           +-- performance NN pobj
 |               +-- methods NNS nn
 |               |   +-- various JJ amod
 |               +-- '' '' punct
 +-- . . punct

3
Input: Then we discuss the effects of varying the parameter setting in the algorithms , as well as the number of presentation terms .
Parse:
discuss VBP ROOT
 +-- Then RB advmod
 +-- we PRP nsubj
 +-- effects NNS dobj
 |   +-- the DT det
 |   +-- of IN prep
 |       +-- varying VBG pcomp
 |           +-- setting NN dobj
 |               +-- the DT det
 |               +-- parameter NN nn
 |               +-- in IN prep
 |               |   +-- algorithms NNS pobj
 |               |       +-- the DT det
 |               +-- , , punct
 |               +-- well RB cc
 |               |   +-- as RB advmod
 |               |   +-- as IN mwe
 |               +-- number NN conj
 |                   +-- the DT det
 |                   +-- of IN prep
 |                       +-- terms NNS pobj
 |                           +-- presentation NN nn
 +-- . . punct

4
Input: Next we analyze user term feedback behavior and its relation to retrieval performance .
Parse:
analyze VBP ROOT
 +-- Next RB advmod
 +-- we PRP nsubj
 +-- behavior NN dobj
 |   +-- term NN nn
 |   |   +-- user NN nn
 |   +-- feedback NN nn
 |   +-- and CC cc
 |   +-- relation NN conj
 |       +-- its PRP$ poss
 |       +-- to IN prep
 |           +-- performance NN pobj
 |               +-- retrieval NN nn
 +-- . . punct

5
Input: Finally we compare term feedback to relevance feedback and show that it has its particular advantage .
Parse:
compare VBP ROOT
 +-- Finally RB advmod
 +-- we PRP nsubj
 +-- feedback NN dobj
 |   +-- term NN nn
 |   +-- relevance VB infmod
 |       +-- to TO aux
 |       +-- feedback NN dobj
 |       +-- and CC cc
 |       +-- show VB conj
 |           +-- has VBZ ccomp
 |               +-- that IN mark
 |               +-- it PRP nsubj
 |               +-- advantage NN dobj
 |                   +-- its PRP$ poss
 |                   +-- particular JJ amod
 +-- . . punct

6
Input: 6.1 Experiment Setup and Basic Results We took the opportunity of TREC 2005 HARD Track -LRB- 2 -RRB- for the evaluation of our algorithms .
Parse:
took VBD ROOT
 +-- Results NNS nsubj
 |   +-- 6.1 CD num
 |   +-- Setup NNP nn
 |       +-- Experiment NNP nn
 |       +-- and CC cc
 |       +-- Basic NNP conj
 +-- We PRP nsubj
 +-- opportunity NN dobj
 |   +-- the DT det
 |   +-- of IN prep
 |       +-- Track NNP pobj
 |           +-- TREC NNP nn
 |           |   +-- 2005 CD num
 |           +-- HARD NNP nn
 |           +-- -LRB- -LRB- punct
 |           +-- 2 CD dep
 |           +-- -RRB- -RRB- punct
 +-- for IN prep
 |   +-- evaluation NN pobj
 |       +-- the DT det
 |       +-- of IN prep
 |           +-- algorithms NNS pobj
 |               +-- our PRP$ poss
 +-- . . punct

7
Input: The tracks used the AQUAINT collection , a 3GB corpus of English newswire text .
Parse:
used VBD ROOT
 +-- tracks NNS nsubj
 |   +-- The DT det
 +-- collection NN dobj
 |   +-- the DT det
 |   +-- AQUAINT JJ amod
 |   +-- , , punct
 |   +-- corpus NN appos
 |       +-- a DT det
 |       +-- 3GB CD num
 |       +-- of IN prep
 |           +-- text NN pobj
 |               +-- newswire NN nn
 |                   +-- English JJ nn
 +-- . . punct

8
Input: The topics included 50 ones previously known to be hard , i.e .
Parse:
included VBD ROOT
 +-- topics NNS nsubj
 |   +-- The DT det
 +-- ones NNS dobj
 |   +-- 50 CD num
 |   +-- known VBN partmod
 |       +-- previously RB advmod
 |       +-- hard JJ xcomp
 |           +-- to TO aux
 |           +-- be VB cop
 |           +-- , , punct
 |           +-- i.e NN dep
 +-- . . punct

9
Input: with low retrieval performance .
Parse:
with IN ROOT
 +-- performance NN pobj
 |   +-- low JJ amod
 |   +-- retrieval NN nn
 +-- . . punct

10
Input: It is for these hard topics that user feedback is most helpful , as it can provide information to disambiguate the queries ; with easy topics the user may be unwilling to spend efforts for feedback if the automatic retrieval results are good enough .
Parse:
is VBZ ROOT
 +-- It PRP nsubj
 +-- for IN prep
 |   +-- topics NNS pobj
 |       +-- these DT det
 |       +-- hard JJ amod
 +-- helpful JJ ccomp
 |   +-- that WDT mark
 |   +-- feedback NN nsubj
 |   |   +-- user NN nn
 |   +-- is VBZ cop
 |   +-- most RBS advmod
 |   +-- , , punct
 |   +-- provide VB advcl
 |   |   +-- as IN mark
 |   |   +-- it PRP nsubj
 |   |   +-- can MD aux
 |   |   +-- information NN dobj
 |   |       +-- disambiguate VB infmod
 |   |           +-- to TO aux
 |   |           +-- queries NNS dobj
 |   |               +-- the DT det
 |   +-- ; : punct
 |   +-- unwilling JJ parataxis
 |       +-- with IN prep
 |       |   +-- topics NNS pobj
 |       |       +-- easy JJ amod
 |       +-- user NN nsubj
 |       |   +-- the DT det
 |       +-- may MD aux
 |       +-- be VB cop
 |       +-- spend VB xcomp
 |           +-- to TO aux
 |           +-- efforts NNS dobj
 |           |   +-- for IN prep
 |           |       +-- feedback NN pobj
 |           +-- good JJ advcl
 |               +-- if IN mark
 |               +-- results NNS nsubj
 |               |   +-- the DT det
 |               |   +-- automatic JJ amod
 |               |   +-- retrieval NN nn
 |               +-- are VBP cop
 |               +-- enough RB advmod
 +-- . . punct

11
Input: Participants of the track were able to submit custom designed clarification forms to solicit feedback from human assessors provided by Table 2
Parse:
able JJ ROOT
 +-- Participants NNS nsubj
 |   +-- of IN prep
 |       +-- track NN pobj
 |           +-- the DT det
 +-- were VBD cop
 +-- submit VB xcomp
     +-- to TO aux
     +-- forms NNS dobj
     |   +-- designed VBN amod
     |   |   +-- custom NN dep
     |   +-- clarification NN nn
     +-- solicit VB xcomp
         +-- to TO aux
         +-- feedback NN dobj
             +-- from IN prep
             |   +-- assessors NNS pobj
             |       +-- human JJ amod
             +-- provided VBN partmod
                 +-- by IN prep
                     +-- Table NNP pobj
                         +-- 2 CD num

12
Input: The last row is the percentage of MAP improvement over the baseline .
Parse:
percentage NN ROOT
 +-- row NN nsubj
 |   +-- The DT det
 |   +-- last JJ amod
 +-- is VBZ cop
 +-- the DT det
 +-- of IN prep
 |   +-- improvement NN pobj
 |       +-- MAP NNP nn
 +-- over IN prep
 |   +-- baseline NN pobj
 |       +-- the DT det
 +-- . . punct
