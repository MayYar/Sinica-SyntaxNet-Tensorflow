
1
Input: In order to better understand the strengths and weaknesses of our technique , we evaluate it on a wide range of data sets .
Parse:
evaluate VBP ROOT
 +-- In IN prep
 |   +-- order NN pobj
 |       +-- understand VB infmod
 |           +-- to TO aux
 |           +-- better RBR advmod
 |           +-- strengths NNS dobj
 |               +-- the DT det
 |               +-- and CC cc
 |               +-- weaknesses NNS conj
 |               +-- of IN prep
 |                   +-- technique NN pobj
 |                       +-- our PRP$ poss
 +-- , , punct
 +-- we PRP nsubj
 +-- it PRP dobj
 +-- on IN prep
 |   +-- range NN pobj
 |       +-- a DT det
 |       +-- wide JJ amod
 |       +-- of IN prep
 |           +-- sets NNS pobj
 |               +-- data NNS nn
 +-- . . punct

2
Input: Table 2 provides a summary of the TREC data sets considered .
Parse:
provides VBZ ROOT
 +-- Table NNP nsubj
 |   +-- 2 CD num
 +-- summary NN dobj
 |   +-- a DT det
 |   +-- of IN prep
 |       +-- sets NNS pobj
 |           +-- the DT det
 |           +-- TREC NNP nn
 |           +-- data NN nn
 |           +-- considered VBN partmod
 +-- . . punct

3
Input: The WSJ , AP , and ROBUST collections are smaller and consist entirely of newswire articles , whereas WT10g and GOV2 are large web collections .
Parse:
smaller JJR ROOT
 +-- collections NNS nsubj
 |   +-- The DT det
 |   +-- WSJ NNP nn
 |       +-- , , punct
 |       +-- AP NNP conj
 |       +-- and CC cc
 |       +-- ROBUST NNP conj
 +-- are VBP cop
 +-- and CC cc
 +-- consist VBP conj
 |   +-- entirely RB advmod
 +-- of IN prep
 |   +-- articles NNS pobj
 |       +-- newswire NN nn
 +-- , , punct
 +-- collections NNS advcl
 |   +-- whereas IN mark
 |   +-- WT10g CD nsubj
 |   |   +-- and CC cc
 |   |   +-- GOV2 CD conj
 |   +-- are VBP cop
 |   +-- large JJ amod
 |   +-- web NN nn
 +-- . . punct

4
Input: For each data set , we split the available topics into a training and test set , where the training set is used solely for parameter estimation and the test set is used for evaluation purposes .
Parse:
split VBD ROOT
 +-- For IN prep
 |   +-- data NNS pobj
 |       +-- each DT det
 |       +-- set VBN partmod
 +-- , , punct
 +-- we PRP nsubj
 +-- topics NNS dobj
 |   +-- the DT det
 |   +-- available JJ amod
 +-- into IN prep
 |   +-- set VBN pobj
 |       +-- a DT det
 |       +-- training NN nn
 |       |   +-- and CC cc
 |       |   +-- test NN conj
 |       +-- , , punct
 |       +-- used VBN rcmod
 |           +-- where WRB advmod
 |           +-- set NN nsubjpass
 |           |   +-- the DT det
 |           |   +-- training NN nn
 |           +-- is VBZ auxpass
 |           +-- solely RB advmod
 |           +-- for IN prep
 |           |   +-- estimation NN pobj
 |           |       +-- parameter NN nn
 |           +-- and CC cc
 |           +-- used VBN conj
 |               +-- test NN nsubjpass
 |               |   +-- the DT det
 |               |   +-- set VBN partmod
 |               +-- is VBZ auxpass
 |               +-- for IN prep
 |                   +-- purposes NNS pobj
 |                       +-- evaluation NN nn
 +-- . . punct

5
Input: All experiments were carried out using a modified version of Indri , which is part of the Lemur Toolkit -LRB- 18 , 23 -RRB- .
Parse:
carried VBN ROOT
 +-- experiments NNS nsubjpass
 |   +-- All DT det
 +-- were VBD auxpass
 +-- out RP prt
 +-- using VBG xcomp
 |   +-- version NN dobj
 |       +-- a DT det
 |       +-- modified VBN amod
 |       +-- of IN prep
 |       |   +-- Indri NNP pobj
 |       +-- , , punct
 |       +-- part NN rcmod
 |           +-- which WDT nsubj
 |           +-- is VBZ cop
 |           +-- of IN prep
 |               +-- Toolkit NNP pobj
 |                   +-- the DT det
 |                   +-- Lemur NNP nn
 |                   +-- 23 CD appos
 |                       +-- -LRB- -LRB- punct
 |                       +-- 18 CD num
 |                       +-- , , punct
 |                       +-- -RRB- -RRB- punct
 +-- . . punct

6
Input: All collections were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer .
Parse:
stopped VBN ROOT
 +-- collections NNS nsubjpass
 |   +-- All DT det
 +-- were VBD auxpass
 +-- using VBG xcomp
 |   +-- list NN dobj
 |       +-- a DT det
 |       +-- standard JJ amod
 |       +-- of IN prep
 |           +-- terms NNS pobj
 |               +-- 418 CD num
 |               +-- common JJ amod
 +-- and CC cc
 +-- stemmed VBD conj
 |   +-- using VBG xcomp
 |       +-- stemmer NN dobj
 |           +-- a DT det
 |           +-- Porter NNP nn
 +-- . . punct

7
Input: In all cases , only the title portion of the TREC topics are used to construct queries .
Parse:
used VBN ROOT
 +-- In IN prep
 |   +-- cases NNS pobj
 |       +-- all DT det
 +-- , , punct
 +-- portion NN nsubjpass
 |   +-- only RB advmod
 |   +-- the DT det
 |   +-- title NN nn
 |   +-- of IN prep
 |       +-- topics NNS pobj
 |           +-- the DT det
 |           +-- TREC NNP nn
 +-- are VBP auxpass
 +-- construct VB xcomp
 |   +-- to TO aux
 |   +-- queries NNS dobj
 +-- . . punct

8
Input: We construct G using the sequential dependence assumption for all data sets -LRB- 14 -RRB- .
Parse:
construct VBP ROOT
 +-- We PRP nsubj
 +-- G NNP dobj
 +-- using VBG xcomp
 |   +-- assumption NN dobj
 |       +-- the DT det
 |       +-- dependence NN nn
 |       |   +-- sequential JJ amod
 |       +-- for IN prep
 |           +-- sets NNS pobj
 |               +-- all DT det
 |               +-- data NNS nn
 |               +-- 14 CD appos
 |                   +-- -LRB- -LRB- punct
 |                   +-- -RRB- -RRB- punct
 +-- . . punct

9
Input: 4.1 ad hoc Retrieval Results We now investigate how well our model performs in practice in a pseudo relevance feedback setting .
Parse:
investigate VBP ROOT
 +-- Results NNPS nsubj
 |   +-- 4.1 CD num
 |   +-- ad NN nn
 |   +-- hoc FW nn
 |   +-- Retrieval NNP nn
 +-- We PRP nsubj
 +-- now RB advmod
 +-- performs VBZ ccomp
 |   +-- well RB advmod
 |   |   +-- how WRB advmod
 |   +-- model NN nsubj
 |   |   +-- our PRP$ poss
 |   +-- in IN prep
 |       +-- setting NN pobj
 |           +-- a DT det
 |           +-- relevance NN nn
 |           |   +-- pseudo NN nn
 |           +-- feedback NN nn
 +-- . . punct

10
Input: We compare unigram language modeling -LRB- with Dirichlet smoothing -RRB- , the MRF model -LRB- without expansion -RRB- , relevance models , and LCE to better understand how each model performs across the various data sets .
Parse:
compare VBP ROOT
 +-- We PRP nsubj
 +-- modeling NN dobj
 |   +-- language NN nn
 |   |   +-- unigram NN nn
 |   +-- -LRB- -LRB- punct
 |   +-- with IN prep
 |   |   +-- smoothing VBG pobj
 |   |       +-- Dirichlet NNP nn
 |   +-- -RRB- -RRB- punct
 |   +-- , , punct
 |   +-- model NN conj
 |   |   +-- the DT det
 |   |   +-- MRF NNP nn
 |   |   +-- -LRB- -LRB- punct
 |   |   +-- without IN prep
 |   |   |   +-- expansion NN pobj
 |   |   +-- -RRB- -RRB- punct
 |   +-- models NNS conj
 |   |   +-- relevance NN nn
 |   +-- and CC cc
 |   +-- LCE NN conj
 |       +-- understand VB infmod
 |           +-- to TO aux
 |           +-- better RBR advmod
 |           +-- performs VBZ ccomp
 |               +-- how WRB advmod
 |               +-- model NN nsubj
 |               |   +-- each DT det
 |               +-- across IN prep
 |                   +-- sets NNS pobj
 |                       +-- the DT det
 |                       +-- various JJ amod
 |                       +-- data NNS nn
 +-- . . punct

11
Input: For the unigram language model , the smoothing parameter was trained .
Parse:
trained VBN ROOT
 +-- For IN prep
 |   +-- model NN pobj
 |       +-- the DT det
 |       +-- language NN nn
 |           +-- unigram NN nn
 +-- , , punct
 +-- parameter NN nsubjpass
 |   +-- the DT det
 |   +-- smoothing VBG amod
 +-- was VBD auxpass
 +-- . . punct

12
Input: For the MRF model , we train the model parameters -LRB- i.e .
Parse:
train VBP ROOT
 +-- For IN prep
 |   +-- model NN pobj
 |       +-- the DT det
 |       +-- MRF NNP nn
 +-- , , punct
 +-- we PRP nsubj
 +-- parameters NNS dobj
 |   +-- the DT det
 |   +-- model NN nn
 |   +-- -LRB- -LRB- punct
 |   +-- i.e NN dep
 +-- . . punct
