
1
Input: Following the standard machine learning setup , our goal is to learn a function h
Parse:
is VBZ ROOT
 +-- Following VBG prep
 |   +-- setup NN pobj
 |       +-- the DT det
 |       +-- standard JJ amod
 |       +-- learning VBG nn
 |           +-- machine NN nn
 +-- , , punct
 +-- goal NN nsubj
 |   +-- our PRP$ poss
 +-- learn VB xcomp
 |   +-- to TO aux
 |   +-- function NN dobj
 |       +-- a DT det
 +-- h . punct

2
Input: In order to quantify the quality of a prediction , ? y = h -LRB- x -RRB- , we will consider a loss function ?
Parse:
y FW ROOT
 +-- In IN prep
 |   +-- order NN pobj
 |       +-- quantify VB infmod
 |           +-- to TO aux
 |           +-- quality NN dobj
 |               +-- the DT det
 |               +-- of IN prep
 |                   +-- prediction NN pobj
 |                       +-- a DT det
 +-- , , punct
 +-- ? . punct
 +-- h NNP dep
 |   +-- = SYM nn
 +-- consider VB dep
     +-- -LRB- -LRB- punct
     +-- x NFP punct
     +-- -RRB- -RRB- punct
     +-- , , punct
     +-- we PRP nsubj
     +-- will MD aux
     +-- function NN dobj
         +-- a DT det
         +-- loss NN nn

3
Input: ? -LRB- y , ? y -RRB- quantifies the penalty for making prediction ? y if the correct output is y .
Parse:
quantifies VBZ ROOT
 +-- ? . punct
 +-- -LRB- -LRB- punct
 +-- y UH discourse
 +-- , , punct
 +-- ? , punct
 +-- y NFP punct
 +-- -RRB- -RRB- punct
 +-- penalty NN dobj
 |   +-- the DT det
 |   +-- for IN prep
 |       +-- making VBG pcomp
 |           +-- prediction NN dobj
 +-- y : punct
 +-- y NNP advcl
 |   +-- if IN mark
 |   +-- output NN nsubj
 |   |   +-- the DT det
 |   |   +-- correct JJ amod
 |   +-- is VBZ cop
 +-- . . punct

4
Input: The loss function allows us to incorporate specific performance measures , which we will exploit 1 http
Parse:
allows VBZ ROOT
 +-- function NN nsubj
 |   +-- The DT det
 |   +-- loss NN nn
 +-- incorporate VB xcomp
     +-- us PRP nsubj
     +-- to TO aux
     +-- measures NNS dobj
         +-- specific JJ amod
         +-- performance NN nn
         +-- , , punct
         +-- exploit VB rcmod
             +-- which WDT dobj
             +-- we PRP nsubj
             +-- will MD aux
             +-- 1 CD prep
                 +-- http ADD dep

5
Input: We restrict ourselves to the supervised learning scenario , where input output pairs -LRB- x , y -RRB- are available for training and are assumed to come from some fixed distribution P -LRB- x , y -RRB- .
Parse:
restrict VBP ROOT
 +-- We PRP nsubj
 +-- ourselves PRP dobj
 +-- to IN prep
 |   +-- scenario NN pobj
 |       +-- the DT det
 |       +-- supervised JJ amod
 |       +-- learning VBG nn
 |       +-- , , punct
 |       +-- available JJ rcmod
 |           +-- where WRB advmod
 |           +-- pairs NNS nsubj
 |           |   +-- input NN nn
 |           |   +-- output NN nn
 |           |   +-- -LRB- -LRB- punct
 |           |   +-- y NN dep
 |           |   |   +-- x UH dep
 |           |   |   +-- , , punct
 |           |   +-- -RRB- -RRB- punct
 |           +-- are VBP cop
 |           +-- for IN prep
 |           |   +-- training NN pobj
 |           +-- and CC cc
 |           +-- assumed VBN conj
 |           |   +-- are VBP auxpass
 |           |   +-- come VB xcomp
 |           |       +-- to TO aux
 |           |       +-- from IN prep
 |           |           +-- P NN pobj
 |           |               +-- some DT det
 |           |               +-- fixed VBN amod
 |           |               +-- distribution NN nn
 |           |               +-- -LRB- -LRB- punct
 |           |               +-- x NFP punct
 |           |               +-- , , punct
 |           |               +-- y NNP appos
 |           +-- -RRB- -RRB- punct
 +-- . . punct
