
1
Input: Encouraged by the initial experimental results , we explored two further optimization of the basic algorithm .
Parse:
explored VBD ROOT
 +-- Encouraged VBN partmod
 |   +-- by IN prep
 |       +-- results NNS pobj
 |           +-- the DT det
 |           +-- initial JJ amod
 |           +-- experimental JJ amod
 +-- , , punct
 +-- we PRP nsubj
 +-- optimization NN dobj
 |   +-- two CD num
 |   +-- further JJ amod
 |   +-- of IN prep
 |       +-- algorithm NN pobj
 |           +-- the DT det
 |           +-- basic JJ amod
 +-- . . punct

2
Input: 5.1 Weighting Interesting Terms The word trivia refer to tidbits of unimportant or uncommon information .
Parse:
Terms NNS ROOT
 +-- 5.1 CD num
 +-- Weighting VBG amod
 +-- Interesting NNP amod
 +-- word NN dep
 |   +-- The DT det
 |   +-- refer VBP rcmod
 |       +-- trivia NNS nsubj
 |       +-- to IN prep
 |           +-- tidbits NNS pobj
 |               +-- of IN prep
 |                   +-- information NN pobj
 |                       +-- unimportant JJ amod
 |                           +-- or CC cc
 |                           +-- uncommon JJ conj
 +-- . . punct

3
Input: As we have noted , interesting nuggets often has a trivialike quality that makes them of interest to human beings .
Parse:
has VBZ ROOT
 +-- noted VBN advcl
 |   +-- As IN mark
 |   +-- we PRP nsubj
 |   +-- have VBP aux
 +-- , , punct
 +-- nuggets NNS nsubj
 |   +-- interesting JJ amod
 +-- often RB advmod
 +-- quality NN dobj
 |   +-- a DT det
 |   +-- trivialike JJ amod
 |   +-- makes VBZ rcmod
 |       +-- that WDT nsubj
 |       +-- them PRP dobj
 |       +-- of IN prep
 |           +-- interest NN pobj
 |               +-- to IN prep
 |                   +-- beings NNS pobj
 |                       +-- human JJ amod
 +-- . . punct

4
Input: From this description of interesting nuggets and trivia , we hypothesize that interesting nuggets are likely to occur rarely in a text corpora .
Parse:
hypothesize VBP ROOT
 +-- From IN prep
 |   +-- description NN pobj
 |       +-- this DT det
 |       +-- of IN prep
 |           +-- nuggets NNS pobj
 |               +-- interesting JJ amod
 |               +-- and CC cc
 |               +-- trivia NNS conj
 +-- , , punct
 +-- we PRP nsubj
 +-- likely JJ ccomp
 |   +-- that IN mark
 |   +-- nuggets NNS nsubj
 |   |   +-- interesting JJ amod
 |   +-- are VBP cop
 |   +-- occur VB xcomp
 |       +-- to TO aux
 |       +-- rarely RB advmod
 |       +-- in IN prep
 |           +-- corpora NN pobj
 |               +-- a DT det
 |               +-- text NN nn
 +-- . . punct

5
Input: There is a possibility that some low frequency terms may actually be important in identifying interesting nuggets .
Parse:
is VBZ ROOT
 +-- There EX expl
 +-- possibility NN nsubj
 |   +-- a DT det
 |   +-- important JJ ccomp
 |       +-- that IN mark
 |       +-- terms NNS nsubj
 |       |   +-- some DT det
 |       |   +-- frequency NN nn
 |       |       +-- low JJ amod
 |       +-- may MD aux
 |       +-- actually RB advmod
 |       +-- be VB cop
 |       +-- in IN prep
 |           +-- identifying VBG pcomp
 |               +-- nuggets NNS dobj
 |                   +-- interesting JJ amod
 +-- . . punct

6
Input: A standard unigram language model would not capture these low frequency terms as important terms .
Parse:
capture VB ROOT
 +-- model NN nsubj
 |   +-- A DT det
 |   +-- standard JJ amod
 |   +-- language NN nn
 |       +-- unigram NN nn
 +-- would MD aux
 +-- not RB neg
 +-- terms NNS dobj
 |   +-- these DT det
 |   +-- frequency NN nn
 |       +-- low JJ amod
 +-- as IN prep
 |   +-- terms NNS pobj
 |       +-- important JJ amod
 +-- . . punct

7
Input: To explore this possibility , we experimented with three different term weighting schemes that can provide more weight to certain low frequency terms .
Parse:
experimented VBD ROOT
 +-- explore VB advcl
 |   +-- To TO aux
 |   +-- possibility NN dobj
 |       +-- this DT det
 +-- , , punct
 +-- we PRP nsubj
 +-- with IN prep
 |   +-- schemes NNS pobj
 |       +-- three CD num
 |       +-- term NN nn
 |       |   +-- different JJ amod
 |       +-- weighting NN nn
 |       +-- provide VB rcmod
 |           +-- that WDT nsubj
 |           +-- can MD aux
 |           +-- weight NN dobj
 |           |   +-- more JJR amod
 |           +-- to IN prep
 |               +-- terms NNS pobj
 |                   +-- certain JJ amod
 |                   +-- frequency NN nn
 |                       +-- low JJ amod
 +-- . . punct

8
Input: The weighting schemes we considered include commonly used TFIDF , as well as information theoretic Kullback Leiber divergence and Jensen Shannon divergence -LRB- 8 -RRB- .
Parse:
include VBP ROOT
 +-- schemes NNS nsubj
 |   +-- The DT det
 |   +-- weighting NN nn
 |   +-- considered VBD rcmod
 |       +-- we PRP nsubj
 +-- TFIDF NN dobj
 |   +-- used VBN amod
 |   |   +-- commonly RB advmod
 |   +-- , , punct
 |   +-- well RB cc
 |   |   +-- as RB advmod
 |   |   +-- as IN mwe
 |   +-- divergence NN conj
 |       +-- information NN nn
 |       +-- theoretic JJ amod
 |       +-- Kullback NNP nn
 |       +-- Leiber NNP nn
 |       +-- and CC cc
 |       +-- divergence NN conj
 |       |   +-- Shannon NNP nn
 |       |       +-- Jensen NNP nn
 |       +-- -LRB- -LRB- punct
 |       +-- 8 CD dep
 |       +-- -RRB- -RRB- punct
 +-- . . punct
