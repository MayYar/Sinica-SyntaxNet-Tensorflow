(P ? I) + £fL; the matrix Q? according to Eq.(28); by properly discretize Q? .
Table 2
This is the dataset of the abstracts of technical reports published in the Department of Computer Science at a university .
The dataset contained 476 abstracts, which were divided into four research areas
WebKB .
The WebKB dataset contains webpages gathered from university computer science departments .
There are about 8280 documents and they are divided into 7 categories
The raw text is about 27MB .
Among these 7 categories, student, faculty, course and project are four most populous entity representing categories .
The associated subset is typically called WebKB4 .
Reuters .
The Reuters 21578 Text Categorization Test collection contains documents collected from the Reuters newswire in 1987 .
It is a standard text categorization benchmark and contains 135 categories .
In our experiments, we use a subset of the data collection which includes the 10 most frequent categories among the 135 topics and we call it Reuters top 10 .
WebACE .
The WebACE dataset was from WebACE project and has been used for document clustering [17][5] .
The WebACE dataset contains 2340 documents consisting news articles from Reuters new service via the Web in October 1997 .
These documents are divided into 20 classes .
News4 .
The News4 dataset used in our experiments are selected from the famous 20 newsgroups dataset5 .
The topic rec containing autos, motorcycles, baseball and hockey was selected from the version 20news 18828 .
The News4 dataset contains 3970 document vectors .
5 http
In all our experiments, we first select the top 1000 words by mutual information with class labels .
3.2 Evaluation Metrics In the experiments, we set the number of clusters equal to the true number of classes C for all the clustering algorithms .
To evaluate their performance, we compare the clusters generated by these algorithms with the true classes by computing the following two performance measures .
Clustering Accuracy (Acc) .
The first performance measure is the Clustering Accuracy, which discovers the one toone relationship between clusters and classes and measures the extent to which each cluster contained data points from the corresponding class .
It sums up the whole matching degree between all pair class clusters .
Clustering accuracy can be computed as
T(Ck, Lm) is the number of entities which belong to class m are assigned to cluster k .
Accuracy computes the maximum sum of T(Ck, Lm) for all pairs of clusters and classes, and these pairs have no overlaps .
The greater clustering accuracy means the better clustering performance .
Normalized Mutual Information .
Another evaluation metric we adopt here is the Normalized Mutual Information NMI [23], which is widely used for determining the quality of clusters .
For two random variable X and Y, the NMI is defined as
One can see that NMI(X, X) = 1, which is the maximal possible value of NMI .
Given a clustering result, the NMI in Eq.(30) is estimated as NMI = C k=1 C m=1 nk,mlog n¡Pnk,m nk ?nm C k=1 nklog nk n C m=1 ?nmlog ?nm n , (31) where nk denotes the number of data contained in the cluster Ck (1 k C), ?nm is the number of data belonging to the m th class (1 m C), and nk,m denotes the number of data that are in the intersection between the cluster Ck and the m th class .
The value calculated in Eq.(31) is used as a performance measure for the given clustering result .
The larger this value, the better the clustering performance .
3.3 Comparisons We have conducted comprehensive performance evaluations by testing our method and comparing it with 8 other representative data clustering methods using the same data corpora .
The algorithms that we evaluated are listed below. .
