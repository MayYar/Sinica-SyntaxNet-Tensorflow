Since our proposed algorithm is based on regression framework .
The most related work is optimal experimental design [1], including A Optimal Design, D Optimal Design, and EOptimal Design .
In this Section, we give a brief description of these approaches .
2.1 The Active Learning Problem The generic problem of active learning is the following .
Given a set of points A = {x1, x2, ¡P ¡P ¡P , xm} in Rd , find a subset B = {z1, z2, ¡P ¡P ¡P , zk} ? A which contains the most informative points .
In other words, the points zi(i = 1, ¡P ¡P ¡P , k) can improve the classifier the most if they are labeled and used as training points .
2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean .
Different observations have errors that are independent, but with equal variances £m2 .
We define f(x) = wT x to be the learner"s output given input x and the weight vector w .
Suppose we have a set of labeled sample points (z1, y1), ¡P ¡P ¡P , (zk, yk), where yi is the label of zi .
Thus, the maximum likelihood estimate for the weight vector, ?w, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi ? yi 2 (2) The estimate ?w gives us an estimate of the output at a novel input
By Gauss Markov theorem, we know that ?w ? w has a zero mean and a covariance matrix given by £m2 H?1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ?2 Jsse ?w2 = k i=1 zizT i = ZZT where Z = (z1, z2, ¡P ¡P ¡P , zk) .
The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are
? A optimal design
? E optimal design
Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A optimal design is more efficient than the other two .
Some recent work on experimental design can be found in [6], [16]. .
