Apocrita: A Distributed Peer-to-Peer File Sharing System 
content:
1 ABSTRACT :
1-1:Many organizations are required to author documents for various purposes, and such documents may need to be accessible by all member of the organization .
1-2:This access may be needed for editing or simply viewing a document .
1-3:In some cases these documents are shared between authors, via email, to be edited .
1-4:This can easily cause incorrect version to be sent or conflicts created between multiple users trying to make amendments to a document .
1-5:There may even be multiple different documents in the process of being edited .
1-6:The user may be required to search for a particular document, which some search tools such as Google Desktop may be a solution for local documents but will not find a document on another user"s machine .
1-7:Another problem arises when a document is made available on a user"s machine and that user is offline, in which case the document is no longer accessible .
1-8:In this paper we present Apocrita, a revolutionary distributed P2P file sharing system for Intranets .
1-9:C.2.4 [Computer Communication Networks]: Distributed .
2 INTRODUCTION :
2-1:The Peer to Peer (P2P) computing paradigm is becoming a completely new form of mutual resource sharing over the Internet .
2-2:With the increasingly common place broadband Internet access, P2P technology has finally become a viable way to share documents and media files .
2-3:There are already programs on the market that enable P2P file sharing .
2-4:These programs enable millions of users to share files among themselves .
2-5:While the utilization of P2P clients is already a gigantic step forward compared to downloading files off websites, using such programs are not without their problems .
2-6:The downloaded files still require a lot of manual management by the user .
2-7:The user still needs to put the files in the proper directory, manage files with multiple versions, delete the files when they are no longer wanted .
2-8:We strive to make the process of sharing documents within an Intranet easier .
2-9:Many organizations are required to author documents for various purposes, and such documents may need to be accessible by all members of the organization .
2-10:This access may be needed for editing or simply viewing a document .
2-11:In some cases these documents are sent between authors, via email, to be edited .
2-12:This can easily cause incorrect version to be sent or conflicts created between multiple users trying to make amendments to a document .
2-13:There may even be multiple different documents in the process of being edited .
2-14:The user may be required to search for a particular document, which some search tools such as Google Desktop may be a solution for local documents but will not find a document on another user"s machine .
2-15:Furthermore, some organizations do not have a file sharing server or the necessary network infrastructure to enable one .
2-16:In this paper we present Apocrita, which is a cost effective distributed P2P file sharing system for such organizations .
2-17:The rest of this paper is organized as follows .
2-18:In section 2, we present Apocrita .
2-19:The distributed indexing mechanism and protocol are presented in Section 3 .
2-20:Section 4 presents the peer to peer distribution model .
2-21:A proof of concept prototype is presented in Section 5, and performance evaluations are discussed in Section 6 .
2-22:Related work is presented is Section 7, and finally conclusions and future work are discussed in Section 8. .
3 APOCRITA :
3-1:Apocrita is a distributed peer to peer file sharing system, and has been designed to make finding documents easier in an Intranet environment .
3-2:Currently, it is possible for documents to be located on a user's machine or on a remote machine .
3-3:It is even possible that different revisions could reside on each node on the Intranet .
3-4:This means there must be a manual process to maintain document versions .
3-5:Apocrita solves this problem using two approaches .
3-6:First, due to the inherent nature of Apocrita, the document will only reside on a single logical location .
3-7:Second, Apocrita provides a method of reverting to previous document versions .
3-8:Apocrita Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page .
3-9:To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and or a fee .
3-10:ACMSE"07, MARCH 23 24, 2007, WINSTON SALEM, NC, USA .
3-11:COPYRIGHT 2007 ACM 978 1 59593 629 5 07 0003 â€¦$5.00 .
3-12:174 will also distribute documents across multiple machines to ensure high availability of important documents .
3-13:For example, if a machine contains an important document and the machine is currently inaccessible, the system is capable of maintaining availability of the document through this distribution mechanism .
3-14:It provides a simple interface for searching and accessing files that may exist either locally or remotely .
3-15:The distributed nature of the documents is transparent to the user .
3-16:Apocrita supports a decentralized network model where the peers use a discovery protocol to determine peers .
3-17:Apocrita is intended for network users on an Intranet .
3-18:The main focus is organizations that may not have a network large enough to require a file server and supporting infrastructure .
3-19:It eliminates the need for documents to be manually shared between users while being edited and reduces the possibility of conflicting versions being distributed .
3-20:The system also provides some redundancy and in the event of a single machine failure, no important documents will be lost .
3-21:It is operating system independent, and easy to access through a web browser or through a standalone application .
3-22:To decrease the time required for indexing a large number of documents, the indexing process is distributed across available idle nodes .
3-23:Local and remote files should be easily accessible through a virtual mountable file system, providing transparency for users. .
4 DISTRIBUTED INDEXING :
4-1:Apocrita uses a distributed index for all the documents that are available on the Intranet .
4-2:Each node will contain part of the full index, and be aware of what part of the index each other node has .
4-3:A node will be able to contact each node that contains a unique portion of the index .
4-4:In addition, each node has a separate local index of its own documents .
4-5:But as discussed later, in the current implementation, each node has a copy of the entire index .
4-6:Indexing of the documents is distributed .
4-7:Therefore, if a node is in the process of indexing many documents, it will break up the work over the nodes .
4-8:Once a node"s local index is updated with the new documents, the distributed index will then be updated .
4-9:The current distributed indexing system consists of three separate modules: NodeController, FileSender, and NodeIndexer .
4-10:The responsibility of each module is discussed later in this section .
4-11:3.1 Indexing Protocol The protocol we have designed for the distributed indexing is depicted in Figure 1 .
4-12:Figure 1 .
4-13:Apocrita distributed indexing protocol .
4-14:IDLE QUERY: The IDLE QUERY is sent out from the initiating node to determine which other nodes may be able to help with the overall indexing process .
4-15:There are no parameters sent with the command .
4-16:The receiving node will respond with either a BUSY or IDLE command .
4-17:If the IDLE command is received, the initiating node will add the responding node to a list of available distributed indexing helpers .
4-18:In the case of a BUSY command being received, the responding node is ignored .
4-19:BUSY: Once a node received an IDL QUERY, it will determine whether it can be considered a candidate for distributed indexing .
4-20:This determination is based on the overall CPU usage of the node .
4-21:If the node is using most of its CPU for other processes, the node will respond to the IDLE QUERY with a BUSY command .
4-22:IDLE: As with the case of the BUSY response, the node receiving the IDLE QUERY will determine its eligibility for distributed indexing .
4-23:To be considered a candidate for distributed indexing, the overall CPU usage must be at a minimum to all for dedicated indexing of the distributed documents .
4-24:If this is the case, the node will respond with an IDLE command .
4-25:INCOMING FILE: Once the initiating node assembles a set of idle nodes to assist with the distributed indexing, it will divide the documents to be sent to the nodes .
4-26:To do this, it sends an INCOMING FILE message, which contains the name of the file as well as the size in bytes .
4-27:After the INCOMING FILE command has been sent, the initiating node will begin to stream the file to the other node .
4-28:The initiating node will loop through the files that are to be sent to the other node; each file stream being preceded by the INCOMING FILE command with the appropriate parameters .
4-29:INDEX FILE: Once the indexing node has completed the indexing process of the set of files, it must send the resultant index back to the initiating node .
4-30:The index is comprised of multiple files, which exist on the file system of the indexing node .
4-31:As with the INCOMING FILE command, the indexing node streams each index file after sending an INDEX FILE command .
4-32:The INDEX FILE command has two parameters: the first being the name of the index, and the second is the size of the file in bytes .
4-33:SEND COMPLETE: When sending the sets of files for both the index and the files to be indexed, the node must notify the corresponding node when the process is complete .
4-34:Once the initiating node is finished sending the set of documents to be indexed, it will then send a SEND COMPLETE command indicating to the indexing node that there are no more files and the node can proceed with indexing the files .
4-35:In the case of the initiating node sending the index files, the indexing node will complete the transfer with the SEND COMPLETE command indicating to the initiating node that there are no more index files to be sent and the initiating node can then assemble those index files into the main index .
4-36:The NodeController is responsible for setting up connections with nodes in the idle state to distribute the indexing process .
4-37:Using JXTA [5], the node controller will obtain a set of nodes .
4-38:This set of nodes is iterated and each one is sent the IDLE QUERY command .
4-39:The nodes that respond with idle are then collected .
4-40:The set of idle nodes includes the node initiating the distributed indexing process, referred to as the local node .
4-41:Once the collection of idle nodes is obtained, the node updates the set of controllers and evenly divides the set of documents that are to be indexed .
4-42:For example, if there are 100 documents and 10 nodes (including the local node) then each node will have 10 documents to index .
4-43:For each indexing node an instance of the FileSender object is created .
4-44:The FileSender is aware of the set of documents that node is responsible for .
4-45:Once a FileSender object has been created for each node, the NodeController waits for each FileSender to complete .
4-46:When the FileSender objects have completed the NodeController will take the resultant indexes from 175 each node and pass them to an instance of the IndexCompiler, which maintains the index and the list of FileSenders .
4-47:Once the IndexCompiler has completed it will return to the idle state and activate the directory scanner to monitor the locally owned set of documents for changes that may require reindexing .
4-48:The NodeIndexer is responsible for receiving documents sent to it by the initiating node and then indexing them using the Lucene engine [7] .
4-49:Once the indexing is complete the resulting index is streamed back to the initiating node as well as compiled in the indexer nodes own local index .
4-50:Before initiating the indexing process it must be sent an IDLE QUERY message .
4-51:This is the first command that sets off the indexing process .
4-52:The indexer node will determine whether it is considered idle based on the current CPU usage .
4-53:As outlined in the protocol section if the node is not being used and has a low overall CPU usage percentage it will return IDLE to the IDLE QUERY command .
4-54:If the indexer nodes CPU usage is above 50% for a specified amount of time it is then considered to be busy and will respond to the IDLE QUERY command with BUSY .
4-55:If a node is determined busy it returns to its listening state waiting for another IDLE QUERY from another initiating node .
4-56:If the node is determined to be idle it will enter the state where it will receive files from the initiating node that it is responsible for indexing .
4-57:Once all of the files are received by the initiating node, indicated by a SEND COMPLETE message, it starts an instance of the Lucene indexing engine .
4-58:The files are stored in a temporary directory separate from the nodes local documents that it is responsible for maintaining an index of .
4-59:The Lucene index writer then indexes all of the transferred files .
4-60:The index is stored on the drive within a temporary directory separate from the current index .
4-61:After the indexing of the files completes the indexer node enters the state where the index files are sent back to the initiating node .
4-62:The indexer node loops through all of the files created by Lucene"s IndexWriter and streams them to the initiating node .
4-63:Once these files are sent back that index is then merged into the indexer nodes own full index of the existing files .
4-64:It then enters the idle state where it will then listen for any other nodes that required distributing the indexing process .
4-65:The FileSender object is the initiating node equivalent of the indexer node .
4-66:It initiates the communication between the initiating node and the node that will assist in the distributed indexing .
4-67:The initiating node runs many instances of the FileSender node one for each other node it has determined to be idle .
4-68:Upon instantiation of the FileSender it is passed the node that it is responsible for contacting and the set of files that must be sent .
4-69:The FileSender"s first job is to send the files that are to be indexed by the other idle node .
4-70:The files are streamed one at a time to the other node .
4-71:It sends each file using the INCOMING FILE command .
4-72:With that command it sends the name of the file being sent and the size in bytes .
4-73:Once all files have been sent the FileSender sends the SEND COMPLETE command .
4-74:The FileSender creates an instance of Lucene"s IndexWriter and prepares to create the index in a temporary directory on the file system .
4-75:The FileSender will begin to receive the files that are to be saved within the index .
4-76:It receives an INDEX FILE command with the name of the files and the size in bytes .
4-77:This file is then streamed into the temporary index directory on the FileSender node .
4-78:After the transfer of the index files has been completed the FileSender notifies the instance of the index compiler that it is ready to combine the index .
4-79:Each instance of the FileSender has its own unique section of temporary space to store the index that has been transferred back from the indexing node .
4-80:When notifying the IndexCompiler it will also pass the location of the particular FileSenders directory location of that index. .
5 PEER TO PEER DISTRIBUTION :
5-1:Apocrita uses a peer to peer distribution model in order to distribute files .
5-2:Files are distributed solely from a serving node to a client node without regard for the availability of file pieces from other clients in the network .
5-3:This means that the file transfers will be fast and efficient and should not severely affect the usability of serving nodes from the point of view of a local user .
5-4:The JXTA framework [5] is used in order to implement peer to peer functionality .
5-5:This has been decided due to the extremely shorttimeline of the project which allows us to take advantage of over five years of testing and development and support from many large organizations employing JXTA in their own products .
5-6:We are not concerned with any potential quality problems because JXTA is considered to be the most mature and stable peer to peer framework available .
5-7:Using JXTA terminology, there are three types of peers used in node classification .
5-8:Edge peers are typically low bandwidth, non dedicated nodes .
5-9:Due to these characteristics, edge peers are not used with Apocrita .
5-10:Relay peers are typically higher bandwidth, dedicated nodes .
5-11:This is the classification of all nodes in the Apocrita network, and, as such, are the default classification used .
5-12:Rendezvous peers are used to coordinate message passing between nodes in the Apocrita network .
5-13:This means that a minimum of one rendezvous peer per subnet is required .
5-14:4.1 Peer Discovery The Apocrita server subsystem uses the JXTA Peer Discovery Protocol in order to find participating peers within the network as shown in Figure 2 .
5-15:Figure 2 .
5-16:Apocrita peer discovery process .
5-17:176 The PDP listens for peer advertisements from other nodes in the Apocrita swarm .
5-18:If a peer advertisement is detected, the server will attempt to join the peer group and start actively contributing to the network .
5-19:If no peers are found by the discovery service, the server will create a new peer group and start advertising this peer group .
5-20:This new peer group will be periodically advertised on the network; any new peers joining the network will attach to this peer group .
5-21:A distinct advantage of using the JXTA PDP is that Apocrita does not have to be sensitive to particular networking nuances such as Maximum Transmission Unit .
5-22:In addition, Apocrita does not have to support one to many packet delivery methods such as multicast and instead can rely on JXTA for this support .
5-23:4.2 Index Query Operation All nodes in the Apocrita swarm have a complete and up to date copy of the network index stored locally .
5-24:This makes querying the index for search results trivial .
5-25:Unlike the Gnutella protocol, a query does not have to propagate throughout the network .
5-26:This also means that the time to return query results is very fast much faster than protocols that rely on nodes in the network to pass the query throughout the network and then wait for results .
5-27:This is demonstrated in Figure 3 .
5-28:Figure 3 .
5-29:Apocrita query operation .
5-30:Each document in the swarm has a unique document identification number .
5-31:A node will query the index and a result will be returned with both the document ID number as well as a list of peers with a copy of the matched document ID .
5-32:It is then the responsibility of the searching peer to contact the peers in the list to negotiate file transfer between the client and server. .
6 PROTOTYPE IMPLEMENTATION :
6-1:Apocrita uses the Lucene framework [7], which is a project under development by the Apache Software Foundation .
6-2:Apache Lucene is a high performance, full featured text search engine library written entirely in Java .
6-3:In the current implementation, Apocrita is only capable of indexing plain text documents .
6-4:Apocrita uses the JXTA framework [5] as a peer to peer transport library between nodes .
6-5:JXTA is used to pass both messages and files between nodes in the search network .
6-6:By using JXTA, Apocrita takes advantage of a reliable, and proven peer to peer transport mechanism .
6-7:It uses the pipe facility in order to pass messages and files between nodes .
6-8:The pipe facility provides many different types of pipe advertisements .
6-9:This includes an unsecured unicast pipe, a secured unicast pipe, and a propagated unsecured pipe .
6-10:Message passing is used to pass status messages between nodes in order to aid in indexing, searching, and retrieval .
6-11:For example, a node attempting to find an idle node to participate in indexing will query nodes via the message facility .
6-12:Idle nodes will reply with a status message to indicate they are available to start indexing .
6-13:File passing is used within Apocrita for file transfer .
6-14:After a file has been searched for and located within the peer group, a JXTA socket will be opened and file transfer will take place .
6-15:A JXTA socket is similar to a standard Java socket, however a JXTA socket uses JXTA pipes in underlying network transport .
6-16:File passing uses an unsecured unicast pipe in order to transfer data .
6-17:File passing is also used within Apocrita for index transfer .
6-18:Index transfer works exactly like a file transfer .
6-19:In fact, the index transfer actually passes the index as a file .
6-20:However, there is one key difference between file transfer and index transfer .
6-21:In the case of file transfer, a socket is created between only two nodes .
6-22:In the case of index transfer, a socket must be created between all nodes in the network in order to pass the index, which allows for all nodes to have a full and complete index of the entire network .
6-23:In order to facilitate this transfer efficiently, index transfer will use an unsecured propagated pipe to communicate with all nodes in the Apocrita network. .
7 PERFORMANCE EVALUATION :
7-1:It is difficult to objectively benchmark the results obtained through Apocrita because there is no other system currently available with the same goals as Apocrita .
7-2:We have, however, evaluated the performance of the critical sections of the system .
7-3:The critical sections were determined to be the processes that are the most time intensive .
7-4:The evaluation was completed on standard lab computers on a 100Mb s Ethernet LAN; the machines run Windows XP with a Pentium 4 CPU running at 2.4GHz with 512 MB of RAM .
7-5:The indexing time has been run against both: the Time Magazine collection [8], which contains 432 documents and 83 queries and their most relevant results, and the NPL collection [8] that has a total of 11,429 documents and 93 queries with expected results .
7-6:Each document ranges in size between 4KB and 8KB .
7-7:As Figure 4 demonstrates, the number of nodes involved in the indexing process affects the time taken to complete the indexing processsometimes even drastically .
7-8:Figure 4 .
7-9:Node vs .
7-10:index time .
7-11:The difference in going from one indexing node to two indexing nodes is the most drastic and equates to an indexing time 37% faster than a single indexing node .
7-12:The different between two 177 indexing nodes and three indexing nodes is still significant and represents a 16% faster time than two indexing nodes .
7-13:As the number of indexing nodes increases the results are less dramatic .
7-14:This can be attributed to the time overhead associated with having many nodes perform indexing .
7-15:The time needed to communicate with a node is constant, so as the number of nodes increases, this constant becomes more prevalent .
7-16:Also, the complexity of joining the indexing results is a complex operation and is complicated further as the number of indexing nodes increases .
7-17:Socket performance is also a very important part of Apocrita .
7-18:Benchmarks were performed using a 65MB file on a system with both the client and server running locally .
7-19:This was done to isolate possible network issues .
7-20:Although less drastic, similar results were shown when the client and server run on independent hardware .
7-21:In order to mitigate possible unexpected errors, each test was run 10 times .
7-22:Figure 5 .
7-23:Java sockets vs .
7-24:JXTA sockets .
7-25:As Figure 5 demonstrates, the performance of JXTA sockets is abysmal as compared to the performance of standard Java sockets .
7-26:The minimum transfer rate obtained using Java sockets is 81,945KB s while the minimum transfer rater obtained using JXTA sockets is much lower at 3, 805KB s .
7-27:The maximum transfer rater obtain using Java sockets is 97,412KB s while the maximum transfer rate obtained using JXTA sockets is 5,530KB s .
7-28:Finally, the average transfer rate using Java sockets is 87,540KB s while the average transfer rate using JXTA sockets is 4,293KB s .
7-29:The major problem found in these benchmarks is that the underlying network transport mechanism does not perform as quickly or efficiently as expected .
7-30:In order to garner a performance increase, the JXTA framework needs to be substituted with a more traditional approach .
7-31:The indexing time is also a bottleneck and will need to be improved for the overall quality of Apocrita to be improved. .
8 RELATED WORK :
8-1:Several decentralized P2P systems [1, 2, 3] exist today that Apocrita features some of their functionality .
8-2:However, Apocrita also has unique novel searching and indexing features that make this system unique .
8-3:For example, Majestic 12 [4] is a distributed search and indexing project designed for searching the Internet .
8-4:Each user would install a client, which is responsible for indexing a portion of the web .
8-5:A central area for querying the index is available on the Majestic 12 web page .
8-6:The index itself is not distributed, only the act of indexing is distributed .
8-7:The distributed indexing aspect of this project most closely relates Apocrita goals .
8-8:YaCy [6] is a peer to peer web search application .
8-9:YaCy consists of a web crawler, an indexer, a built in database engine, and a p2p index exchange protocol .
8-10:YaCy is designed to maintain a distributed index of the Internet .
8-11:It used a distributed hash table to maintain the index .
8-12:The local node is used to query but all results that are returned are accessible on the Internet .
8-13:YaCy used many peers and DHT to maintain a distributed index .
8-14:Apocrita will also use a distributed index in future implementations and may benefit from using an implementation of a DHT .
8-15:YaCy however, is designed as a web search engine and, as such solves a much different problem than Apocrita. .
9-1:We presented Apocrita, a distributed P2P searching and indexing system intended for network users on an Intranet
9-2:It can help organizations with no network file server or necessary network infrastructure to share documents
9-3:It eliminates the need for documents to be manually shared among users while being edited and reduce the possibility of conflicting versions being distributed
9-4:A proof of concept prototype has been constructed, but the results from measuring the network transport mechanism and the indexing time were not as impressive as initially envisioned
9-5:Despite these shortcomings, the experience gained from the design and implementation of Apocrita has given us more insight into building challenging distributed systems
9-6:For future work, Apocrita will have a smart content distribution model in which a single instance of a file can intelligently and transparently replicate throughout the network to ensure a copy of every important file will always be available regardless of the availability of specific nodes in the network
9-7:In addition, we plan to integrate a revision control system into the content distribution portion of Apocrita so that users could have the ability to update an existing file that they found and have the old revision maintained and the new revision propagated
9-8:Finally, the current implementation has some overhead and redundancy due to the fact that the entire index is maintained on each individual node, we plan to design a distributed index.
10-1:Rodrigues, R., Liskov, B., Shrira, L.: The Design of a Robust Peer to Peer System
10-2:Available online: http:  www.pmg.lcs.mit.edu ~rodrigo ew02 robust.pdf
10-3:Chawathe, Y., Ratnasamy, S., Breslau, L., Lanham, N., and Chenker, S.: Making Gnutella like P2P Systems Scalable
10-4:In Proceedings of SIGCOMM"03, Karlsruhe, Germany
10-5:Harvest: A Distributed Search System: http:  harvest.sourceforge.net
10-6:Majestic 12: Distributed Search Engine: http:  www.majestic12.co.uk
10-7:JXTA: http:  www.jxta.org
10-8:YaCy: Distributed P2P based Web Indexing: http:  www.yacy.net yacy
10-9:Lucene Search Engine Library: http:  lucene.apache.org
10-10:Test Collections (Time Magazine and NPL): www.dcs.gla.ac.uk idom ir_resources test_collections
10-11:178
picture:
