Collaboration Among a Satellite Swarm 
content:
1 ABSTRACT :
1-1:The paper deals with on board planning for a satellite swarm via communication and negotiation .
1-2:We aim at defining individual behaviours that result in a global behaviour that meets the mission requirements .
1-3:We will present the formalization of the problem, a communication protocol, a solving method based on reactive decision rules, and first results .
1-4:H.4 [Information Systems Applications]: Miscellaneous; .
2 INTRODUCTION :
2-1:Much research has been undertaken to increase satellite autonomy such as enabling them to solve by themselves problems that may occur during a mission, adapting their behaviour to new events and transferring planning on board ; even if the development cost of such a satellite is increased, there is an increase in performance and mission possibilities [34] .
2-2:Moreover, the use of satellite swarms sets of satellites flying in formation or in constellation around the Earthmakes it possible to consider joint activities, to distribute skills and to ensure robustness .
2-3:Multi agent architectures have been developed for satellite swarms [36, 38, 42] but strong assumptions on deliberation and communication capabilities are made in order to build a collective plan .
2-4:Mono agent planning [4, 18, 28] and task allocation [20] are widely studied .
2-5:In a multi agent context, agents that build a collective plan must be able to change their goals, reallocate resources and react to environment changes and to the others" choices .
2-6:A coordination step must be added to the planning step [40, 30, 11] .
2-7:However, this step needs high communication and computation capabilities .
2-8:For instance, coalition based [37], contract based [35] and all negotiationbased [25] mechanisms need these capabilities, especially in dynamic environments .
2-9:In order to relax communication constraints, coordination based on norms and conventions [16] or strategies [17] are considered .
2-10:Norms constraint agents in their decisions in such a way that the possibilities of conflicts are reduced .
2-11:Strategies are private decision rules that allow an agent to draw benefit from the knowledgeable world without communication .
2-12:However, communication is still needed in order to share information and build collective conjectures and plans .
2-13:Communication can be achieved through a stigmergic approach (via the environment) or through message exchange and a protocol .
2-14:A protocol defines interactions between agents and cannot be uncoupled from its goal, e.g .
2-15:exchanging information, finding a trade off, allocating tasks and so on .
2-16:Protocols can be viewed as an abstraction of an interaction [9] .
2-17:They may be represented in a variety of ways, e.g .
2-18:AUML [32] or Petri nets [23] .
2-19:As protocols are originally designed for a single goal, some works aim at endowing them with flexibility [8, 26] .
2-20:However, an agent cannot always communicate with another agent or the communication possibilites are restricted to short time intervals .
2-21:The objective of this work is to use intersatellite connections, called InterSatellite Links or ISL, in an Earth observation constellation inspired from the Fuego mission [13, 19], in order to increase the system reactivity and to improve the mission global return through a hybrid agent approach .
2-22:At the individual level, agents are deliberative in order to create a local plan but at the collective level, they use normative decision rules in order to coordinate with one another .
2-23:We will present the features of our problem, a communication protocol, a method for request allocation and finally, collaboration strategies .
2-24:287 978 81 904262 7 5 c 2007 IFAAMAS .
3 PROBLEM FEATURES :
3-1:An observation satellite constellation is a set of satellites in various orbits whose mission is to take pictures of various areas on the Earth surface, for example hot points corresponding to volcanos or forest fires .
3-2:The ground sends the constellation observation requests characterized by their geographical positions, priorities specifying if the requests are urgent or not, the desired dates of observation and the desired dates for data downloading .
3-3:The satellites are equipped with a single observation instrument whose mirror can roll to shift the line of sight .
3-4:A minimum duration is necessary to move the mirror, so requests that are too close together cannot be realized by the same satellite .
3-5:The satellites are also equipped with a detection instrument pointed forward that detects hot points and generates observation requests on board .
3-6:The constellations that we consider are such as the orbits of the various satellites meet around the poles .
3-7:A judicious positioning of the satellites in their orbits makes it possible to consider that two (or more) satellites meet in the polar areas, and thus can communicate without the ground intervention .
3-8:Intuitively, intersatellite communication increases the reactivity of the constellation since each satellite is within direct view of a ground station (and thus can communicate with it) only 10 % of the time .
3-9:The features of the problem are the following: 3 to 20 satellites in the constellation; pair communication around the poles; no ground intervention during the planning process; asynchronous requests with various priorities. .
4 A MULTI AGENT APPROACH :
4-1:As each satellite is a single entity that is a piece of the global swarm, a multi agent system fits to model satellite constellations [39] .
4-2:This approach has been developped through the ObjectAgent architecture [38], TeamAgent [31], DIPS [14] or Prospecting ANTS [12] .
4-3:3.1 Satellite swarm An observation satellite swarm1 is a multi agent system where the requests do not have to be carried out in a fixed order and the agents (the satellites) do not have any physical interaction .
4-4:Carrying out a request cannot prevent another agent from carrying out another one, even the same one .
4-5:At most, there will be a waste of resources .
4-6:Formally, a swarm is defined as follows: Definition 1 (Swarm) .
4-7:A satellite swarm E is a triplet < S, T, Vicinity >: S is a set of n agents {s1 .
4-8:.
4-9:.
4-10:sn}; T ⊆ R+ or N+ is a set of dates with a total order <; Vicinity : S × T → 2S .
4-11:In the sequel, we will assume that the agents share a common clock .
4-12:For a given agent and a given time, the vicinity relation returns the set of agents with whom it can communicate at that time .
4-13:As we have seen previously, this relation exists when the agents meet .
4-14:1 This term will designate a satellite constellation with InterSatellite Links .
4-15:3.2 Requests Requests are the observation tasks that the satellite swarm must achieve .
4-16:As we have seen previously, the requests are generated both on the ground and on board .
4-17:Each agent is allocated a set of initial requests .
4-18:During the mission, new requests are sent to the agents by the ground or agents can generate new requests by themselves .
4-19:Formally, a request is defined as follows: Definition 2 (Request) .
4-20:A request R is defined as a tuple < idR, pos(R), prio(R), tbeg(R),bR >: idR is an identifier; pos(R) is the geographic position of R; prio(R) ∈ R is the request priority; tbeg(R) ∈ T is the desired date of observation; bR ∈ {true, false} specifies if R has been realized .
4-21:The priority prio(R) of a request represents how much it is important for the user, namely the request sender, that the request should be carried out .
4-22:Thus a request with a high priority must be realized at all costs .
4-23:In our application, priorities are comprised between 1 and 5 (the highest) .
4-24:In the sequel, we will note Rt si the set of the requests that are known by agent si at time t ∈ T .
4-25:For each request R in Rt si , there is a cost value, noted costsi ∈ R, representing how far from the desired date of observation tbeg(R) an agent si can realize R .
4-26:So, the more an agent can carry out a request in the vicinity of the desired date of observation, the lower the cost value .
4-27:3.3 Candidacy An agent may have several intentions about a request, i.e .
4-28:for a request R, an agent si may: propose to carry out R : si may realize R; commit to carry out R : si will realize R; not propose to carry out R : si may not realize R; refuse to carry out R : si will not realize R .
4-29:We can notice that these four propositions are modalities of proposition C: si realizes R: 3C means that si proposes to carry out R; 2C means that si commits to carry out R; ¬3C means that si does not propose to carry out R; ¬2C means that si refuses to carry out R .
4-30:More formally: Definition 3 (Candidacy) .
4-31:A candidacy C is a tuple < idC , modC, sC , RC , obsC, dnlC >: idC is an identifier; modC ∈ {3, 2, ¬3, ¬2} is a modality; sC ∈ S is the candidate agent; RC ∈ Rt sC is the request on which sC candidates; obsC ∈ T is the realization date proposed by sC ; dnlC ∈ T is the download date .
4-32:3.4 Problem formalization Then, our problem is the following: we would like each agent to build request allocations (i.e a plan) dynamically such as if these requests are carried out their number is the highest possible or the global cost is minimal .
4-33:More formally, Definition 4 (Problem) .
4-34:Let E be a swarm .
4-35:Agents si in E must build a set {At s1 .
4-36:.
4-37:.
4-38:At sn } where At si ⊆ Rt si such 288 The Sixth Intl .
4-39:Joint Conf .
4-40:on Autonomous Agents and Multi Agent Systems (AAMAS 07) as: | S si∈S At si | is maximal; P si∈S P R∈At si prio(R) is maximal .
4-41:P si∈S P R∈At si costsi is minimal .
4-42:Let us notice that these criteria are not necessarily compatible .
4-43:As the choices of an agent will be influenced by the choices of the others, it is necessary that the agents should reason on a common knowledge about the requests .
4-44:It is thus necessary to set up an effective communication protocol. .
5 COMMUNICATION PROTOCOL :
5-1:Communication is commonly associated with cooperation .
5-2:Deliberative agents need communication to cooperate, whereas it is not necessarily the case for reactive agents [2, 41] .
5-3:Gossip protocols [22, 24], or epidemic protocols, are used to share knowledge with multicast .
5-4:Each agent selects a set of agents at a given time in order to share information .
5-5:The speed of information transmission is contingent upon the length of the discussion round .
5-6:4.1 The corridor metaphor The suggested protocol is inspired from what we name the corridor metaphor, which represents well the satellite swarm problem .
5-7:Various agents go to and fro in a corridor where objects to collect appear from time to time .
5-8:Two objects that are too close to each other cannot be collected by the same agent because the action takes some time and an agent cannot stop its movement .
5-9:In order to optimize the collection, the agents can communicate when they meet .
5-10:S 2 S ABel A 1 A 3S Figure 1: Time t 1 S 2S Bel non A 3S Figure 2: Time t Example 1 .
5-11:Let us suppose three agents, s1, s2, s3 and an object A to be collected .
5-12:At time t, s1 did not collect A and s2 does not know that A exists .
5-13:When s1 meets s2, it communicates the list of the objects it knows, that is to say It is not certain that A is still there because another agent may have passed before s2, but it can take it into account in its plan .
5-14:At time t , s3 collects A .
5-15:In the vicinity of s2, s3 communicates its list of objects and A is not in the list .
5-16:As both agents meet in a place where it is possible for s3 to have collected A, the object would have been in the list if it had not been collected .
5-17:s2 can thus believe that A does not exist anymore and can withdraw it from its plan .
5-18:4.2 Knowledge to communicate In order to build up their plans, agents need to know the current requests and the others agents" intentions .
5-19:For each agent two kinds of knowledge to maintain are defined: requests (Definition 2); candidacies (Definition 3) .
5-20:Definition 5 (Knowledge) .
5-21:Knowledge K is a tuple < data(K), SK , tK >: data(K) is a request R or a candidacy C; SK ⊆ S is the set of agents knowing K; tK ∈ T is a temporal timestamp .
5-22:In the sequel, we will note Kt si the knowledge of agent si at time t ∈ T .
5-23:4.3 An epidemic protocol From the corridor metaphor, we can define a communication protocol that benefits from all the communication opportunities .
5-24:An agent notifies any change within its knowledge and each agent must propagate these changes to its vicinity who update their knowledge bases and reiterate the process .
5-25:This protocol is a variant of epidemic protocols [22] inspired from the work on overhearing [27] .
5-26:Protocol 1 (Communication) .
5-27:Let si be an agent in S .
5-28:∀t ∈ T: ∀ sj ∈ Vicinity(si, t), si executes: .
6 ∀ K ∈ Kt :
6-1:si such as sj ∈ SK : sj with K .
7 sj acknowledges receipt of K to si. :
7-1:Two kinds of updates exist for an agent: an internal update from a knowledge modification by the agent itself; an external update from received knowledge .
7-2:For an internal update, updating K depends on data(K): a candidacy C is modified when its modality changes and a request R is modified when an agent realizes it .
7-3:When K is updated, the timestamp is updated too .
7-4:Protocol 2 (Internal update) .
7-5:Let si ∈ S be an agent .
7-6:An internal update from si at time t ∈ T is performed: when knowledge K is created; when data(K) is modified .
7-7:In both cases: .
8 tK ← t; :
8-1:.
9 SK ← {si}. :
9-1:For an external update, only the most recent knowledge K is taken into account because timestamps change only when data(K) is modified .
9-2:If K is already known, it is updated if the content or the set of agents knowing it have been modified .
9-3:If K is unknown, it is simply added to the agent"s knowledge .
9-4:Protocol 3 (External update) .
9-5:Let si be an agent and K the knowledge transmitted by agent sj .
9-6:∀ K ∈ K, the external update at time t ∈ T is defined as follows: .
10 if ∃ K ∈ Kt :
10-1:si such as iddata(K) = iddata(K ) then In space contexts, [5, 21, 6] present multi agent architectures for on board planning .
10-2:However, they assume high communication and computation capabilities [10] .
10-3:[13] relax these constraints by cleaving planning modules: on the first hand, satellites have a planner that builds plans on a large horizon and on the second hand, they have a decision module that enables them to choose to realize or not a planned observation .
10-4:In an uncertain environment such as the one of satellite swarms, it may be advantageous to delay the decision until the last moment (i.e .
10-5:the realization date), especially if there are several possibilities for a given request .
10-6:The main idea in contingency planning [15, 29] is to determine the nodes in the initial plan where the risks of failures are most important and to incrementally build contingency branches for these situations .
10-7:5.1 A deliberative approach Inspired from both approaches, we propose to build allocations made up of a set of unquestionable requests and a set of uncertain disjunctive requests on which a decision will be made at the end of the decision horizon .
10-8:This horizon corresponds to the request realization date .
10-9:Proposing such partial allocations allows conflicts to be solved locally without propagating them through the whole plan .
10-10:In order to build the agents" initial plans, let us assume that each agent is equipped with an on board planner .
10-11:A plan is defined as follows: Definition 6 (Plan) .
10-12:Let si be an agent, Rt si a set of requests and Ct si a set of candidacies .
10-13:Let us define three sets: the set of potential requests: Rp = {R ∈ Rt si |bR = false} the set of mandatory requests: Rm = {R ∈ Rp |∃C ∈ Ct si : modC = 2, sC = si, RC = R} the set of given up requests: Rg = {R ∈ Rp |∃C ∈ Ct si : modC = ¬2, sC = si, RC = R} A plan At si generated at time t ∈ T is a set of requests such as Rm ⊆ At si ⊆ Rp and ∃ R ∈ Rg such as R ∈ At si .
10-14:Building a plan generates candidacies .
10-15:Definition 7 (Generating candidacies) .
10-16:Let si be an agent and At1 si a (possibly empty) plan at time t1 .
10-17:Let At2 si be the plan generated at time t2 with t2 > t1 .
10-18:∀ R ∈ At1 si such as R ∈ At2 si , a candidacy C such as mod(C) = ¬3, sC = si and RC = R is generated; ∀ R ∈ At2 si such as R ∈ At1 si , a candidacy C such as mod(C) = 3, sC = si and RC = R is generated; Protocol 2 is used to update Kt1 si in Kt2 si .
10-19:290 The Sixth Intl .
10-20:Joint Conf .
10-21:on Autonomous Agents and Multi Agent Systems (AAMAS 07) 5.2 Conflicts When two agents compare their respective plans some conflicts may appear .
10-22:It is a matter of redundancies between allocations on a given request, i.e.: several agents stand as candidates to carry out this request .
10-23:Whereas such redundancies may sometimes be useful to ensure the realization of a request (the realization may fail, e.g .
10-24:because of clouds), it may also lead to a loss of opportunity .
10-25:Consequently, conflict has to be defined: Definition 8 (Conflict) .
10-26:Let si and sj be two agents with, at time t, candidacies Csi and Csj respectively (sCsi = si and sCsj = sj) .
10-27:si and sj are in conflict if and only if: RCsi = RCsj modCsi and modCsj ∈ {2, 3} Let us notice that the agents have the means to know whether they are in conflict with another one during the communication process .
10-28:Indeed, they exchange information not only concerning their own plan but also concerning what they know about the other agents" plans .
10-29:All the conflicts do not have the same strength, meaning that they can be solved with more or less difficulty according to the agents" communication capacities .
10-30:A conflict is soft when the concerned agents can communicate before one or the other carries out the request in question .
10-31:A conflict is hard when the agents cannot communicate before the realization of the request .
10-32:Definition 9 (Soft Hard conflict) .
10-33:Let si and sj (i < j) two agents in conflict with, at time t, candidacies Csi and Csj respectively (sCsi = si and sCsj = sj) .
10-34:If ∃ V ⊆ S such as V = {si .
10-35:.
10-36:.
10-37:sj} and if ∃ T ∈ T such as T = {ti−1 .
10-38:.
10-39:.
10-40:tj−1} (ti−1 = t) where: ∀ i ≤ k <j, sk+1 ∈ Vicinity(sk, tk) with tk < obsCsi , tk < obsCsj and tk ≥ tk−1 then the conflict is soft else it is hard .
10-41:A conflict is soft if it exists a chain of agents between the two agents in conflict such as information can propagate before both agents realize the request .
10-42:If this chain does not exist, it means that the agents in conflict cannot communicate directly or not .
10-43:Consequently, the conflict is hard .
10-44:In satellite swarms, the geographical positions of the requests are known as well as the satellite orbits .
10-45:So each agent is able to determine if a conflict is soft or hard .
10-46:We can define the conflict cardinality: Definition 10 (Conflict cardinality) .
10-47:Let si be an agent and R a request in conflict .
10-48:The conflict cardinality is cardc(R) = |{C ∈ Ct si |modC ∈ {2, 3}, CR = R}| .
10-49:The conflict cardinality corresponds to the number of agents that are candidates or committed to the same request .
10-50:Thus, a conflict has at least a cardinality of 2. .
11 COLLABORATION STRATEGIES :
11-1:In space contexts, communication time and agents" computing capacities are limited .
11-2:When they are in conflict, the agents must find a local agreement (instead of an expensive global agreement) by using the conflict in order to increase the number of realized requests, to decrease the time of mission return, to increase the quality of the pictures taken or to make sure that a request is carried out .
11-3:Example 2 .
11-4:Let us suppose a conflict on request R between agents si and sj .
11-5:We would like that the most expert agent, i.e .
11-6:the agent that can carry out the request under the best conditions, does it .
11-7:Let us suppose si is the expert .
11-8:si must allocate R to itself .
11-9:It remains to determine what sj must do: sj can either select a substitute for R in order to increase the number of requests potentially realized, or do nothing in order to preserve resources, or allocate R to itself to ensure redundancy .
11-10:Consequently, we can define collaboration strategies dedicated to conflict solving .
11-11:A strategy is a private (namely intrinsic to an agent) decision process that allows an agent to make a decision on a given object .
11-12:In our application, strategies specify what to do with redundancies .
11-13:6.1 Cost and expertise In our application, cost is linked to the realization dates .
11-14:Carrying out a request consumes the agents" resources (e.g.: on board energy, memory) .
11-15:Consequently, an observation has a cost for each agent which depends on when it is realized: the closer the realization date to the desired date of observation, the lower the cost .
11-16:Definition 11 (Cost) .
11-17:Let si be an agent .
11-18:The cost costsi (RC ) ∈ R to carry out a request RC according to a candidacy C is defined as: costsi (RC ) = |obsC − tbeg(RC)| .
11-19:From this cost notion, we can formally define an expert notion between two agents .
11-20:The expertise for an agent means it can realize the request at the lower cost .
11-21:Definition 12 (Expertise) .
11-22:Let si and sj ∈ S be two agents and R a request .
11-23:Agent si is an expert for R if and only if costsi ≤ costsj .
11-24:6.2 Soft conflict solving strategies Three strategies are proposed to solve a conflict .
11-25:The expert strategy means that the expert agent maintains its candidacy whereas the other one gives up .
11-26:The altruist strategy means that the agent that can download first3 , provided the cost increase is negligible, maintains its candidacy whereas the other one gives up .
11-27:The insurance strategy means that both agents maintain their candidacies in order to ensure redundancy .
11-28:Strategy 1 (Expert) .
11-29:Let si and sj be two agents in conflict on their respective candidacies Csi and Csj such as si is the expert agent .
11-30:The expert strategy is: modCsi = 2 and modCsj = ¬2 .
11-31:Strategy 2 (Altruist) .
11-32:Let si and sj be two agents in conflict on their respective candidacies Csi and Csj such as si is the expert agent .
11-33:Let ∈ R+ be a threshold on the cost increase .
11-34:The altruist strategy is : if dnlCsi > dnlCsj and |costsi − costsj (R)| < then modCsi = ¬2 and modCsj = 2 .
11-35:Strategy 3 (Insurance) .
11-36:Let si and sj be two agents in conflict on their respective candidacies Csi and Csj such as si is the expert agent .
11-37:Let α ∈ R be a priority threshold .
11-38:The insurance strategy is : if prio(R) cardc(R)−1 > α then modCsi = 3 and modCsj = 3 .
11-39:3 i.e .
11-40:the agent using memory resources during a shorter time .
11-41:The Sixth Intl .
11-42:Joint Conf .
11-43:on Autonomous Agents and Multi Agent Systems (AAMAS 07) 291 In the insurance strategy, redundancy triggering is adjusted by the conflict cardinality cardc(R) .
11-44:The reason is the following: the more redundancies on a given request, the less a new redundancy on this request is needed .
11-45:The three strategies are implemented in a negotiation protocol dedicated to soft conflicts .
11-46:The protocol is based on a subsumption architecture [7] on strategies: the insurance strategy (1) is the major strategy because it ensures redundancy for which the swarm is implemented .
11-47:Then the altruist strategy comes (2) in order to allocate the resources so as to enhance the mission return .
11-48:Finally, the expert strategy that does not have preconditions (3) enhances the cost of the plan .
11-49:Protocol 4 (Soft conflict solving) .
11-50:Let R be a request in a soft conflict between two agents, si and sj .
11-51:These agents have Csi and Csj for respective candidacies .
11-52:Let si be the expert agent .
11-53:Agents apply strategies as follows: .
12 insurance strategy (α) :
12-1:.
13 altruist strategy ( ) :
13-1:.
14 expert strategy :
14-1:The choice of parameters α and allows to adjust the protocol results .
14-2:For example, if = 0, the altruist strategy is never used .
14-3:6.3 Hard conflict solving strategies In case of a hard conflict, the agent that is not aware will necessarily realize the request (with success or not) .
14-4:Consequently, a redundancy is useful only if the other agent is more expert or if the priority of the request is high enough to need redundancy .
14-5:Therefore, we will use the insurance strategy (refer to Section 6.2) and define a competitive strategy .
14-6:The latter is defined for two agents, si and sj, in a hard conflict on a request R .
14-7:Let si be the agent that is aware of the conflict4 .
14-8:Strategy 4 (Competitive) .
14-9:Let λ ∈ R+ be an cost threshold .
14-10:The competitive strategy is: if costsi < costsj − λ then modCsi = 3 .
14-11:Protocol 5 (Hard conflict solving) .
14-12:Let si be an agent in a hard conflict with an agent sj on a request R .
14-13:si applies strategies as follows: .
15 insurance strategy (α) :
15-1:.
16 competitive strategy (λ) :
16-1:.
17 withdrawal : modCsi = ¬2 :
17-1:= ¬2 6.4 Generalization Although agents use pair communication, they may have information about several agents and conflict cardinality may be more than 2 .
17-2:Therefore, we define a k conflict as a conflict with a cardinality of k on a set of agents proposing or committing to realize the same request .
17-3:Formally, Definition 13 (k conflict) .
17-4:Let S = {s1 .
17-5:.
17-6:.
17-7:sk} be a set of agents with respective candidacies Cs1 .
17-8:.
17-9:.
17-10:Csk at time ∀1 ≤ i ≤ k, sCsi = si; !∃R such as ∀1 ≤ i ≤ k, RCsi = R; 4 i.e .
17-11:the agent that must make a decision on R .
17-12:∀1 ≤ i ≤ k, modCsi ∈ {2, 3} .
17-13:S is maximal (⊆) among the sets that satisfy these properties .
17-14:As previously, a k conflict can be soft or hard .
17-15:A k conflict is soft if each pair conflict in the k conflict is a soft conflict with respect to Definition 9 .
17-16:As conflicts bear on sets of agents, expertise is a total order on agents .
17-17:We define rank i expertise where the concerned agent is the ith expert .
17-18:In case of a soft k conflict, the rank i expert agent makes its decision with respect to the rank (i + 1) expert agent according to Protocol 4 .
17-19:The protocol is applied recursively and α and parameters are updated at each step in order to avoid cost explosion5 .
17-20:In case of a hard conflict, the set S of agents in conflict can be splitted in SS (the subset of agents in a soft conflict) and SH (the subset of unaware agents) .
17-21:Only agents in SS can take a decision and must adapt themselves to agents in SH .
17-22:The rank i expert agent in SS uses Protocol 5 on the whole set SH and the rank (i − 1) expert agent in SS .
17-23:If an agent in SS applies the competitive strategy all the others withdraws. .
18 EXPERIMENTS :
18-1:Satellite swarm simulations have been implemented in JAVA with the JADE platform [3] .
18-2:The on board planner is implemented with linear programming using ILOG CPLEX [1] .
18-3:The simulation scenario implements 3 satellites on 6hour orbits .
18-4:Two scenarios have been considered: the first one with a set of 40 requests with low mutual exclusion and conflict rate and the second one with a set of 74 requests with high mutual exclusion and conflict rate .
18-5:For each scenario, six simulations have been performed: one with centralized planning (all requests are planned by the ground station before the simulation), one where agents are isolated (they cannot communicate nor coordinate with one another), one informed simulation (agents only communicate requests) and three other simulations implementing the instanciated collaboration strategies (politics): neutral politics: α, and λ are set to average values; drastic politics: α and λ are set to higher values, i.e .
18-6:agents will ensure redundancy only if the priorities are high and, in case of a hard conflict, if the cost payoff is much higher; lax politics: α is set to a lower value, i.e .
18-7:redundancies are more frequent .
18-8:In the case of low mutual exclusion and conflict rate (Table 1), centralized and isolated simulations lead to the same number of observations, with the same average priorities .
18-9:Isolation leading to a lower cost is due to the high number of redundancies: many agents carry out the same request at different costs .
18-10:The informed simulation reduces the number of redundancies but sligthly increases the average cost for the same reason .
18-11:We can notice that the use of 5 For instance, the rank 1 expert agent withdraws due to the altruist strategy and the cost increases by in the worst case, then rank 2 expert agent withdraws due to the altruist strategy and the cost increases by in the worst case .
18-12:So the cost has increased by 2 in the worst case .
18-13:292 The Sixth Intl .
18-14:Joint Conf .
18-15:on Autonomous Agents and Multi Agent Systems (AAMAS 07) Simulation Observations Redundancies Messages Average priority Average cost Centralized 34 0 0 2.76 176.06 Isolated 34 21 0 2.76 160.88 Informed 34 6 457 2.65 165.21 Neutral politics 31 4 1056 2.71 191.16 Drastic politics 24 1 1025 2.71 177.42 Lax politics 33 5 1092 2.7 172.88 Table 1: Scenario 1 the 40 request simulation results Simulation Observations Redundancies Messages Average priority Average cost Centralized 59 0 0 2.95 162.88 Isolated 37 37 0 3.05 141.62 Informed 55 27 836 2.93 160.56 Neutral politics 48 25 1926 3.13 149.75 Drastic politics 43 21 1908 3.19 139.7 Lax politics 53 28 1960 3 154.02 Table 2: Scenario 2 the 74 request simulation results collaboration strategies allows the number of redundancies to be much more reduced but the number of observations decreases owing to the constraint created by commitments .
18-16:Furthermore, the average cost is increased too .
18-17:Nevertheless each avoided redundancy corresponds to saved resources to realize on board generated requests during the simulation .
18-18:In the case of high mutual exclusion and conflict rate (Table 2), noteworthy differences exist between the centralized and isolated simulations .
18-19:We can notice that all informed simulations (with or without strategies) allow to perform more observations than isolated agents do with less redundancies .
18-20:Likewise, we can notice that all politics reduce the average cost contrary to the first scenario .
18-21:The drastic politics is interesting because not only does it allow to perform more observations than isolated agents do but it allows to highly reduce the average cost with the lowest number of redundancies .
18-22:As far as the number of exchanged messages is concerned, there are 12 meetings between 2 agents during the simulations .
18-23:In the worst case, at each meeting each agent sends N pieces of information on the requests plus 3N pieces of information on the agents" intentions plus 1 message for the end of communication, where N is the total number of requests .
18-24:Consequently, 3864 messages are exchanged in the worst case for the 40 request simulations and 7128 messages for the 74 request simulations .
18-25:These numbers are much higher than the number of messages that are actually exchanged .
18-26:We can notice that the informed simulations, that communicate only requests, allow a higher reduction .
18-27:In the general case, using communication and strategies allows to reduce redundancies and saves resources but increases the average cost: if a request is realized, agents that know it do not plan it even if its cost can be reduce afterwards .
18-28:It is not the case with isolated agents .
18-29:Using strategies on little constrained problems such as scenario 1 constrains the agents too much and causes an additional cost increase .
18-30:Strategies are more useful on highly constrained problems such as scenario 2 .
18-31:Although agents constrain themselves on the number of observations, the average cost is widely reduce. .
19-1:An observation satellite swarm is a cooperative multiagent system with strong constraints in terms of communication and computation capabilities
19-2:In order to increase the global mission outcome, we propose an hybrid approach: deliberative for individual planning and reactive for collaboration
19-3:Agents reason both on requests to carry out and on the other agents" intentions (candidacies)
19-4:An epidemic communication protocol uses all communication opportunities to update this information
19-5:Reactive decision rules (strategies) are proposed to solve conflicts that may arise between agents
19-6:Through the tuning of the strategies (α, and λ) and their plastic interlacing within the protocol, it is possible to coordinate agents without additional communication: the number of exchanged messages remains nearly the same between informed simulations and simulations implementing strategies
19-7:Some simulations have been made to experimentally validate these protocols and the first results are promising but raise many questions
19-8:What is the trade off between the constraint rate of the problem and the need of strategies? To what extent are the number of redundancies and the average cost affected by the tuning of the strategies? Future works will focus on new strategies to solve new conflicts, specially those arising when relaxing the independence assumption between the requests
19-9:A second point is to take into account the complexity of the initial planning problem
19-10:Indeed, the chosen planning approach results in a combinatory explosion with big sets of requests: an anytime or a fully reactive approach has to be considered for more complex problems
19-11:Acknowledgements We would like to thank Marie Claire Charmeau (CNES6 ), Serge Rainjonneau and Pierre Dago (Alcatel Space Alenia) for their relevant comments on this work
19-12:6 The French Space Agency The Sixth Intl
19-13:Joint Conf
19-14:on Autonomous Agents and Multi Agent Systems (AAMAS 07) 293
20-1:ILOG inc
20-2:CPLEX
20-3:http:  www.ilog.com products cplex
20-4:T
20-5:Balch and R
20-6:Arkin
20-7:Communication in reactive multiagent robotic systems
20-8:Autonomous Robots, pages 27 52, 1994
20-9:F
20-10:Bellifemine, A
20-11:Poggi, and G
20-12:Rimassa
20-13:JADE  a FIPA compliant agent framework
20-14:In Proceedings of PAAM"99, pages 97 108, 1999
20-15:A
20-16:Blum and M
20-17:Furst
20-18:Fast planning through planning graph analysis
20-19:Artificial Intelligence, Vol
20-20:90:281 300, 1997
20-21:E
20-22:Bornschlegl, C
20-23:Guettier, G
20-24:L
20-25:Lann, and J. C
20-26:Poncet
20-27:Constraint based layered planning and distributed control for an autonomous spacecraft formation flying
20-28:In Proceedings of the 1st ESA Workshop on Space Autonomy, 2001
20-29:E
20-30:Bornschlegl, C
20-31:Guettier, and J. C
20-32:Poncet
20-33:Automatic planning for autonomous spacecraft constellation
20-34:In Proceedings of the 2nd NASA Intl
20-35:Workshop on Planning and Scheduling for Space, 2000
20-36:R
20-37:Brooks
20-38:A robust layered control system for a mobile robot
20-39:MIT AI Lab Memo, Vol
20-40:864, 1985
20-41:A
20-42:Chopra and M
20-43:Singh
20-44:Nonmonotonic commitment machines
20-45:Lecture Notes in Computer Science: Advances in Agent Communication, Vol
20-46:2922:183 200, 2004
20-47:A
20-48:Chopra and M
20-49:Singh
20-50:Contextualizing commitment protocols
20-51:In Proceedings of the 5th AAMAS, 2006
20-52:B
20-53:Clement and A
20-54:Barrett
20-55:Continual coordination through shared activites
20-56:In Proceedings of the 2nd AAMAS, pages 57 64, 2003
20-57:J
20-58:Cox and E
20-59:Durfee
20-60:Efficient mechanisms for multiagent plan merging
20-61:In Proceedings of the 3rd AAMAS, 2004
20-62:S
20-63:Curtis, M
20-64:Rilee, P
20-65:Clark, and G
20-66:Marr
20-67:Use of swarm intelligence in spacecraft constellations for the resource exploration of the asteroid belt
20-68:In Proceedings of the Third International Workshop on Satellite Constellations and Formation Flying, pages 24 26, 2003
20-69:S
20-70:Damiani, G
20-71:Verfaillie, and M. C
20-72:Charmeau
20-73:An Earth watching satellite constellation : How to manage a team of watching agents with limited communications
20-74:In Proceedings of the 4th AAMAS, pages 455 462, 2005
20-75:S
20-76:Das, P
20-77:Gonzales, R
20-78:Krikorian, and W
20-79:Truszkowski
20-80:Multi agent planning and scheduling environment for enhanced spacecraft autonomy
20-81:In Proceedings of the 5th ISAIRAS, 1999
20-82:R
20-83:Dearden, N
20-84:Meuleau, S
20-85:Ramakrishnan, D
20-86:Smith, and R
20-87:Wahington
20-88:Incremental contingency planning
20-89:In Proceedings of ICAPS"03 Workshop on Planning under Uncertainty and Incomplete Information, pages 1 10, 2003
20-90:F
20-91:Dignum
20-92:Autonomous agents with norms
20-93:Artificial Intelligence and Law, Vol
20-94:7:69 79, 1999
20-95:E
20-96:Durfee
20-97:Scaling up agent coordination strategies
20-98:IEEE Computer, Vol
20-99:34(7):39 46, 2001
20-100:K
20-101:Erol, J
20-102:Hendler, and D
20-103:Nau
20-104:HTN planning : Complexity and expressivity
20-105:In Proceedings of the 12th AAAI, pages 1123 1128, 1994
20-106:D
20-107:Escorial, I
20-108:F
20-109:Tourne, and F
20-110:J
20-111:Reina
20-112:Fuego : a dedicated constellation of small satellites to detect and monitor forest fires
20-113:Acta Astronautica, Vol.52(9 12):765 775, 2003
20-114:B
20-115:Gerkey and M
20-116:Matarić
20-117:A formal analysis and taxonomy of task allocation in multi robot systems
20-118:Journal of Robotics Research, Vol
20-119:23(9):939 954, 2004
20-120:C
20-121:Guettier and J. C
20-122:Poncet
20-123:Multi level planning for spacecraft autonomy
20-124:In Proceedings of the 6th ISAIRAS, pages 18 21, 2001
20-125:I
20-126:Gupta, A. M
20-127:Kermarrec, and A
20-128:Ganesh
20-129:Efficient epidemic style protocols for reliable and scalable multicast
20-130:In Proceedings of the 21st IEEE Symposium on Reliable Distributed Systems, pages 180 189, 2002
20-131:G
20-132:Gutnik and G
20-133:Kaminka
20-134:Representing conversations for scalable overhearing
20-135:Journal of Artificial Intelligence Research, Vol
20-136:25:349 387, 2006
20-137:K
20-138:Jenkins, K
20-139:Hopkinson, and K
20-140:Birman
20-141:A gossip protocol for subgroup multicast
20-142:In Proceedings of the 21st International Conference on Distributed Computing Systems Workshops, pages 25 30, 2001
20-143:N
20-144:Jennings, S
20-145:Parsons, P
20-146:Norriega, and C
20-147:Sierra
20-148:On augumentation based negotiation
20-149:In Proceedings of the International Workshop on Multi Agent Systems, pages 1 7, 1998
20-150:J. L
20-151:Koning and M. P
20-152:Huget
20-153:A semi formal specification language dedicated to interaction protocols
20-154:Information Modeling and Knowledge Bases XII: Frontiers in Artificial Intelligence and Applications, pages 375 392, 2001
20-155:F
20-156:Legras and C
20-157:Tessier
20-158:LOTTO: group formation by overhearing in large teams
20-159:In Proceedings of 2nd AAMAS, 2003
20-160:D
20-161:McAllester, D
20-162:Rosenblitt, P
20-163:Norriega, and C
20-164:Sierra
20-165:Systematic nonlinear planning
20-166:In Proceedings of the 9th AAAI, pages 634 639, 1991
20-167:N
20-168:Meuleau and D
20-169:Smith
20-170:Optimal limited contingency planning
20-171:In Proceedings of the 19th AAAI, pages 417 426, 2003
20-172:P
20-173:Modi and M
20-174:Veloso
20-175:Bumping strategies for the multiagent agreement problem
20-176:In Proceedings of the 4th AAMAS, pages 390 396, 2005
20-177:J
20-178:B
20-179:Mueller, D
20-180:M
20-181:Surka, and B
20-182:Udrea
20-183:Agent based control of multiple satellite formation flying
20-184:In Proceedings of the 6th ISAIRAS, 2001
20-185:J
20-186:Odell, H
20-187:Parunak, and B
20-188:Bauer
20-189:Extending UML for agents
20-190:In Proceedings of the Agent Oriented Information Systems Workshop at the 17th AAAI, 2000
20-191:B
20-192:Pittel
20-193:On spreading a rumor
20-194:SIAM Journal of Applied Mathematics, Vol
20-195:47:213 223, 1987
20-196:B
20-197:Polle
20-198:Autonomy requirement and technologies for future constellation
20-199:Astrium Summary Report, 2002
20-200:T
20-201:Sandholm
20-202:Contract types for satisficing task allocation
20-203:In Proceedings of the AAAI Spring Symposium: Satisficing Models, pages 23 25, 1998
20-204:T
20-205:Schetter, M
20-206:Campbell, and D
20-207:M
20-208:Surka
20-209:Multiple agent based autonomy for satellite constellation
20-210:Artificial Intelligence, Vol
20-211:145:147 180, 2003
20-212:O
20-213:Shehory and S
20-214:Kraus
20-215:Methods for task allocation via agent coalition formation
20-216:Artificial Intelligence, Vol
20-217:101(1 2):165 200, 1998
20-218:D
20-219:M
20-220:Surka
20-221:ObjectAgent for robust autonomous control
20-222:In Proceedings of the AAAI Spring Symposium, 2001
20-223:W
20-224:Truszkowski, D
20-225:Zoch, and D
20-226:Smith
20-227:Autonomy for constellations
20-228:In Proceedings of the SpaceOps Conference, 2000
20-229:R
20-230:VanDerKrogt and M
20-231:deWeerdt
20-232:Plan repair as an extension of planning
20-233:In Proceedings of the 15th ICAPS, pages 161 170, 2005
20-234:B
20-235:Werger
20-236:Cooperation without deliberation : A minimal behavior based approach to multi robot teams
20-237:Artificial Intelligence, Vol
20-238:110:293 320, 1999
20-239:P
20-240:Zetocha
20-241:Satellite cluster command and control
20-242:IEEE Aerospace Conference, Vol
20-243:7:49 54, 2000
20-244:294 The Sixth Intl
20-245:Joint Conf
20-246:on Autonomous Agents and Multi Agent Systems (AAMAS 07)
picture:
