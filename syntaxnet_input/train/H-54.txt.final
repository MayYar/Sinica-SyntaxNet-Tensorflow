Knowledge-intensive Conceptual Retrieval and Passage 
content:
1 ABSTRACT :
1-1:This paper presents a study of incorporating domain specific knowledge (i.e., information about concepts and relationships between concepts in a certain domain) in an information retrieval system to improve its effectiveness in retrieving biomedical literature .
1-2:The effects of different types of domain specific knowledge in performance contribution are examined .
1-3:Based on the TREC platform, we show that appropriate use of domainspecific knowledge in a proposed conceptual retrieval model yields about 23% improvement over the best reported result in passage retrieval in the Genomics Track of TREC 2006 .
1-4:H.3.3 [Information Storage and Retrieval]: Information Search .
2 INTRODUCTION :
2-1:Biologists search for literature on a daily basis .
2-2:For most biologists, PubMed, an online service of U.S .
2-3:National Library of Medicine (NLM), is the most commonly used tool for searching the biomedical literature .
2-4:PubMed allows for keyword search by using Boolean operators .
2-5:For example, if one desires documents on the use of the drug propanolol in the disease hypertension, a typical PubMed query might be propanolol AND hypertension, which will return all the documents having the two keywords .
2-6:Keyword search in PubMed is effective if the query is well crafted by the users using their expertise .
2-7:However, information needs of biologists, in some cases, are expressed as complex questions [8][9], which PubMed is not designed to handle .
2-8:While NLM does maintain an experimental tool for free text queries [6], it is still based on PubMed keyword search .
2-9:The Genomics track of the 2006 Text REtrieval Conference provides a common platform to assess the methods and techniques proposed by various groups for biomedical information retrieval .
2-10:The queries were collected from real biologists and they are expressed as complex questions, such as How do mutations in the Huntingtin gene affect Huntington"s disease? .
2-11:The document collection contains 162,259 Highwire full text documents in HTML format .
2-12:Systems from participating groups are expected to find relevant passages within the full text documents .
2-13:A passage is defined as any span of text that does not include the HTML paragraph tag (i.e., <P> or < P>) .
2-14:We approached the problem by utilizing domain specific knowledge in a conceptual retrieval model .
2-15:Domain specific knowledge, in this paper, refers to information about concepts and relationships between concepts in a certain domain .
2-16:We assume that appropriate use of domain specific knowledge might improve the effectiveness of retrieval .
2-17:For example, given a query What is the role of gene PRNP in the Mad Cow Disease?, expanding the gene symbol PRNP with its synonyms Prp, PrPSc, and prion protein, more relevant documents might be retrieved .
2-18:PubMed and many other biomedical systems [8][9][10][13] also make use of domain specific knowledge to improve retrieval effectiveness .
2-19:Intuitively, retrieval on the level of concepts should outperform bag of words approaches, since the semantic relationships among words in a concept are utilized .
2-20:In some recent studies [13][15], positive results have been reported for this hypothesis .
2-21:In this paper, concepts are entry terms of the ontology Medical Subject Headings (MeSH), a controlled vocabulary maintained by NLM for indexing biomedical literature, or gene symbols in the Entrez gene database also from NLM .
2-22:A concept could be a word, such as the gene symbol PRNP, or a phrase, such as Mad cow diseases .
2-23:In the conceptual retrieval model presented in this paper, the similarity between a query and a document is measured on both concept and word levels .
2-24:This paper makes two contributions: knowledge in an IR system to improve its effectiveness in retrieving biomedical literature .
2-25:Based on this approach, our system achieved significant improvement (23%) over the best reported result in passage retrieval in the Genomics track of TREC 2006 .
2-26:types of domain specific knowledge in performance contribution .
2-27:This paper is organized as follows: problem statement is given in the next section .
2-28:The techniques are introduced in section 3 .
2-29:In section 4, we present the experimental results .
2-30:Related works are given in section 5 and finally, we conclude the paper in section 6. .
3 PROBLEM STATEMENT :
3-1:We describe the queries, document collection and the system output in this section .
3-2:The query set used in the Genomics track of TREC 2006 consists of 28 questions collected from real biologists .
3-3:As described in [8], these questions all have the following general format: Biological object (1..m) Relationship ←⎯⎯⎯⎯→ Biological process (1..n) (1) where a biological object might be a gene, protein, or gene mutation and a biological process can be a physiological process or disease .
3-4:A question might involve multiple biological objects (m) and multiple biological processes (n) .
3-5:These questions were derived from four templates (Table 2) .
3-6:Table 2 Query templates and examples in the Genomics track of TREC 2006 Template Example What is the role of gene in disease? What is the role of DRD4 in alcoholism? What effect does gene have on biological process? What effect does the insulin receptor gene have on tumorigenesis? How do genes interact in organ function? How do HMG and HMGB1 interact in hepatitis? How does a mutation in gene influence biological process? How does a mutation in Ret influence thyroid function? Features of the queries: 1) They are different from the typical Web queries and the PubMed queries, both of which usually consist of 1 to 3 keywords; 2) They are generated from structural templates which can be used by a system to identify the query components, the biological object or process .
3-7:The document collection contains 162,259 Highwire full text documents in HTML format .
3-8:The output of the system is a list of passages ranked according to their similarities with the query .
3-9:A passage is defined as any span of text that does not include the HTML paragraph tag (i.e., <P> or < P>) .
3-10:A passage could be a part of a sentence, a sentence, a set of consecutive sentences or a paragraph (i.e., the whole span of text that are inside of <P> and < P> HTML tags) .
3-11:This is a passage level information retrieval problem with the attempt to put biologists in contexts where relevant information is provided. .
4 TECHNIQUES AND METHODS :
4-1:We approached the problem by first retrieving the top k most relevant paragraphs, then extracting passages from these paragraphs, and finally ranking the passages .
4-2:In this process, we employed several techniques and methods, which will be introduced in this section .
4-3:First, we give two definitions: Definition 3.1 A concept is 1) a entry term in the MeSH ontology, or 2) a gene symbol in the Entrez gene database .
4-4:This definition of concept can be generalized to include other biomedical dictionary terms .
4-5:Definition 3.2 A semantic type is a category defined in the Semantic Network of the Unified Medical Language System [14] .
4-6:The current release of the UMLS Semantic Network contains 135 semantic types such as Disease or Syndrome .
4-7:Each entry term in the MeSH ontology is assigned one or more semantic types .
4-8:Each gene symbol in the Entrez gene database maps to the semantic type Gene or Genome .
4-9:In addition, these semantic types are linked by 54 relationships .
4-10:For example, Antibiotic prevents Disease or Syndrome .
4-11:These relationships among semantic types represent general biomedical knowledge .
4-12:We utilized these semantic types and their relationships to identify related concepts .
4-13:The rest of this section is organized as follows: in section 3.1, we explain how the concepts are identified within a query .
4-14:In section 3.2, we specify five different types of domain specific knowledge and introduce how they are compiled .
4-15:In section 3.3, we present our conceptual IR model .
4-16:Finally, our strategy for passage extraction is described in section 3.4 .
4-17:3.1 Identifying concepts within a query A concept, defined in Definition 3.1, is a gene symbol or a MeSH term .
4-18:We make use of the query templates to identify gene symbols .
4-19:For example, the query How do HMG and HMGB1 interact in hepatitis? is derived from the template How do genes interact in organ function? .
4-20:In this case, HMG and HMGB1 will be identified as gene symbols .
4-21:In cases where the query templates are not provided, programs for recognition of gene symbols within texts are needed .
4-22:We use the query translation functionality of PubMed to extract MeSH terms in a query .
4-23:This is done by submitting the whole query to PubMed, which will then return a file in which the MeSH terms in the query are labeled .
4-24:In Table 3.1, three MeSH terms within the query What is the role of gene PRNP in the Mad cow disease? are found in the PubMed translation: "encephalopathy, bovine spongiform" for Mad cow disease, genes for gene, and role for role .
4-25:Table 3.1 The PubMed translation of the query "What is the role of gene PRNP in the Mad cow disease?" .
4-26:Term PubMed translation Mad cow disease "bovine spongiform encephalopathy"[Text Word] OR "encephalopathy, bovine spongiform"[MeSH Terms] OR Mad cow disease[Text Word] gene ("genes"[TIAB] NOT Medline[SB]) OR "genes"[MeSH Terms] OR gene[Text Word] role "role"[MeSH Terms] OR role[Text Word] 3.2 Compiling domain specific knowledge In this paper, domain specific knowledge refers to information about concepts and their relationships in a certain domain .
4-27:We used five types of domain specific knowledge in the domain of genomics: Type 1 .
4-28:Synonyms (terms listed in the thesauruses that refer to the same meaning) Type 2 .
4-29:Hypernyms (more generic terms, one level only) Type 3 .
4-30:Hyponyms (more specific terms, one level only) Type 4 .
4-31:Lexical variants (different forms of the same concept, such as abbreviations .
4-32:They are commonly used in the literature, but might not be listed in the thesauruses) Type 5 .
4-33:Implicitly related concepts (terms that are semantically related and also co occur more frequently than being independent in the biomedical texts) Knowledge of type 1 3 is retrieved from the following two thesauruses: 1) MeSH, a controlled vocabulary maintained by NLM for indexing biomedical literature .
4-34:The 2007 version of MeSH contains information about 190,000 concepts .
4-35:These concepts are organized in a tree hierarchy; 2) Entrez Gene, one of the most widely used searchable databases of genes .
4-36:The current version of Entrez Gene contains information about 1.7 million genes .
4-37:It does not have a hierarchy .
4-38:Only synonyms are retrieved from Entrez Gene .
4-39:The compiling of type 4 5 knowledge is introduced in section 3.2.1 and 3.2.2, respectively .
4-40:3.2.1 Lexical variants Lexical variants of gene symbols New gene symbols and their lexical variants are regularly introduced into the biomedical literature [7] .
4-41:However, many reference databases, such as UMLS and Entrez Gene, may not be able to keep track of all this kind of variants .
4-42:For example, for the gene symbol "NF kappa B", at least 5 different lexical variants can be found in the biomedical literature: "NF kappaB", "NFkappaB", "NFkappa B", "NF kB", and "NFkB", three of which are not in the current UMLS and two not in the Entrez Gene .
4-43:[3][21] have shown that expanding gene symbols with their lexical variants improved the retrieval effectiveness of their biomedical IR systems .
4-44:In our system, we employed the following two strategies to retrieve lexical variants of gene symbols .
4-45:Strategy I: This strategy is to automatically generate lexical variants according to a set of manually crafted heuristics [3][21] .
4-46:For example, given a gene symbol PLA2, a variant PLAII is generated according to the heuristic that Roman numerals and Arabic numerals are convertible when naming gene symbols .
4-47:Another variant, PLA 2, is also generated since a hyphen or a space could be inserted at the transition between alphabetic and numerical characters in a gene symbol .
4-48:Strategy II: This strategy is to retrieve lexical variants from an abbreviation database .
4-49:ADAM [22] is an abbreviation database which covers frequently used abbreviations and their definitions (or long forms) within MEDLINE, the authoritative repository of citations from the biomedical literature maintained by the NLM .
4-50:Given a query How does nucleoside diphosphate kinase (NM23) contribute to tumor progression?, we first identify the abbreviation NM23 and its long form nucleoside diphosphate kinase using the abbreviation identification program from [4] .
4-51:Searching the long form nucleoside diphosphate kinase in ADAM, other abbreviations, such as NDPK or NDK, are retrieved .
4-52:These abbreviations are considered as the lexical variants of NM23 .
4-53:Lexical variants of MeSH concepts ADAM is used to obtain the lexical variants of MeSH concepts as well .
4-54:All the abbreviations of a MeSH concept in ADAM are considered as lexical variants to each other .
4-55:In addition, those long forms that share the same abbreviation with the MeSH concept and are different by an edit distance of 1 or 2 are also considered as its lexical variants .
4-56:As an example, "human papilloma viruses" and "human papillomaviruses" have the same abbreviation HPV in ADAM and their edit distance is 1 .
4-57:Thus they are considered as lexical variants to each other .
4-58:The edit distance between two strings is measured by the minimum number of insertions, deletions, and substitutions of a single character required to transform one string into the other [12] .
4-59:3.2.2 Implicitly related concepts Motivation: In some cases, there are few documents in the literature that directly answer a given query .
4-60:In this situation, those documents that implicitly answer their questions or provide supporting information would be very helpful .
4-61:For example, there are few documents in PubMed that directly answer the query "What is the role of the genes HNF4 and COUP tf I in the suppression in the function of the liver?" .
4-62:However, there exist some documents about the role of "HNF4" and "COUP tf I" in regulating "hepatitis B virus" transcription .
4-63:It is very likely that the biologists would be interested in these documents because "hepatitis B virus" is known as a virus that could cause serious damage to the function of liver .
4-64:In the given example, "hepatitis B virus" is not a synonym, hypernym, hyponym, nor a lexical variant of any of the query concepts, but it is semantically related to the query concepts according to the UMLS Semantic Network .
4-65:We call this type of concepts implicitly related concepts of the query .
4-66:This notion is similar to the B term used in [19] for relating two disjoint literatures for biomedical hypothesis generation .
4-67:The difference is that we utilize the semantic relationships among query concepts to exclusively focus on concepts of certain semantic types .
4-68:A query q in format (1) of section 2 can be represented by q = (A, C) where A is the set of biological objects and C is the set of biological processes .
4-69:Those concepts that are semantically related to both A and C according to the UMLS Semantic Network are considered as the implicitly related concepts of the query .
4-70:In the above example, A = {HNF4, COUP tf I}, C = {function of liver}, and "hepatitis B virus" is one of the implicitly related concepts .
4-71:We make use of the MEDLINE database to extract the implicitly related concepts .
4-72:The 2006 version of MEDLINE database contains citations (i.e., abstracts, titles, and etc.) of over 15 million biomedical articles .
4-73:Each document in MEDLINE is manually indexed by a list of MeSH terms to describe the topics covered by that document .
4-74:Implicitly related concepts are extracted and ranked in the following steps: Step 1 .
4-75:Let list_A be the set of MeSH terms that are 1) used for indexing those MEDLINE citations having A, and 2) semantically related to A according to the UMLS Semantic Network .
4-76:Similarly, list_C is created for C .
4-77:Concepts in B = list_A ∩ list_C are considered as implicitly related concepts of the query .
4-78:Step 2 .
4-79:For each concept b∈B, compute the association between b and A using the mutual information measure [5]: P( , ) ( , ) log P( )P( ) b A I b A b A = where P(x) = n N, n is the number of MEDLINE citations having x and N is the size of MEDLINE .
4-80:A large value for I(b, A) means that b and A co occur much more often than being independent .
4-81:I(b, C) is computed similarly .
4-82:Step 3 .
4-83:Let r(b) = (I(b, A), I(b, C)), for b∈ B .
4-84:Given b1, b2 ∈ B, we say r(b1) ≤ r(b2) if I(b1, A) ≤ I(b2, A) and I(b1, C) ≤ I(b2, C) .
4-85:Then the association between b and the query q is measured by: { : and ( ) ( )} ( , ) { : and ( ) ( )} x x B r x r b score b q x x B r b r x ∈ ≤ = ∈ ≤ (2) The numerator in Formula 2 is the number of the concepts in B that are associated with both A and C equally with or less than b .
4-86:The denominator is the number of the concepts in B that are associated with both A and C equally with or more than b .
4-87:Figure 3.2.2 shows the top 4 implicitly related concepts for the sample query .
4-88:Figure 3.2.2 Top 4 implicitly related concepts for the query "How do interactions between HNF4 and COUP TF1 suppress liver function?" .
4-89:In Figure 3.2.2, the top 4 implicitly related concepts are all highly associated with liver: Hepatocytes are liver cells; Hepatoblastoma is a malignant liver neoplasm occurring in young children; the vast majority of Gluconeogenesis takes place in the liver; and Hepatitis B virus is a virus that could cause serious damage to the function of liver .
4-90:The top k ranked concepts in B are used for query expansion: if I(b, A) ≥ I(b, C), then b is considered as an implicit related concept of A .
4-91:A document having b but not A will receive a partial weight of A .
4-92:The expansion is similar for C when I(b, A) < I(b, C) .
4-93:3.3 Conceptual IR model We now discuss our conceptual IR model .
4-94:We first give the basic conceptual IR model in section 3.3.1 .
4-95:Then we explain how the domain specific knowledge is incorporated in the model using query expansion in section 3.3.2 .
4-96:A pseudo feedback strategy is introduced in section 3.3.3 .
4-97:In section 3.3.4, we give a strategy to improve the ranking by avoiding incorrect match of abbreviations .
4-98:3.3.1 Basic model Given a query q and a document d, our model measures two similarities, concept similarity and word similarity: ( , ) ( , )( , ) ( , ) concept word sim q d sim q d sim q d= Concept similarity Two vectors are derived from a query q, 1 2 1 11 12 1 2 21 22 2 ( , ) ( , ,..., ) ( , ,..., ) m n q v v v c c c v c c c = = = where v1 is a vector of concepts describing the biological object(s) and v2 is a vector of concepts describing the biological process(es) .
4-99:Given a vector of concepts v, let s(v) be the set of concepts in v .
4-100:The weight of vi is then measured by: ( ) max{log : ( ) ( ) and 0}i i v v N w v s v s v n n = ⊆ > where v is a vector that contains a subset of concepts in vi and nv is the number of documents having all the concepts in v .
4-101:The concept similarity between q and d is then computed by 2 1 ( )( , ) i i concept i w vsim q d α = = ×∑ where αi is a parameter to indicate the completeness of vi that document d has covered .
4-102:αi is measured by: and i i i c c d c v c c v idf idf α ∈ ∈ ∈ = ∑ ∑ (3) where idfc is the inverse document frequency of concept c .
4-103:An example: suppose we have a query How does Nurr 77 delete T cells before they migrate to the spleen or lymph nodes and how does this impact autoimmunity? .
4-104:After identifying the concepts in the query, we have: 1 2 ('Nurr 77') ('T cells', 'spleen', 'autoimmunity', 'lymph nodes') v v = = Suppose that some document frequencies of different combinations of concepts are as follows: 25 df('Nurr 77') 0 df('T cells', 'spleen', 'autoimmunity', 'lymph nodes') 326 df('T cells', 'spleen', 'autoimmunity') 82 df('spleen', 'autoimmunity', 'lymph nodes') 147 df('T cells', 'autoimmunity', 'lymph nodes') 2332 df('T cells', 'spleen', 'lymph nodes') The weight of vi is then computed by (note that there does not exist a document having all the concepts in v2): 1 2 ( ) log( 25) ( ) log( 82) w v N w v N = = .
4-105:Now suppose a document d contains concepts ‘Nurr 77", 'T cells', 'spleen', and 'lymph nodes', but not ‘autoimmunity", then the value of parameter αi is computed as follows: 1 2 1 ('T cells')+ ('spleen')+ ('lymph nodes') ('T cells')+ ('spleen')+ ('lymph nodes')+ ('autoimmunity') idf idf idf idf idf idf idf α α = = Word similarity The similarity between q and d on the word level is computed using Okapi [17]: 10.5 ( 1) log( )( , ) 0.5word w q N n k tf sim q d n K tf∈ − + + = + + ∑ (4) where N is the size of the document collection; n is the number of documents containing w; K=k1 × ((1 b)+b × dl avdl) and k1=1.2, C Function of Liver Implicitly related concepts Hepatocytes Hepatoblastoma Gluconeogenesis Hepatitis B virus HNF4 and COUP tf I A b=0.75 are constants .
4-106:dl is the document length of d and avdl is the average document length; tf is the term frequency of w within d .
4-107:The model Given two documents d1 and d2, we say 1 2( , ) ( , )sim q d sim q d> or d1 will be ranked higher than d2, with respect to the same query q, if either 1) 1 2( , ) ( , ) concept concept sim q d sim q d> or 2) 1 2 1 2and( , ) ( , ) ( , ) ( , ) concept concept word word sim q d sim q d sim q d sim q d= > This conceptual IR model emphasizes the similarity on the concept level .
4-108:A similar model but applied to non biomedical domain has been given in [15] .
4-109:3.3.2 Incorporating domain specific knowledge Given a concept c, a vector u is derived by incorporating its domain specific knowledge: 1 2 3( , , , )u c u u u= where u1 is a vector of its synonyms, hyponyms, and lexical variants; u2 is a vector of its hypernyms; and u3 is a vector of its implicitly related concepts .
4-110:An occurrence of any term in u1 will be counted as an occurrence of c .
4-111:idfc in Formula 3 is updated as: 1, logc c u N D idf = 1,c uD is the set of documents having c or any term in 1u .
4-112:The weight that a document d receives from u is given by: max{ : and }tw t u t d∈ ∈ where wt = β .cidf× The weighting factor β is an empirical tuning parameter determined as: its lexical variant; .
5 β = 0.95 if t is a hypernym; :
5-1:the number of selected top ranked implicitly related concepts (see section 3.2.2); i is the position of t in the ranking of implicitly related concepts .
5-2:3.3.3 Pseudo feedback Pseudo feedback is a technique commonly used to improve retrieval performance by adding new terms into the original query .
5-3:We used a modified pseudo feedback strategy described in [2] .
5-4:Step 1 .
5-5:Let C be the set of concepts in the top 15 ranked documents .
5-6:For each concept c in C, compute the similarity between c and the query q, the computation of sim(q,c) can be found in [2] .
5-7:Step 2 .
5-8:The top k ranked concepts by sim(q,c) are selected .
5-9:Step 3 .
5-10:Associate each selected concept c' with the concept cq in q that 1) has the same semantic type as c', and 2) is most related to c' among all the concepts in q .
5-11:The association between c' and cq is computed by: P( ', ) ( ', ) log P( ')P( ) q q q c c I c c c c = where P(x) = n N, n is the number of documents having x and N is the size of the document collection .
5-12:A document having c' but not cq receives a weight given by: (0.5× (k i+1) k) ,qcidf× where i is the position of c' in the ranking of step 2 .
5-13:3.3.4 Avoid incorrect match of abbreviations Some gene symbols are very short and thus ambiguous .
5-14:For example, the gene symbol APC could be the abbreviation for many non gene long forms, such as air pollution control, aerobic plate count, or argon plasma coagulation .
5-15:This step is to avoid incorrect match of abbreviations in the top ranked documents .
5-16:Given an abbreviation X with the long form L in the query, we scan the top k ranked (k=1000) documents and when a document is found with X, we compare L with all the long forms of X in that document .
5-17:If none of these long forms is equal or close to L (i.e., the edit distance between L and the long form of X in that document is 1 or 2), then the concept similarity of X is subtracted .
5-18:3.4 Passage extraction The goal of passage extraction is to highlight the most relevant fragments of text in paragraphs .
5-19:A passage is defined as any span of text that does not include the HTML paragraph tag (i.e., <P> or < P>) .
5-20:A passage could be a part of a sentence, a sentence, a set of consecutive sentences or a paragraph (i.e., the whole span of text that are inside of <P> and < P> HTML tags) .
5-21:It is also possible to have more than one relevant passage in a single paragraph .
5-22:Our strategy for passage extraction assumes that the optimal passage(s) in a paragraph should have all the query concepts that the whole paragraph has .
5-23:Also they should have higher density of query concepts than other fragments of text in the paragraph .
5-24:Suppose we have a query q and a paragraph p represented by a sequence of sentences 1 2.. .
5-25:.np s s s= Let C be the set of concepts in q that occur in p and S = Φ .
5-26:Step 1 .
5-27:For each sequence of consecutive sentences 1.. .
5-28:,i i js s s+ 1 ≤ i ≤ j ≤ n, let S = S 1{ .. .
5-29:}i i js s s+∪ if 1...i i js s s+ satisfies that: 1) Every query concept in C occurs in 1...i i js s s+ and 2) There does not exist k, such that i < k < j and every query concept in C occurs in 1...i i ks s s+ or 1 2.. .
5-30:.k k js s s+ + Condition 1 requires 1...i i js s s+ having all the query concepts in p and condition 2 requires 1...i i js s s+ be the minimal .
5-31:Step 2 .
5-32:Let 1min{ 1: .. .
5-33:}i i jL j i s s s S+= − + ∈ .
5-34:For every 1...i i js s s+ in S, let 1{ .. .
5-35:}i i jS S s s s+= − if (j i + 1) > L .
5-36:This step is to remove those sequences of sentences in S that have lower density of query concepts .
5-37:Step 3 .
5-38:For every two sequences of consecutive sentences 1 1 1 2 2 21 1.. .
5-39:, and ...i i j i i js s s S s s s S+ +∈ ∈ , if 1 2 1 2 2 1 , and 1 i i j j i j ≤ ≤ ≤ + (5) then do Repeat this step until for every two sequences of consecutive sentences in S, condition (5) does not apply .
5-40:This step is to merge those sequences of sentences in S that are adjacent or overlapped .
5-41:Finally the remaining sequences of sentences in S are returned as the optimal passages in the paragraph p with respect to the query .
5-42:1 1 2 1 1 2 2 2 1 1 1 1 { .. .
5-43:} { .. .
5-44:} { .. .
5-45:} i i j i i j i i j S S s s s S S s s s S S s s s + + + = ∪ = − = − .
6 EXPERIMENTAL RESULTS :
6-1:The evaluation of our techniques and the experimental results are given in this section .
6-2:We first describe the datasets and evaluation metrics used in our experiments and then present the results .
6-3:4.1 Data sets and evaluation metrics Our experiments were performed on the platform of the Genomics track of TREC 2006 .
6-4:The document collection contains 162,259 full text documents from 49 Highwire biomedical journals .
6-5:The set of queries consists of 28 queries collected from real biologists .
6-6:The performance is measured on three different levels (passage, aspect, and document) to provide better insight on how the question is answered from different perspectives .
6-7:Passage MAP: As described in [8], this is a character based precision calculated as follows: At each relevant retrieved passage, precision will be computed as the fraction of characters overlapping with the gold standard passages divided by the total number of characters included in all nominated passages from this system for the topic up until that point .
6-8:Similar to regular MAP, relevant passages that were not retrieved will be added into the calculation as well, with precision set to 0 for relevant passages not retrieved .
6-9:Then the mean of these average precisions over all topics will be calculated to compute the mean average passage precision .
6-10:Aspect MAP: A question could be addressed from different aspects .
6-11:For example, the question what is the role of gene PRNP in the Mad cow disease? could be answered from aspects like Diagnosis, Neurologic manifestations, or Prions Genetics .
6-12:This measure indicates how comprehensive the question is answered .
6-13:Document MAP: This is the standard IR measure .
6-14:The precision is measured at every point where a relevant document is obtained and then averaged over all relevant documents to obtain the average precision for a given query .
6-15:For a set of queries, the mean of the average precision for all queries is the MAP of that IR system .
6-16:The output of the system is a list of passages ranked according to their similarities with the query .
6-17:The performances on the three levels are then calculated based on the ranking of the passages .
6-18:4.2 Results The Wilcoxon signed rank test was employed to determine the statistical significance of the results .
6-19:In the tables of the following sections, statistically significant improvements (at the 5% level) are marked with an asterisk .
6-20:4.2.1 Conceptual IR model vs .
6-21:term based model The initial baseline was established using word similarity only computed by the Okapi (Formula 4) .
6-22:Another run based on our basic conceptual IR model was performed without using query expansion, pseudo feedback, or abbreviation correction .
6-23:The experimental result is shown in Table 4.2.1 .
6-24:Our basic conceptual IR model significantly outperforms the Okapi on all three levels, which suggests that, although it requires additional efforts to identify concepts, retrieval on the concept level can achieve substantial improvements over purely term based retrieval model .
6-25:4.2.2 Contribution of different types of knowledge A series of experiments were performed to examine how each type of domain specific knowledge contributes to the retrieval performance .
6-26:A new baseline was established using the basic conceptual IR model without incorporating any type of domainspecific knowledge .
6-27:Then five runs were conducted by adding each individual type of domain specific knowledge .
6-28:We also conducted a run by adding all types of domain specific knowledge .
6-29:Results of these experiments are shown in Table 4.2.2 .
6-30:We found that any available type of domain specific knowledge improved the performance in passage retrieval .
6-31:The biggest improvement comes from the lexical variants, which is consistent with the result reported in [3] .
6-32:This result also indicates that biologists are likely to use different variants of the same concept according to their own writing preferences and these variants might not be collected in the existing biomedical thesauruses .
6-33:It also suggests that the biomedical IR systems can benefit from the domain specific knowledge extracted from the literature by text mining systems .
6-34:Synonyms provided the second biggest improvement .
6-35:Hypernyms, hyponyms, and implicitly related concepts provided similar degrees of improvement .
6-36:The overall performance is an accumulative result of adding different types of domain specific knowledge and it is better than any individual addition .
6-37:It is clearly shown that the performance is significantly improved (107% on passage level, 63.1% on aspect level, and 49.6% on document level) when the domain specific knowledge is appropriately incorporated .
6-38:Although it is not explicitly shown in Table 4.2.3, different types of domain specific knowledge affect different subsets of queries .
6-39:More specifically, each of these types (with the exception of the lexical variants which affects a large number of queries) affects only a few queries .
6-40:But for those affected queries, their improvement is significant .
6-41:As a consequence, the accumulative improvement is very significant .
6-42:4.2.3 Pseudo feedback and abbreviation correction Using the Baseline+All in Table 4.2.2 as a new baseline, the contribution of abbreviation correction and pseudo feedback is given in Table 4.2.3 .
6-43:There is little improvement by avoiding incorrect matching of abbreviations .
6-44:The pseudo feedback contributed about 4.6% improvement in passage retrieval .
6-45:4.2.4 Performance compared with best reported results We compared our result with the results reported in the Genomics track of TREC 2006 [8] on the conditions that 1) systems are automatic systems and 2) passages are extracted from paragraphs .
6-46:The performance of our system relative to the best reported results is shown in Table 4.2.4 (in TREC 2006, some systems returned the whole paragraphs as passages .
6-47:As a consequence, excellent retrieval results were obtained on document and aspect levels at the expense of performance on the passage level .
6-48:We do not include the results of such systems here) .
6-49:Table 4.2.4 Performance compared with best reported results .
6-50:Passage MAP Aspect MAP Document MAP Best reported results 0.1486 0.3492 0.5320 Our results 0.1823 0.3811 0.5391 Improvement 22.68% 9.14% 1.33% The best reported results in the first row of Table 4.2.4 on three levels (passage, aspect, and document) are from different systems .
6-51:Our result is from a single run on passage retrieval in which it is better than the best reported result by 22.68% in passage retrieval and at the same time, 9.14% better in aspect retrieval, and 1.33% better in document retrieval (Since the average precision of each individual query was not reported, we can not apply the Wilcoxon signed rank test to calculate the significance of difference between our performance and the best reported result.) .
6-52:Table 4.2.1 Basic conceptual IR model vs .
6-53:term based model Run Passage Aspect Document MAP Imprvd qs # (%) MAP Imprvd qs # (%) MAP Imprvd qs # (%) Okapi 0.064 N A 0.175 N A 0.285 N A Basic conceptual IR model 0.084* (+31.3%) 17 (65.4%) 0.233* (+33.1%) 12 (46.2%) 0.359* (+26.0%) 15 (57.7%) Table 4.2.2 Contribution of different types of domain specific knowledge Run Passage Aspect Document MAP Imprvd qs # (%) MAP Imprvd qs # (%) MAP Imprvd qs # (%) Baseline = Basic conceptual IR model 0.084 N A 0.233 N A 0.359 N A Baseline+Synonyms 0.105 (+25%) 11 (42.3%) 0.246 (+5.6%) 9 (34.6%) 0.420 (+17%) 13 (50%) Baseline+Hypernyms 0.088 (+4.8%) 11 (42.3%) 0.225 ( 3.4%) 9 (34.6%) 0.390 (+8.6%) 16 (61.5%) Baseline+Hyponyms 0.087 (+3.6%) 10 (38.5%) 0.217 ( 6.9%) 7 (26.9%) 0.389 (+8.4%) 10 (38.5%) Baseline+Variants 0.150* (+78.6%) 16 (61.5%) 0.348* (+49.4%) 13 (50%) 0.495* (+37.9%) 10 (38.5%) Baseline+Related 0.086 (+2.4%) 9 (34.6%) 0.220 ( 5.6%) 9 (34.6%) 0.387 (+7.8%) 13 (50%) Baseline+All 0.174* (107%) 25 (96.2%) 0.380* (+63.1%) 19 (73.1%) 0.537* (+49.6%) 14 (53.8%) Table 4.2.3 Contribution of abbreviation correction and pseudo feedback Run Passage Aspect Document MAP Imprvd qs # (%) MAP Imprvd qs # (%) MAP Imprvd qs # (%) Baseline+All 0.174 N A 0.380 N A 0.537 N A Baseline+All+Abbr 0.175 (+0.6%) 5 (19.2%) 0.375 ( 1.3%) 4 (15.4%) 0.535 ( 0.4%) 4 (15.4%) Baseline+All+Abbr+PF 0.182 (+4.6%) 10 (38.5%) 0.381 (+0.3%) 6 (23.1%) 0.539 (+0.4%) 9 (34.6%) A separate experiment has been done using a second testbed, the ad hoc Task of TREC Genomics 2005, to evaluate our knowledge intensive conceptual IR model for document retrieval of biomedical literature .
6-54:The overall performance in terms of MAP is 35.50%, which is about 22.92% above the best reported result [9] .
6-55:Notice that the performance was only measured on the document level for the ad hoc Task of TREC Genomics 2005. .
7 RELATED WORKS :
7-1:Many studies used manually crafted thesauruses or knowledge databases created by text mining systems to improve retrieval effectiveness based on either word statistical retrieval systems or conceptual retrieval systems .
7-2:[11][1] assessed query expansion using the UMLS Metathesaurus .
7-3:Based on a word statistical retrieval system, [11] used definitions and different types of thesaurus relationships for query expansion and a deteriorated performance was reported .
7-4:[1] expanded queries with phrases and UMLS concepts determined by the MetaMap, a program which maps biomedical text to UMLS concepts, and no significant improvement was shown .
7-5:We used MeSH, Entrez gene, and other non thesaurus knowledge resources such as an abbreviation database for query expansion .
7-6:A critical difference between our work and those in [11][1] is that our retrieval model is based on concepts, not on individual words .
7-7:The Genomics track in TREC provides a common platform to evaluate methods and techniques proposed by various groups for biomedical information retrieval .
7-8:As summarized in [8][9][10], many groups utilized domain specific knowledge to improve retrieval effectiveness .
7-9:Among these groups, [3] assessed both thesaurus based knowledge, such as gene information, and non thesaurus based knowledge, such as lexical variants of gene symbols, for query expansion .
7-10:They have shown that query expansion with acronyms and lexical variants of gene symbols produced the biggest improvement, whereas, the query expansion with gene information from gene databases deteriorated the performance .
7-11:[21] used a similar approach for generating lexical variants of gene symbols and reported significant improvements .
7-12:Our system utilized more types of domain specific knowledge, including hyponyms, hypernyms and implicitly related concepts .
7-13:In addition, under the conceptual retrieval framework, we examined more comprehensively the effects of different types of domain specific knowledge in performance contribution .
7-14:[20][15] utilized WordNet, a database of English words and their lexical relationships developed by Princeton University, for query expansion in the non biomedical domain .
7-15:In their studies, queries were expanded using the lexical semantic relations such as synonyms, hypernyms, or hyponyms .
7-16:Little benefit has been shown in [20] .
7-17:This has been due to ambiguity of the query terms which have different meanings in different contexts .
7-18:When these synonyms having multiple meanings are added to the query, substantial irrelevant documents are retrieved .
7-19:In the biomedical domain, this kind of ambiguity of query terms is relatively less frequent, because, although the abbreviations are highly ambiguous, general biomedical concepts usually have only one meaning in the thesaurus, such as UMLS, whereas a term in WordNet usually have multiple meanings (represented as synsets in WordNet) .
7-20:Besides, we have implemented a post ranking step to reduce the number of incorrect matches of abbreviations, which will hopefully decrease the negative impact caused by the abbreviation ambiguity .
7-21:Besides, we have implemented a postranking step to reduce the number of incorrect matches of abbreviations, which will hopefully decrease the negative impact caused by the abbreviation ambiguity .
7-22:The retrieval model in [15] emphasized the similarity between a query and a document on the phrase level assuming that phrases are more important than individual words when retrieving documents .
7-23:Although the assumption is similar, our conceptual model is based on the biomedical concepts, not phrases .
7-24:[13] presented a good study of the role of knowledge in the document retrieval of clinical medicine .
7-25:They have shown that appropriate use of semantic knowledge in a conceptual retrieval framework can yield substantial improvements .
7-26:Although the retrieval model is similar, we made a study in the domain of genomics, in which the problem structure and task knowledge is not as well defined as in the domain of clinical medicine [18] .
7-27:Also, our similarity function is very different from that in [13] .
7-28:In summary, our approach differs from previous works in four important ways: First, we present a case study of conceptual retrieval in the domain of genomics, where many knowledge resources can be used to improve the performance of biomedical IR systems .
7-29:Second, we have studied more types of domainspecific knowledge than previous researchers and carried out more comprehensive experiments to look into the effects of different types of domain specific knowledge in performance contribution .
7-30:Third, although some of the techniques seem similar to previously published ones, they are actually quite different in details .
7-31:For example, in our pseudo feedback process, we require that the unit of feedback is a concept and the concept has to be of the same semantic type as a query concept .
7-32:This is to ensure that our conceptual model of retrieval can be applied .
7-33:As another example, the way in which implicitly related concepts are extracted in this paper is significantly different from that given in [19] .
7-34:Finally, our conceptual IR model is actually based on complex concepts because some biomedical meanings, such as biological processes, are represented by multiple simple concepts. .
8 CONCLUSION :
8-1:This paper proposed a conceptual approach to utilize domainspecific knowledge in an IR system to improve its effectiveness in retrieving biomedical literature .
8-2:We specified five different types of domain specific knowledge (i.e., synonyms, hyponyms, hypernyms, lexical variants, and implicitly related concepts) and examined their effects in performance contribution .
8-3:We also evaluated other two techniques, pseudo feedback and abbreviation correction .
8-4:Experimental results have shown that appropriate use of domain specific knowledge in a conceptual IR model yields significant improvements (23%) in passage retrieval over the best known results .
8-5:In our future work, we will explore the use of other existing knowledge resources, such as UMLS and the Wikipedia, and evaluate techniques such as disambiguation of gene symbols for improving retrieval effectiveness .
8-6:The application of our conceptual IR model in other domains such as clinical medicine will be investigated. .
9-1:insightful discussion.
10-1:Aronson A.R., Rindflesch T.C
10-2:Query expansion using the UMLS Metathesaurus
10-3:Proc AMIA Annu Fall Symp
10-4:1997
10-5:485 9
10-6:Baeza Yates R., Ribeiro Neto B
10-7:Modern Information Retrieval
10-8:Addison Wesley, 1999, 129 131
10-9:Buttcher S., Clarke C.L.A., Cormack G.V
10-10:Domain specific synonym expansion and validation for biomedical information retrieval (MultiText experiments for TREC 2004)
10-11:TREC"04
10-12:Chang J.T., Schutze H., Altman R.B
10-13:Creating an online dictionary of abbreviations from MEDLINE
10-14:Journal of the American Medical Informatics Association
10-15:2002 9(6)
10-16:Church K.W., Hanks P
10-17:Word association norms, mutual information and lexicography
10-18:Computational Linguistics
10-19:1990;16:22, C29
10-20:Fontelo P., Liu F., Ackerman M
10-21:askMEDLINE: a free text, natural language query tool for MEDLINE PubMed
10-22:BMC Med Inform Decis Mak
10-23:2005 Mar 10;5(1):5
10-24:Fukuda K., Tamura A., Tsunoda T., Takagi T
10-25:Toward information extraction: identifying protein names from biological papers
10-26:Pac Symp Biocomput
10-27:1998;:707 18
10-28:Hersh W.R., and etc
10-29:TREC 2006 Genomics Track Overview
10-30:TREC"06
10-31:Hersh W.R., and etc
10-32:TREC 2005 Genomics Track Overview
10-33:In TREC"05
10-34:Hersh W.R., and etc
10-35:TREC 2004 Genomics Track Overview
10-36:In TREC"04
10-37:Hersh W.R., Price S., Donohoe L
10-38:Assessing thesaurus based query expansion using the UMLS Metathesaurus
10-39:Proc AMIA Symp
10-40:344 8
10-41:2000
10-42:Levenshtein, V
10-43:Binary codes capable of correcting deletions, insertions, and reversals
10-44:Soviet Physics  Doklady 10, 10 (1996), 707 710
10-45:Lin J., Demner Fushman D
10-46:The Role of Knowledge in Conceptual Retrieval: A Study in the Domain of Clinical Medicine
10-47:SIGIR"06
10-48:99 06
10-49:Lindberg D., Humphreys B., and McCray A
10-50:The Unified Medical Language System
10-51:Methods of Information in Medicine
10-52:32(4):281 291, 1993
10-53:Liu S., Liu F., Yu C., and Meng W.Y
10-54:An Effective Approach to Document Retrieval via Utilizing WordNet and Recognizing Phrases
10-55:SIGIR"04
10-56:266 272 Proux D., Rechenmann F., Julliard L., Pillet V.V., Jacq B
10-57:Detecting Gene Symbols and Names in Biological Texts: A First Step toward Pertinent Information Extraction
10-58:Genome Inform Ser Workshop Genome Inform
10-59:1998;9:72 80
10-60:Robertson S.E., Walker S
10-61:Okapi Keenbow at TREC 8
10-62:NIST Special Publication 500 246: TREC 8
10-63:Sackett D.L., and etc
10-64:Evidence Based Medicine: How to Practice and Teach EBM
10-65:Churchill Livingstone
10-66:Second edition, 2000
10-67:Swanson,D.R., Smalheiser,N.R
10-68:An interactive system for finding complemen tary literatures: a stimulus to scientific discovery
10-69:Artificial Intelligence, 1997; 91,183 203
10-70:Voorhees E
10-71:Query expansion using lexical semantic relations
10-72:SIGIR 1994
10-73:61 9 Zhong M., Huang X.J
10-74:Concept based biomedical text retrieval
10-75:SIGIR"06
10-76:723 4 Zhou W., Torvik V.I., Smalheiser N.R
10-77:ADAM: Another Database of Abbreviations in MEDLINE
10-78:Bioinformatics
10-79:2006; 22(22): 2813 2818
picture:
