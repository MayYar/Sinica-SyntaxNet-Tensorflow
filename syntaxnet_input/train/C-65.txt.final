Shooter Localization and Weapon Classification with 
content:
1 ABSTRACT :
1-1:The paper presents a wireless sensor network based mobile countersniper system .
1-2:A sensor node consists of a helmetmounted microphone array, a COTS MICAz mote for internode communication and a custom sensorboard that implements the acoustic detection and Time of Arrival (ToA) estimation algorithms on an FPGA .
1-3:A 3 axis compass provides self orientation and Bluetooth is used for communication with the soldier"s PDA running the data fusion and the user interface .
1-4:The heterogeneous sensor fusion algorithm can work with data from a single sensor or it can fuse ToA or Angle of Arrival (AoA) observations of muzzle blasts and ballistic shockwaves from multiple sensors .
1-5:The system estimates the trajectory, the range, the caliber and the weapon type .
1-6:The paper presents the system design and the results from an independent evaluation at the US Army Aberdeen Test Center .
1-7:The system performance is characterized by 1degree trajectory precision and over 95% caliber estimation accuracy for all shots, and close to 100% weapon estimation accuracy for 4 out of 6 guns tested .
1-8:C.2.4 [Computer Communications Networks]: The importance of countersniper systems is underscored by the constant stream of news reports coming from the Middle East .
1-9:In October 2006 CNN reported on a new tactic employed by insurgents .
1-10:A mobile sniper team moves around busy city streets in a car, positions itself at a good standoff distance from dismounted US military personnel, takes a single well aimed shot and immediately melts in the city traffic .
1-11:By the time the soldiers can react, they are gone .
1-12:A countersniper system that provides almost immediate shooter location to every soldier in the vicinity would provide clear benefits to the warfigthers .
1-13:Our team introduced PinPtr, the first sensor networkbased countersniper system [17, 8] in 2003 .
1-14:The system is based on potentially hundreds of inexpensive sensor nodes deployed in the area of interest forming an ad hoc multihop network .
1-15:The acoustic sensors measure the Time of Arrival (ToA) of muzzle blasts and ballistic shockwaves, pressure waves induced by the supersonic projectile, send the data to a base station where a sensor fusion algorithm determines the origin of the shot .
1-16:PinPtr is characterized by high precision: 1m average 3D accuracy for shots originating within or near the sensor network and 1 degree bearing precision for both azimuth and elevation and 10% accuracy in range estimation for longer range shots .
1-17:The truly unique characteristic of the system is that it works in such reverberant environments as cluttered urban terrain and that it can resolve multiple simultaneous shots at the same time .
1-18:This capability is due to the widely distributed sensing and the unique sensor fusion approach [8] .
1-19:The system has been tested several times in US Army MOUT (Military Operations in Urban Terrain) facilities .
1-20:The obvious disadvantage of such a system is its static nature .
1-21:Once the sensors are distributed, they cover a certain area .
1-22:Depending on the operation, the deployment may be needed for an hour or a month, but eventually the area looses its importance .
1-23:It is not practical to gather and reuse the sensors, especially under combat conditions .
1-24:Even if the sensors are cheap, it is still a waste and a logistical problem to provide a continuous stream of sensors as the operations move from place to place .
1-25:As it is primarily the soldiers that the system protects, a natural extension is to mount the sensors on the soldiers themselves .
1-26:While there are vehiclemounted countersniper systems [1] available commercially, we are not aware of a deployed system that protects dismounted soldiers .
1-27:A helmet mounted system was developed in the mid 90s by BBN [3], but it was not continued beyond the Darpa program that funded it .
1-28:113 To move from a static sensor network based solution to a highly mobile one presents significant challenges .
1-29:The sensor positions and orientation need to be constantly monitored .
1-30:As soldiers may work in groups of as little as four people, the number of sensors measuring the acoustic phenomena may be an order of magnitude smaller than before .
1-31:Moreover, the system should be useful to even a single soldier .
1-32:Finally, additional requirements called for caliber estimation and weapon classification in addition to source localization .
1-33:The paper presents the design and evaluation of our soldierwearable mobile countersniper system .
1-34:It describes the hardware and software architecture including the custom sensor board equipped with a small microphone array and connected to a COTS MICAz mote [12] .
1-35:Special emphasis is paid to the sensor fusion technique that estimates the trajectory, range, caliber and weapon type simultaneously .
1-36:The results and analysis of an independent evaluation of the system at the US Army Aberdeen Test Center are also presented. .
2 APPROACH :
2-1:The firing of a typical military rifle, such as the AK47 or M16, produces two distinct acoustic phenomena .
2-2:The muzzle blast is generated at the muzzle of the gun and travels at the speed sound .
2-3:The supersonic projectile generates an acoustic shockwave, a kind of sonic boom .
2-4:The wavefront has a conical shape, the angle of which depends on the Mach number, the speed of the bullet relative to the speed of sound .
2-5:The shockwave has a characteristic shape resembling a capital N .
2-6:The rise time at both the start and end of the signal is very fast, under 1 μsec .
2-7:The length is determined by the caliber and the miss distance, the distance between the trajectory and the sensor .
2-8:It is typically a few hundred μsec .
2-9:Once a trajectory estimate is available, the shockwave length can be used for caliber estimation .
2-10:Our system is based on four microphones connected to a sensorboard .
2-11:The board detects shockwaves and muzzle blasts and measures their ToA .
2-12:If at least three acoustic channels detect the same event, its AoA is also computed .
2-13:If both the shockwave and muzzle blast AoA are available, a simple analytical solution gives the shooter location as shown in Section 6 .
2-14:As the microphones are close to each other, typically 2 4, we cannot expect very high precision .
2-15:Also, this method does not estimate a trajectory .
2-16:In fact, an infinite number of trajectory bullet speed pairs satisfy the observations .
2-17:However, the sensorboards are also connected to COTS MICAz motes and they share their AoA and ToA measurements, as well as their own location and orientation, with each other using a multihop routing service [9] .
2-18:A hybrid sensor fusion algorithm then estimates the trajectory, the range, the caliber and the weapon type based on all available observations .
2-19:The sensorboard is also Bluetooth capable for communication with the soldier"s PDA or laptop computer .
2-20:A wired USB connection is also available .
2-21:The sensorfusion algorithm and the user interface get their data through one of these channels .
2-22:The orientation of the microphone array at the time of detection is provided by a 3 axis digital compass .
2-23:Currently the system assumes that the soldier"s PDA is GPS capable and it does not provide self localization service itself .
2-24:However, the accuracy of GPS is a few meters degrading the Figure 1: Acoustic sensorboard mote assembly .
2-25:overall accuracy of the system .
2-26:Refer to Section 7 for an analysis .
2-27:The latest generation sensorboard features a Texas Instruments CC 1000 radio enabling the high precision radio interferometric self localization approach we have developed separately [7] .
2-28:However, we leave the integration of the two technologies for future work. .
3 HARDWARE :
3-1:Since the first static version of our system in 2003, the sensor nodes have been built upon the UC Berkeley Crossbow MICA product line [11] .
3-2:Although rudimentary acoustic signal processing can be done on these microcontroller based boards, they do not provide the required computational performance for shockwave detection and angle of arrival measurements, where multiple signals from different microphones need to be processed in parallel at a high sampling rate .
3-3:Our 3rd generation sensorboard is designed to be used with MICAz motes in fact it has almost the same size as the mote itself (see Figure 1) .
3-4:The board utilizes a powerful Xilinx XC3S1000 FPGA chip with various standard peripheral IP cores, multiple soft processor cores and custom logic for the acoustic detectors (Figure 2) .
3-5:The onboard Flash (4MB) and PSRAM (8MB) modules allow storing raw samples of several acoustic events, which can be used to build libraries of various acoustic signatures and for refining the detection cores off line .
3-6:Also, the external memory blocks can store program code and data used by the soft processor cores on the FPGA .
3-7:The board supports four independent analog channels sampled at up to 1 MS s (million samples per seconds) .
3-8:These channels, featuring an electret microphone (Panasonic WM64PNT), amplifiers with controllable gain (30 60 dB) and a 12 bit serial ADC (Analog Devices AD7476), reside on separate tiny boards which are connected to the main sensorboard with ribbon cables .
3-9:This partitioning enables the use of truly different audio channels (eg.: slower sampling frequency, different gain or dynamic range) and also results in less noisy measurements by avoiding long analog signal paths .
3-10:The sensor platform offers a rich set of interfaces and can be integrated with existing systems in diverse ways .
3-11:An RS232 port and a Bluetooth (BlueGiga WT12) wireless link with virtual UART emulation are directly available on the board and provide simple means to connect the sensor to PCs and PDAs .
3-12:The mote interface consists of an I2 C bus along with an interrupt and GPIO line (the latter one is used 114 Figure 2: Block diagram of the sensorboard .
3-13:for precise time synchronization between the board and the mote) .
3-14:The motes are equipped with IEEE 802.15.4 compliant radio transceivers and support ad hoc wireless networking among the nodes and to from the base station .
3-15:The sensorboard also supports full speed USB transfers (with custom USB dongles) for uploading recorded audio samples to the PC .
3-16:The on board JTAG chain directly accessible through a dedicated connector contains the FPGA part and configuration memory and provides in system programming and debugging facilities .
3-17:The integrated Honeywell HMR3300 digital compass module provides heading, pitch and roll information with 1◦ accuracy, which is essential for calculating and combining directional estimates of the detected events .
3-18:Due to the complex voltage requirements of the FPGA, the power supply circuitry is implemented on the sensorboard and provides power both locally and to the mote .
3-19:We used a quad pack of rechargeable AA batteries as the power source (although any other configuration is viable that meets the voltage requirements) .
3-20:The FPGA core (1.2 V) and I O (3.3 V) voltages are generated by a highly efficient buck switching regulator .
3-21:The FPGA configuration (2.5 V) and a separate 3.3 V power net are fed by low current LDOs, the latter one is used to provide independent power to the mote and to the Bluetooth radio .
3-22:The regulators except the last one can be turned on off from the mote or through the Bluetooth radio (via GPIO lines) to save power .
3-23:The first prototype of our system employed 10 sensor nodes .
3-24:Some of these nodes were mounted on military kevlar helmets with the microphones directly attached to the surface at about 20 cm separation as shown in Figure 3(a) .
3-25:The rest of the nodes were mounted in plastic enclosures (Figure 3(b)) with the microphones placed near the corners of the boxes to form approximately 5 cm×10 cm rectangles. .
4 SOFTWARE ARCHITECTURE :
4-1:The sensor application relies on three subsystems exploiting three different computing paradigms as they are shown in Figure 4 .
4-2:Although each of these execution models suit their domain specific tasks extremely well, this diversity (a) (b) Figure 3: Sensor prototypes mounted on a kevlar helmet (a) and in a plastic box on a tripod (b) .
4-3:presents a challenge for software development and system integration .
4-4:The sensor fusion and user interface subsystem is running on PDAs and were implemented in Java .
4-5:The sensing and signal processing tasks are executed by an FPGA, which also acts as a bridge between various wired and wireless communication channels .
4-6:The ad hoc internode communication, time synchronization and data sharing are the responsibilities of a microcontroller based radio module .
4-7:Similarly, the application employs a wide variety of communication protocols such as Bluetooth and IEEE 802.14.5 wireless links, as well as optional UARTs, I2 C and or USB buses .
4-8:Soldier Operated Device (PDA Laptop) FPGA Sensor Board Mica Radio Module 2.4 GHz Wireless Link Radio Control Message Routing Acoustic Event Encoder Sensor Time Synch .
4-9:Network Time Synch.Remote Control Time stamping Interrupts Virtual Register Interface C O O R D I N A T O R A n a l o g c h a n n e l s Compass PicoBlaze Comm .
4-10:Interface PicoBlaze WT12 Bluetooth Radio MOTE IF:I2C,Interrupts USB PSRAM U A R T U A R T MB det SW det REC Bluetooth Link User Interface Sensor Fusion Location Engine GPS Message (Dis )AssemblerSensor Control Figure 4: Software architecture diagram .
4-11:The sensor fusion module receives and unpacks raw measurements (time stamps and feature vectors) from the sensorboard through the Bluetooth link .
4-12:Also, it fine tunes the execution of the signal processing cores by setting parameters through the same link .
4-13:Note that measurements from other nodes along with their location and orientation information also arrive from the sensorboard which acts as a gateway between the PDA and the sensor network .
4-14:The handheld device obtains its own GPS location data and di115 rectly receives orientation information through the sensorboard .
4-15:The results of the sensor fusion are displayed on the PDA screen with low latency .
4-16:Since, the application is implemented in pure Java, it is portable across different PDA platforms .
4-17:The border between software and hardware is considerably blurred on the sensor board .
4-18:The IP cores implemented in hardware description languages on the reconfigurable FPGA fabric closely resemble hardware building blocks .
4-19:However, some of them most notably the soft processor cores execute true software programs .
4-20:The primary tasks of the sensor board software are 1) acquiring data samples from the analog channels, 2) processing acoustic data (detection), and 3) providing access to the results and run time parameters through different interfaces .
4-21:As it is shown in Figure 4, a centralized virtual register file contains the address decoding logic, the registers for storing parameter values and results and the point to point data buses to and from the peripherals .
4-22:Thus, it effectively integrates the building blocks within the sensorboard and decouples the various communication interfaces .
4-23:This architecture enabled us to deploy the same set of sensors in a centralized scenario, where the ad hoc mote network (using the I2 C interface) collected and forwarded the results to a base station or to build a decentralized system where the local PDAs execute the sensor fusion on the data obtained through the Bluetooth interface (and optionally from other sensors through the mote interface) .
4-24:The same set of registers are also accessible through a UART link with a terminal emulation program .
4-25:Also, because the low level interfaces are hidden by the register file, one can easily add replace these with new ones (eg.: the first generation of motes supported a standard μP interface bus on the sensor connector, which was dropped in later designs) .
4-26:The most important results are the time stamps of the detected events .
4-27:These time stamps and all other timing information (parameters, acoustic event features) are based on a 1 MHz clock and an internal timer on the FPGA .
4-28:The time conversion and synchronization between the sensor network and the board is done by the mote by periodically requesting the capture of the current timer value through a dedicated GPIO line and reading the captured value from the register file through the I2 C interface .
4-29:Based on the the current and previous readings and the corresponding mote local time stamps, the mote can calculate and maintain the scaling factor and offset between the two time domains .
4-30:The mote interface is implemented by the I2 C slave IP core and a thin adaptation layer which provides a data and address bus abstraction on top of it .
4-31:The maximum effective bandwidth is 100 Kbps through this interface .
4-32:The FPGA contains several UART cores as well: for communicating with the on board Bluetooth module, for controlling the digital compass and for providing a wired RS232 link through a dedicated connector .
4-33:The control, status and data registers of the UART modules are available through the register file .
4-34:The higher level protocols on these lines are implemented by Xilinx PicoBlaze microcontroller cores [13] and corresponding software programs .
4-35:One of them provides a command line interface for test and debug purposes, while the other is responsible for parsing compass readings .
4-36:By default, they are connected to the RS232 port and to the on board digital compass line respectively, however, they can be rewired to any communication interface by changing the register file base address in the programs (e.g .
4-37:the command line interface can be provided through the Bluetooth channel) .
4-38:Two of the external interfaces are not accessible through the register file: a high speed USB link and the SRAM interface are tied to the recorder block .
4-39:The USB module implements a simple FIFO with parallel data lines connected to an external FT245R USB device controller .
4-40:The RAM driver implements data read write cycles with correct timing and is connected to the on board pseudo SRAM .
4-41:These interfaces provide 1 MB s effective bandwidth for downloading recorded audio samples, for example .
4-42:The data acquisition and signal processing paths exhibit clear symmetry: the same set of IP cores are instantiated four times (i.e .
4-43:the number of acoustic channels) and run independently .
4-44:The signal paths meet only just before the register file .
4-45:Each of the analog channels is driven by a serial A D core for providing a 20 MHz serial clock and shifting in 8 bit data samples at 1 MS s and a digital potentiometer driver for setting the required gain .
4-46:Each channel has its own shockwave and muzzle blast detector, which are described in Section 5 .
4-47:The detectors fetch run time parameter values from the register file and store their results there as well .
4-48:The coordinator core constantly monitors the detection results and generates a mote interrupt promptly upon full detection or after a reasonable timeout after partial detection .
4-49:The recorder component is not used in the final deployment, however, it is essential for development purposes for refining parameter values for new types of weapons or for other acoustic sources .
4-50:This component receives the samples from all channels and stores them in circular buffers in the PSRAM device .
4-51:If the signal amplitude on one of the channels crosses a predefined threshold, the recorder component suspends the sample collection with a predefined delay and dumps the contents of the buffers through the USB link .
4-52:The length of these buffers and delays, the sampling rate, the threshold level and the set of recorded channels can be (re)configured run time through the register file .
4-53:Note that the core operates independently from the other signal processing modules, therefore, it can be used to validate the detection results off line .
4-54:The FPGA cores are implemented in VHDL, the PicoBlaze programs are written in assembly .
4-55:The complete configuration occupies 40% of the resources (slices) of the FPGA and the maximum clock speed is 30 MHz, which is safely higher than the speed used with the actual device (20MHz) .
4-56:The MICAz motes are responsible for distributing measurement data across the network, which drastically improves the localization and classification results at each node .
4-57:Besides a robust radio layer, the motes require two essential middleware services to achieve this goal .
4-58:The messages need to be propagated in the ad hoc multihop network using a routing service .
4-59:We successfully integrated the Directed Flood Routing Framework [9] in our application .
4-60:Apart from automatic message aggregation and efficient buffer management, the most unique feature of DFRF is its plug in architecture, which accepts custom routing policies .
4-61:Routing policies are state machines that govern how received messages are stored, resent or discarded .
4-62:Example policies include spanning tree routing, broadcast, geographic routing, etc .
4-63:Different policies can be used for different messages concurrently, and the application is able to 116 change the underlying policies at run time (eg.: because of the changing RF environment or power budget) .
4-64:In fact, we switched several times between a simple but lavish broadcast policy and a more efficient gradient routing on the field .
4-65:Correlating ToA measurements requires a common time base and precise time synchronization in the sensor network .
4-66:The Routing Integrated Time Synchronization [15] protocol relies on very accurate MAC layer time stamping to embed the cumulative delay that a data message accrued since the time of the detection in the message itself .
4-67:That is, at every node it measures the time the message spent there and adds this to the number in the time delay slot of the message, right before it leaves the current node .
4-68:Every receiving node can subtract the delay from its current time to obtain the detection time in its local time reference .
4-69:The service provides very accurate time conversion (few μs per hop error), which is more than adequate for this application .
4-70:Note, that the motes also need to convert the sensorboard time stamps to mote time as it is described earlier .
4-71:The mote application is implemented in nesC [5] and is running on top of TinyOS [6] .
4-72:With its 3 KB RAM and 28 KB program space requirement, it easily fits on the MICAz motes. .
5 DETECTION ALGORITHM :
5-1:There are several characteristics of acoustic shockwaves and muzzle blasts which distinguish their detection and signal processing algorithms from regular audio applications .
5-2:Both events are transient by their nature and present very intense stimuli to the microphones .
5-3:This is increasingly problematic with low cost electret microphones designed for picking up regular speech or music .
5-4:Although mechanical damping of the microphone membranes can mitigate the problem, this approach is not without side effects .
5-5:The detection algorithms have to be robust enough to handle severe nonlinear distortion and transitory oscillations .
5-6:Since the muzzle blast signature closely follows the shockwave signal and because of potential automatic weapon bursts, it is extremely important to settle the audio channels and the detection logic as soon as possible after an event .
5-7:Also, precise angle of arrival estimation necessitates high sampling frequency (in the MHz range) and accurate event detection .
5-8:Moreover, the detection logic needs to process multiple channels in parallel (4 channels on our existing hardware) .
5-9:These requirements dictated simple and robust algorithms both for muzzle blast and shockwave detections .
5-10:Instead of using mundane energy detectors which might not be able to distinguish the two different events the applied detectors strive to find the most important characteristics of the two signals in the time domain using simple state machine logic .
5-11:The detectors are implemented as independent IP cores within the FPGA one pair for each channel .
5-12:The cores are run time configurable and provide detection event signals with high precision time stamps and event specific feature vectors .
5-13:Although the cores are running independently and in parallel, a crude local fusion module integrates them by shutting down those cores which missed their events after a reasonable timeout and by generating a single detection message towards the mote .
5-14:At this point, the mote can read and forward the detection times and features and is responsible to restart the cores afterwards .
5-15:The most conspicuous characteristics of an acoustic shockwave (see Figure 5(a)) are the steep rising edges at the be0 200 400 600 800 1000 1200 1400 1600 1 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 1 Shockwave (M16) Time (µs) Amplitude 1 3 5 2 4 len (a) s[t] s[t D] > E tstart := t s[t] s[t D] < E s[t] s[t D] > E & t t_start > Lmin s[t] s[t D] < E len := t tstart IDLE 1 FIRST EDGE DONE 3 SECOND EDGE 4 FIRST EDGE 2 FOUND 5 t tstart ≥ Lmax t tstart ≥ Lmax (b) Figure 5: Shockwave signal generated by a 5.56 × 45 mm NATO projectile (a) and the state machine of the detection algorithm (b) .
5-16:ginning and end of the signal .
5-17:Also, the length of the N wave is fairly predictable as it is described in Section 6.5 and is relatively short (200 300 μs) .
5-18:The shockwave detection core is continuously looking for two rising edges within a given interval .
5-19:The state machine of the algorithm is shown in Figure 5(b) .
5-20:The input parameters are the minimum steepness of the edges (D, E), and the bounds on the length of the wave (Lmin, Lmax) .
5-21:The only feature calculated by the core is the length of the observed shockwave signal .
5-22:In contrast to shockwaves, the muzzle blast signatures are characterized by a long initial period (1 5 ms) where the first half period is significantly shorter than the second half [4] .
5-23:Due to the physical limitations of the analog circuitry described at the beginning of this section, irregular oscillations and glitches might show up within this longer time window as they can be clearly seen in Figure 6(a) .
5-24:Therefore, the real challenge for the matching detection core is to identify the first and second half periods properly .
5-25:The state machine (Figure 6(b)) does not work on the raw samples directly but is fed by a zero crossing encoder .
5-26:After the initial triggering, the detector attempts to collect those ZC segments which belong to the first period (positive amplitude) while discarding too short (in our terminology: garbage) segments effectively implementing a rudimentary low pass filter in the ZC domain .
5-27:After it encounters a sufficiently long negative segment, it runs the same collection logic for the second half period .
5-28:If too much garbage is discarded in the collection phases, the core resets itself to prevent the (false) detection of the halves from completely different periods separated by rapid oscillation or noise .
5-29:Finally, if the constraints on the total length and on the length ratio hold, the core generates a detection event along with the actual length, amplitude and energy of the period calculated concurrently .
5-30:The initial triggering mechanism is based on two amplitude thresholds: one static (but configurable) amplitude level and a dynamically computed one .
5-31:The latter one is essential to adapt the sensor to different ambient noise environments and to temporarily suspend the muzzle blast detector after a shock wave event (oscillations in the analog section or reverberations in the sensor enclosure might otherwise trigger false muzzle blast detections) .
5-32:The dynamic noise level is estimated by a single pole recursive low pass filter (cutoff @ 0.5 kHz ) on the FPGA .
5-33:117 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 1 0.8 0.6 0.4 0.2 0 0.2 0.4 0.6 0.8 1 Time (µs) Amplitude Muzzle blast (M16) 1 2 3 4 5 len2 + len1 (a) IDLE 1 SECOND ZC 3 PENDING ZC 4 FIRST ZC 2 FOUND 5 amplitude threshold long positive ZC long negative ZC valid full period max garbage wrong sign garbage collect first period garbage collect first period garbage (b) Figure 6: Muzzle blast signature (a) produced by an M16 assault rifle and the corresponding detection logic (b) .
5-34:The detection cores were originally implemented in Java and evaluated on pre recorded signals because of much faster test runs and more convenient debugging facilities .
5-35:Later on, they were ported to VHDL and synthesized using the Xilinx ISE tool suite .
5-36:The functional equivalence between the two implementations were tested by VHDL test benches and Python scripts which provided an automated way to exercise the detection cores on the same set of pre recorded signals and to compare the results. .
6 SENSOR FUSION :
6-1:The sensor fusion algorithm receives detection messages from the sensor network and estimates the bullet trajectory, the shooter position, the caliber of the projectile and the type of the weapon .
6-2:The algorithm consists of well separated computational tasks outlined below: arrivals for each individual sensor (see 6.1) .
6-3:analytically fuse a pair of shockwave and muzzle blast AoA estimates .
6-4:(see 6.2) .
6-5:measurements (see 6.3) .
6-6:else compute shooter position first and then trajectory based on it .
6-7:(see 6.4) We describe each step in the following sections in detail .
6-8:6.1 Direction of arrival The first step of the sensor fusion is to calculate the muzzle blast and shockwave AoA s for each sensorboard .
6-9:Each sensorboard has four microphones that measure the ToA s .
6-10:Since the microphone spacing is orders of magnitude smaller than the distance to the sound source, we can approximate the approaching sound wave front with a plane (far field assumption) .
6-11:Let us formalize the problem for 3 microphones first .
6-12:Let P1, P2 and P3 be the position of the microphones ordered by time of arrival t1 < t2 < t3 .
6-13:First we apply a simple geometry validation step .
6-14:The measured time difference between two microphones cannot be larger than the sound propagation time between the two microphones: |ti − tj| <= |Pi − Pj | c + ε Where c is the speed of sound and ε is the maximum measurement error .
6-15:If this condition does not hold, the corresponding detections are discarded .
6-16:Let v(x, y, z) be the normal vector of the unknown direction of arrival .
6-17:We also use r1(x1, y1, z1), the vector from P1 to P2 and r2(x2, y2, z2), the vector from P1 to P3 .
6-18:Let"s consider the projection of the direction of the motion of the wave front (v) to r1 divided by the speed of sound (c) .
6-19:This gives us how long it takes the wave front to propagate form P1 to P2: vr1 = c(t2 − t1) The same relationship holds for r2 and v: vr2 = c(t3 − t1) We also know that v is a normal vector: vv = 1 Moving from vectors to coordinates using the dot product definition leads to a quadratic system: xx1 + yy1 + zz1 = c(t2 − t1) xx2 + yy2 + zz2 = c(t3 − t1) x2 + y2 + z2 = 1 We omit the solution steps here, as they are straightforward, but long .
6-20:There are two solutions (if the source is on the P1P2P3 plane the two solutions coincide) .
6-21:We use the fourth microphone"s measurement if there is one to eliminate one of them .
6-22:Otherwise, both solutions are considered for further processing .
6-23:6.2 Muzzle shock fusion u v 11,tP 22,tP tP, 2P′ Bullet trajectory Figure 7: Section plane of a shot (at P) and two sensors (at P1 and at P2) .
6-24:One sensor detects the muzzle blast"s, the other the shockwave"s time and direction of arrivals .
6-25:Consider the situation in Figure 7 .
6-26:A shot was fired from P at time t .
6-27:Both P and t are unknown .
6-28:We have one muzzle blast and one shockwave detections by two different sensors 118 with AoA and hence, ToA information available .
6-29:The muzzle blast detection is at position P1 with time t1 and AoA measurements are sufficient to compute the position of the shooter .
6-30:Let P2 be the point on the extended shockwave cone surface where PP2 is perpendicular to the surface .
6-31:Note that PP2 is parallel with v .
6-32:Since P2 is on the cone surface which hits P2, a sensor at P2 would detect the same shockwave time of arrival (t2) .
6-33:The cone surface travels at the speed of sound (c), so we can express P using P2: P = P2 + cv(t2 − t) .
6-34:P can also be expressed from P1: P = P1 + cu(t1 − t) yielding P1 + cu(t1 − t) = P2 + cv(t2 − t) .
6-35:P2P2 is perpendicular to v: (P2 − P2)v = 0 yielding (P1 + cu(t1 − t) − cv(t2 − t) − P2)v = 0 containing only one unknown t .
6-36:One obtains: t = (P1−P2)v c +uvt1−t2 uv−1 .
6-37:From here we can calculate the shoter position P .
6-38:Let"s consider the special single sensor case where P1 = P2 (one sensor detects both shockwave and muzzle blast AoA) .
6-39:In this case: t = uvt1−t2 uv−1 .
6-40:Since u and v are not used separately only uv, the absolute orientation of the sensor can be arbitrary, we still get t which gives us the range .
6-41:Here we assumed that the shockwave is a cone which is only true for constant projectile speeds .
6-42:In reality, the angle of the cone slowly grows; the surface resembles one half of an American football .
6-43:The decelerating bullet results in a smaller time difference between the shockwave and the muzzle blast detections because the shockwave generation slows down with the bullet .
6-44:A smaller time difference results in a smaller range, so the above formula underestimates the true range .
6-45:However, it can still be used with a proper deceleration correction function .
6-46:We leave this for future work .
6-47:6.3 Trajectory estimation Danicki showed that the bullet trajectory and speed can be computed analytically from two independent shockwave measurements where both ToA and AoA are measured [2] .
6-48:The method gets more sensitive to measurement errors as the two shockwave directions get closer to each other .
6-49:In the special case when both directions are the same, the trajectory cannot be computed .
6-50:In a real world application, the sensors are typically deployed on a plane approximately .
6-51:In this case, all sensors located on one side of the trajectory measure almost the same shockwave AoA .
6-52:To avoid this error sensitivity problem, we consider shockwave measurement pairs only if the direction of arrival difference is larger than a certain threshold .
6-53:We have multiple sensors and one sensor can report two different directions (when only three microphones detect the shockwave) .
6-54:Hence, we typically have several trajectory candidates, i.e .
6-55:one for each AoA pair over the threshold .
6-56:We applied an outlier filtering and averaging method to fuse together the shockwave direction and time information and come up with a single trajectory .
6-57:Assume that we have N individual shockwave AoA measurements .
6-58:Let"s take all possible unordered pairs where the direction difference is above the mentioned threshold and compute the trajectory for each .
6-59:This gives us at most N(N−1) 2 trajectories .
6-60:A trajectory is represented by one point pi and the normal vector vi (where i is the trajectory index) .
6-61:We define the distance of two trajectories as the dot product of their normal vectors: D(i, j) = vivj For each trajectory a neighbor set is defined: N(i) := {j|D(i, j) < R} where R is a radius parameter .
6-62:The largest neighbor set is considered to be the core set C, all other trajectories are outliers .
6-63:The core set can be found in O(N2 ) time .
6-64:The trajectories in the core set are then averaged to get the final trajectory .
6-65:It can happen that we cannot form any sensor pairs because of the direction difference threshold .
6-66:It means all sensors are on the same side of the trajectory .
6-67:In this case, we first compute the shooter position (described in the next section) that fixes p making v the only unknown .
6-68:To find v in this case, we use a simple high resolution grid search and minimize an error function based on the shockwave directions .
6-69:We have made experiments to utilize the measured shockwave length in the trajectory estimation .
6-70:There are some promising results, but it needs further research .
6-71:6.4 Shooter position estimation The shooter position estimation algorithm aggregates the following heterogenous information generated by earlier computational steps: .
7 trajectory, :
7-1:.
8 muzzle blast ToA at a sensor, :
8-1:bearing estimate to the shooter, and muzzle blast AoA are available) .
8-2:Some sensors report only ToA, some has bearing estimate(s) also and some has range estimate(s) as well, depending on the number of successful muzzle blast and shockwave detections by the sensor .
8-3:For an example, refer to Figure 8 .
8-4:Note that a sensor may have two different bearing and range estimates .
8-5:3 detections gives two possible AoA s for muzzle blast (i.e .
8-6:bearing) and or shockwave .
8-7:Furthermore, the combination of two different muzzle blast and shockwave AoA s may result in two different ranges .
8-8:119 11111 ,,,, rrvvt ′′ 22 ,vt 333 ,, vvt ′ 4t 5t 6t bullet trajectory shooter position Figure 8: Example of heterogenous input data for the shooter position estimation algorithm .
8-9:All sensors have ToA measurements (t1, t2, t3, t4, t5), one sensor has a single bearing estimate (v2), one sensor has two possible bearings (v3, v3) and one sensor has two bearing and two range estimates (v1, v1,r1, r1) In a multipath environment, these detections will not only contain gaussian noise, but also possibly large errors due to echoes .
8-10:It has been showed in our earlier work that a similar problem can be solved efficiently with an interval arithmetic based bisection search algorithm [8] .
8-11:The basic idea is to define a discrete consistency function over the area of interest and subdivide the space into 3D boxes .
8-12:For any given 3D box, this function gives the number of measurements supporting the hypothesis that the shooter was within that box .
8-13:The search starts with a box large enough to contain the whole area of interest, then zooms in by dividing and evaluating boxes .
8-14:The box with the maximum consistency is divided until the desired precision is reached .
8-15:Backtracking is possible to avoid getting stuck in a local maximum .
8-16:This approach has been shown to be fast enough for online processing .
8-17:Note, however, that when the trajectory has already been calculated in previous steps, the search needs to be done only on the trajectory making it orders of magnitude faster .
8-18:Next let us describe how the consistency function is calculated in detail .
8-19:Consider B, a three dimensional box, we would like to compute the consistency value of .
8-20:First we consider only the ToA information .
8-21:If one sensor has multiple ToA detections, we use the average of those times, so one sensor supplies at most one ToA estimate .
8-22:For each ToA, we can calculate the corresponding time of the shot, since the origin is assumed to be in box B .
8-23:Since it is a box and not a single point, this gives us an interval for the shot time .
8-24:The maximum number of overlapping time intervals gives us the value of the consistency function for B .
8-25:For a detailed description of the consistency function and search algorithm, refer to [8] .
8-26:Here we extend the approach the following way .
8-27:We modify the consistency function based on the bearing and range data from individual sensors .
8-28:A bearing estimate supports B if the line segment starting from the sensor with the measured direction intersects the B box .
8-29:A range supports B, if the sphere with the radius of the range and origin of the sensor intersects B .
8-30:Instead of simply checking whether the position specified by the corresponding bearing range pairs falls within B, this eliminates the sensor"s possible orientation error .
8-31:The value of the consistency function is incremented by one for each bearing and range estimate that is consistent with B .
8-32:6.5 Caliber estimation The shockwave signal characteristics has been studied before by Whitham [20] .
8-33:He showed that the shockwave period T is related to the projectile diameter d, the length l, the perpendicular miss distance b from the bullet trajectory to the sensor, the Mach number M and the speed of sound c .
8-34:T = 1.82Mb1 4 c(M2−1)3 8 d l1 4 ≈ 1.82d c (Mb l )1 4 0 100 200 300 400 500 600 0 10 20 30 miss distance (m)shockwavelength(microseconds) .50 cal 5.56 mm 7.62 mm Figure 9: Shockwave length and miss distance relationship .
8-35:Each data point represents one sensorboard after an aggregation of the individual measurements of the four acoustic channels .
8-36:Three different caliber projectiles have been tested (196 shots, 10 sensors) .
8-37:To illustrate the relationship between miss distance and shockwave length, here we use all 196 shots with three different caliber projectiles fired during the evaluation .
8-38:(During the evaluation we used data obtained previously using a few practice shots per weapon.) 10 sensors (4 microphones by sensor) measured the shockwave length .
8-39:For each sensor, we considered the shockwave length estimation valid if at least three out of four microphones agreed on a value with at most 5 microsecond variance .
8-40:This filtering leads to a 86% report rate per sensor and gets rid of large measurement errors .
8-41:The experimental data is shown in Figure 9 .
8-42:Whitham"s formula suggests that the shockwave length for a given caliber can be approximated with a power function of the miss distance (with a 1 4 exponent) .
8-43:Best fit functions on our data are: .50 cal: T = 237.75b0.2059 7.62 mm: T = 178.11b0.1996 5.56 mm: T = 144.39b0.1757 To evaluate a shot, we take the caliber whose approximation function results in the smallest RMS error of the filtered sensor readings .
8-44:This method has less than 1% caliber estimation error when an accurate trajectory estimate is available .
8-45:In other words, caliber estimation only works if enough shockwave detections are made by the system to compute a trajectory .
8-46:120 6.6 Weapon estimation We analyzed all measured signal characteristics to find weapon specific information .
8-47:Unfortunately, we concluded that the observed muzzle blast signature is not characteristic enough of the weapon for classification purposes .
8-48:The reflections of the high energy muzzle blast from the environment have much higher impact on the muzzle blast signal shape than the weapon itself .
8-49:Shooting the same weapon from different places caused larger differences on the recorded signal than shooting different weapons from the same place .
8-50:0 100 200 300 400 500 600 700 800 900 0 100 200 300 400 range (m) speed(m s) AK 47 M240 Figure 10: AK47 and M240 bullet deceleration measurements .
8-51:Both weapons have the same caliber .
8-52:Data is approximated using simple linear regression .
8-53:0 100 200 300 400 500 600 700 800 900 1000 0 50 100 150 200 250 300 350 range (m) speed(m s) M16 M249 M4 Figure 11: M16, M249 and M4 bullet deceleration measurements .
8-54:All weapons have the same caliber .
8-55:Data is approximated using simple linear regression .
8-56:However, the measured speed of the projectile and its caliber showed good correlation with the weapon type .
8-57:This is because for a given weapon type and ammunition pair, the muzzle velocity is nearly constant .
8-58:In Figures 10 and 11 we can see the relationship between the range and the measured bullet speed for different calibers and weapons .
8-59:In the supersonic speed range, the bullet deceleration can be approximated with a linear function .
8-60:In case of the 7.62 mm caliber, the two tested weapons (AK47, M240) can be clearly separated (Figure 10) .
8-61:Unfortunately, this is not necessarily true for the 5.56 mm caliber .
8-62:The M16 with its higher muzzle speed can still be well classified, but the M4 and M249 weapons seem practically undistinguishable (Figure 11) .
8-63:However, this may be partially due to the limited number of practice shots we were able to take before the actual testing began .
8-64:More training data may reveal better separation between the two weapons since their published muzzle velocities do differ somewhat .
8-65:The system carries out weapon classification in the following manner .
8-66:Once the trajectory is known, the speed can be calculated for each sensor based on the shockwave geometry .
8-67:To evaluate a shot, we choose the weapon type whose deceleration function results in the smallest RMS error of the estimated range speed pairs for the estimated caliber class. .
9 RESULTS :
9-1:An independent evaluation of the system was carried out by a team from NIST at the US Army Aberdeen Test Center in April 2006 [19] .
9-2:The experiment was setup on a shooting range with mock up wooden buildings and walls for supporting elevated shooter positions and generating multipath effects .
9-3:Figure 12 shows the user interface with an aerial photograph of the site .
9-4:10 sensor nodes were deployed on surveyed points in an approximately 30×30 m area .
9-5:There were five fixed targets behind the sensor network .
9-6:Several firing positions were located at each of the firing lines at 50, 100, 200 and 300 meters .
9-7:These positions were known to the evaluators, but not to the operators of the system .
9-8:Six different weapons were utilized: AK47 and M240 firing 7.62 mm projectiles, M16, M4 and M249 with 5.56mm ammunition and the .50 caliber M107 .
9-9:Note that the sensors remained static during the test .
9-10:The primary reason for this is that nobody is allowed downrange during live fire tests .
9-11:Utilizing some kind of remote control platform would have been too involved for the limited time the range was available for the test .
9-12:The experiment, therefore, did not test the mobility aspect of the system .
9-13:During the one day test, there were 196 shots fired .
9-14:The results are summarized in Table 1 .
9-15:The system detected all shots successfully .
9-16:Since a ballistic shockwave is a unique acoustic phenomenon, it makes the detection very robust .
9-17:There were no false positives for shockwaves, but there were a handful of false muzzle blast detections due to parallel tests of artillery at a nearby range .
9-18:Shooter Local Caliber Trajectory Trajectory Distance No .
9-19:Range ization Accu Azimuth Distance Error of (m) Rate racy Error (deg) Error (m) (m) Shots 50 93% 100% 0.86 0.91 2.2 54 100 100% 100% 0.66 1.34 8.7 54 200 96% 100% 0.74 2.71 32.8 54 300 97% 97% 1.49 6.29 70.6 34 All 96% 99.5% 0.88 2.47 23.0 196 Table 1: Summary of results fusing all available sensor observations .
9-20:All shots were successfully detected, so the detection rate is omitted .
9-21:Localization rate means the percentage of shots that the sensor fusion was able to estimate the trajectory of .
9-22:The caliber accuracy rate is relative to the shots localized and not all the shots because caliber estimation requires the trajectory .
9-23:The trajectory error is broken down to azimuth in degrees and the actual distance of the shooter from the trajectory .
9-24:The distance error shows the distance between the real shooter position and the estimated shooter position .
9-25:As such, it includes the error caused by both the trajectory and that of the range estimation .
9-26:Note that the traditional bearing and range measures are not good ones for a distributed system such as ours because of the lack of a single reference point .
9-27:121 Figure 12: The user interface of the system showing the experimental setup .
9-28:The 10 sensor nodes are labeled by their ID and marked by dark circles .
9-29:The targets are black squares marked T 1 through T 5 .
9-30:The long white arrows point to the shooter position estimated by each sensor .
9-31:Where it is missing, the corresponding sensor did not have enough detections to measure the AoA of either the muzzle blast, the shockwave or both .
9-32:The thick black line and large circle indicate the estimated trajectory and the shooter position as estimated by fusing all available detections from the network .
9-33:This shot from the 100 meter line at target T 3 was localized almost perfectly by the sensor network .
9-34:The caliber and weapon were also identified correctly .
9-35:6 out of 10 nodes were able to estimate the location alone .
9-36:Their bearing accuracy is within a degree, while the range is off by less than 10% in the worst case .
9-37:The localization rate characterizes the system"s ability to successfully estimate the trajectory of shots .
9-38:Since caliber estimation and weapon classification relies on the trajectory, non localized shots are not classified either .
9-39:There were 7 shots out of 196 that were not localized .
9-40:The reason for missed shots is the trajectory ambiguity problem that occurs when the projectile passes on one side of all the sensors .
9-41:In this case, two significantly different trajectories can generate the same set of observations (see [8] and also Section 6.3) .
9-42:Instead of estimating which one is more likely or displaying both possibilities, we decided not to provide a trajectory at all .
9-43:It is better not to give an answer other than a shot alarm than misleading the soldier .
9-44:Localization accuracy is broken down to trajectory accuracy and range estimation precision .
9-45:The angle of the estimated trajectory was better than 1 degree except for the 300 m range .
9-46:Since the range should not affect trajectory estimation as long as the projectile passes over the network, we suspect that the slightly worse angle precision for 300 m is due to the hurried shots we witnessed the soldiers took near the end of the day .
9-47:This is also indicated by another datapoint: the estimated trajectory distance from the actual targets has an average error of 1.3 m for 300 m shots, 0.75 m for 200 m shots and 0.6 m for all but 300 m shots .
9-48:As the distance between the targets and the sensor network was fixed, this number should not show a 2× improvement just because the shooter is closer .
9-49:Since the angle of the trajectory itself does not characterize the overall error there can be a translation alsoTable 1 also gives the distance of the shooter from the estimated trajectory .
9-50:These indicate an error which is about 1 2% of the range .
9-51:To put this into perspective, a trajectory estimate for a 100 m shot will very likely go through or very near the window the shooter is located at .
9-52:Again, we believe that the disproportionally larger errors at 300 m are due to human errors in aiming .
9-53:As the ground truth was obtained by knowing the precise location of the shooter and the target, any inaccuracy in the actual trajectory directly adds to the perceived error of the system .
9-54:We call the estimation of the shooter"s position on the calculated trajectory range estimation due to the lack of a better term .
9-55:The range estimates are better than 5% accurate from 50 m and 10% for 100 m .
9-56:However, this goes to 20% or worse for longer distances .
9-57:We did not have a facility to test system before the evaluation for ranges beyond 100 m .
9-58:During the evaluation, we ran into the problem of mistaking shockwave echoes for muzzle blasts .
9-59:These echoes reached the sensors before the real muzzle blast for long range shots only, since the projectile travels 2 3× faster than the speed of sound, so the time between the shockwave (and its possible echo from nearby objects) and the muzzle blast increases with increasing ranges .
9-60:This resulted in underestimating the range, since the system measured shorter times than the real ones .
9-61:Since the evaluation we finetuned the muzzle blast detection algorithm to avoid this problem .
9-62:Distance M16 AK47 M240 M107 M4 M249 M4 M249 50m 100% 100% 100% 100% 11% 25% 94% 100m 100% 100% 100% 100% 22% 33% 100% 200m 100% 100% 100% 100% 50% 22% 100% 300m 67% 100% 83% 100% 33% 0% 57% All 96% 100% 97% 100% 23% 23% 93% Table 2: Weapon classification results .
9-63:The percentages are relative to the number of shots localized and not all shots, as the classification algorithm needs to know the trajectory and the range .
9-64:Note that the difference is small; there were 189 shots localized out of the total 196 .
9-65:The caliber and weapon estimation accuracy rates are based on the 189 shots that were successfully localized .
9-66:Note that there was a single shot that was falsely classified by the caliber estimator .
9-67:The 73% overall weapon classification accuracy does not seem impressive .
9-68:But if we break it down to the six different weapons tested, the picture changes dramatically as shown in Table 2 .
9-69:For four of the weapons (AK14, M16, M240 and M107), the classification rate is almost 100% .
9-70:There were only two shots out of approximately 140 that were missed .
9-71:The M4 and M249 proved to be too similar and they were mistaken for each other most of the time .
9-72:One possible explanation is that we had only a limited number of test shots taken with these weapons right before the evaluation and used the wrong deceleration approximation function .
9-73:Either this or a similar mistake was made 122 since if we simply used the opposite of the system"s answer where one of these weapons were indicated, the accuracy would have improved 3x .
9-74:If we consider these two weapons a single weapon class, then the classification accuracy for it becomes 93% .
9-75:Note that the AK47 and M240 have the same caliber (7.62 mm), just as the M16, M4 and M249 do (5.56 mm) .
9-76:That is, the system is able to differentiate between weapons of the same caliber .
9-77:We are not aware of any system that classifies weapons this accurately .
9-78:7.1 Single sensor performance As was shown previously, a single sensor alone is able to localize the shooter if it can determine both the muzzle blast and the shockwave AoA, that is, it needs to measure the ToA of both on at least three acoustic channels .
9-79:While shockwave detection is independent of the range unless the projectile becomes subsonic , the likelihood of muzzle blast detection beyond 150 meters is not enough for consistently getting at least three per sensor node for AoA estimation .
9-80:Hence, we only evaluate the single sensor performance for the 104 shots that were taken from 50 and 100 m .
9-81:Note that we use the same test data as in the previous section, but we evaluate individually for each sensor .
9-82:Table 3 summarizes the results broken down by the ten sensors utilized .
9-83:Since this is now not a distributed system, the results are given relative to the position of the given sensor, that is, a bearing and range estimate is provided .
9-84:Note that many of the common error sources of the networked system do not play a role here .
9-85:Time synchronization is not applicable .
9-86:The sensor"s absolute location is irrelevant (just as the relative location of multiple sensors) .
9-87:The sensor"s orientation is still important though .
9-88:There are several disadvantages of the single sensor case compared to the networked system: there is no redundancy to compensate for other errors and to perform outlier rejection, the localization rate is markedly lower, and a single sensor alone is not able to estimate the caliber or classify the weapon .
9-89:Sensor id 1 2 3 5 7 8 9 10 11 12 Loc .
9-90:rate 44% 37% 53% 52% 19% 63% 51% 31% 23% 44% Bearing (deg) 0.80 1.25 0.60 0.85 1.02 0.92 0.73 0.71 1.28 1.44 Range (m) 3.2 6.1 4.4 4.7 4.6 4.6 4.1 5.2 4.8 8.2 Table 3: Single sensor accuracy for 108 shots fired from 50 and 100 meters .
9-91:Localization rate refers to the percentage of shots the given sensor alone was able to localize .
9-92:The bearing and range values are average errors .
9-93:They characterize the accuracy of localization from the given sensor"s perspective .
9-94:The data indicates that the performance of the sensors varied significantly especially considering the localization rate .
9-95:One factor has to be the location of the given sensor including how far it was from the firing lines and how obstructed its view was .
9-96:Also, the sensors were hand built prototypes utilizing nowhere near production quality packaging mounting .
9-97:In light of these factors, the overall average bearing error of 0.9 degrees and range error of 5 m with a microphone spacing of less than 10 cm are excellent .
9-98:We believe that professional manufacturing and better microphones could easily achieve better performance than the best sensor in our experiment (>60% localization rate and 3 m range error) .
9-99:Interestingly, the largest error in range was a huge 90 m clearly due to some erroneous detection, yet the largest bearing error was less than 12 degrees which is still a good indication for the soldier where to look .
9-100:The overall localization rate over all single sensors was 42%, while for 50 m shots only, this jumped to 61% .
9-101:Note that the firing range was prepared to simulate an urban area to some extent: there were a few single and two storey wooden structures built both in and around the sensor deployment area and the firing lines .
9-102:Hence, not all sensors had line of sight to all shooting positions .
9-103:We estimate that 10% of the sensors had obstructed view to the shooter on average .
9-104:Hence, we can claim that a given sensor had about 50% chance of localizing a shot within 130 m .
9-105:(Since the sensor deployment area was 30 m deep, 100 m shots correspond to actual distances between 100 and 130 m.) Again, we emphasize that localization needs at least three muzzle blast and three shockwave detections out of a possible four for each per sensor .
9-106:The detection rate for single sensors corresponding to at least one shockwave detection per sensor was practically 100% .
9-107:0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% 0 1 2 3 4 5 6 7 8 9 10 number of sensors percentageofshots Figure 13: Histogram showing what fraction of the 104 shots taken from 50 and 100 meters were localized by at most how many individual sensors alone .
9-108:13% of the shots were missed by every single sensor, i.e., none of them had both muzzle blast and shockwave AoA detections .
9-109:Note that almost all of these shots were still accurately localized by the networked system, i.e .
9-110:the sensor fusion using all available observations in the sensor network .
9-111:It would be misleading to interpret these results as the system missing half the shots .
9-112:As soldiers never work alone and the sensor node is relatively cheap to afford having every soldier equipped with one, we also need to look at the overall detection rates for every shot .
9-113:Figure 13 shows the histogram of the percentage of shots vs .
9-114:the number of individual sensors that localized it .
9-115:13% of shots were not localized by any sensor alone, but 87% was localized by at least one sensor out of ten .
9-116:7.2 Error sources In this section, we analyze the most significant sources of error that affect the performance of the networked shooter localization and weapon classification system .
9-117:In order to correlate the distributed observations of the acoustic events, the nodes need to have a common time and space reference .
9-118:Hence, errors in the time synchronization, node localization and node orientation all degrade the overall accuracy of the system .
9-119:123 Our time synchronization approach yields errors significantly less than 100 microseconds .
9-120:As the sound travels about 3 cm in that time, time synchronization errors have a negligible effect on the system .
9-121:On the other hand, node location and orientation can have a direct effect on the overall system performance .
9-122:Notice that to analyze this, we do not have to resort to simulation, instead we can utilize the real test data gathered at Aberdeen .
9-123:But instead of using the real sensor locations known very accurately and the measured and calibrated almost perfect node orientations, we can add error terms to them and run the sensor fusion .
9-124:This exactly replicates how the system would have performed during the test using the imprecisely known locations and orientations .
9-125:Another aspect of the system performance that can be evaluated this way is the effect of the number of available sensors .
9-126:Instead of using all ten sensors in the data fusion, we can pick any subset of the nodes to see how the accuracy degrades as we decrease the number of nodes .
9-127:The following experiment was carried out .
9-128:The number of sensors were varied from 2 to 10 in increments of 2 .
9-129:Each run picked the sensors randomly using a uniform distribution .
9-130:At each run each node was randomly moved to a new location within a circle around its true position with a radius determined by a zero mean Gaussian distribution .
9-131:Finally, the node orientations were perturbed using a zeromean Gaussian distribution .
9-132:Each combination of parameters were generated 100 times and utilized for all 196 shots .
9-133:The results are summarized in Figure 14 .
9-134:There is one 3D barchart for each of the experiment sets with the given fixed number of sensors .
9-135:The x axis shows the node location error, that is, the standard deviation of the corresponding Gaussian distribution that was varied between 0 and 6 meters .
9-136:The y axis shows the standard deviation of the node orientation error that was varied between 0 and 6 degrees .
9-137:The z axis is the resulting trajectory azimuth error .
9-138:Note that the elevation angles showed somewhat larger errors than the azimuth .
9-139:Since all the sensors were in approximately a horizontal plane and only a few shooter positions were out of the same plane and only by 2 m or so, the test was not sufficient to evaluate this aspect of the system .
9-140:There are many interesting observation one can make by analyzing these charts .
9-141:Node location errors in this range have a small effect on accuracy .
9-142:Node orientation errors, on the other hand, noticeably degrade the performance .
9-143:Still the largest errors in this experiment of 3.5 degrees for 6 sensors and 5 degrees for 2 sensors are still very good .
9-144:Note that as the location and orientation errors increase and the number of sensors decrease, the most significantly affected performance metric is the localization rate .
9-145:See Table 4 for a summary .
9-146:Successful localization goes down from almost 100% to 50% when we go from 10 sensors to 2 even without additional errors .
9-147:This is primarily caused by geometry: for a successful localization, the bullet needs to pass over the sensor network, that is, at least one sensor should be on the side of the trajectory other than the rest of the nodes .
9-148:(This is a simplification for illustrative purposes .
9-149:If all the sensors and the trajectory are not coplanar, localization may be successful even if the projectile passes on one side of the network .
9-150:See Section 6.3.) As the numbers of sensors decreased in the experiment by randomly selecting a subset, the probability of trajectories abiding by this rule decreased .
9-151:This also means that even if there are 0 2 4 6 0 2 4 6 0 1 2 3 4 5 6 azimutherror(degree) position error (m) orientation error (degree) 2 sensors 0 2 4 6 0 2 4 6 0 1 2 3 4 5 6 azimutherror(degree) position error (m) orientation error (degree) 4 sensors 0 2 4 6 0 2 4 6 0 1 2 3 4 5 6 azimutherror(degree) position error (m) orientation error (degree) 6 sensors 0 2 4 6 0 2 4 6 0 1 2 3 4 5 6 azimutherror(degree) position error (m) orientation error (degree) 8 sensors Figure 14: The effect of node localization and orientation errors on azimuth accuracy with 2, 4, 6 and 8 nodes .
9-152:Note that the chart for 10 nodes is almost identical for the 8 node case, hence, it is omitted .
9-153:124 many sensors (i.e .
9-154:soldiers), but all of them are right next to each other, the localization rate will suffer .
9-155:However, when the sensor fusion does provide a result, it is still accurate even with few available sensors and relatively large individual errors .
9-156:A very few consistent observation lead to good accuracy as the inconsistent ones are discarded by the algorithm .
9-157:This is also supported by the observation that for the cases with the higher number of sensors (8 or 10), the localization rate is hardly affected by even large errors .
9-158:Errors Sensors 2 4 6 8 10 0 m, 0 deg 54% 87% 94% 95% 96% 2 m, 2 deg 53% 80% 91% 96% 96% 6 m, 0 deg 43% 79% 88% 94% 94% 0 m, 6 deg 44% 78% 90% 93% 94% 6 m, 6 deg 41% 73% 85% 89% 92% Table 4: Localization rate as a function of the number of sensors used, the sensor node location and orientation errors .
9-159:One of the most significant observations on Figure 14 and Table 4 is that there is hardly any difference in the data for 6, 8 and 10 sensors .
9-160:This means that there is little advantage of adding more nodes beyond 6 sensors as far as the accuracy is concerned .
9-161:The speed of sound depends on the ambient temperature .
9-162:The current prototype considers it constant that is typically set before a test .
9-163:It would be straightforward to employ a temperature sensor to update the value of the speed of sound periodically during operation .
9-164:Note also that wind may adversely affect the accuracy of the system .
9-165:The sensor fusion, however, could incorporate wind speed into its calculations .
9-166:It would be more complicated than temperature compensation, but could be done .
9-167:Other practical issues also need to be looked at before a real world deployment .
9-168:Silencers reduce the muzzle blast energy and hence, the effective range the system can detect it at .
9-169:However, silencers do not effect the shockwave and the system would still detect the trajectory and caliber accurately .
9-170:The range and weapon type could not be estimated without muzzle blast detections .
9-171:Subsonic weapons do not produce a shockwave .
9-172:However, this is not of great significance, since they have shorter range, lower accuracy and much less lethality .
9-173:Hence, their use is not widespread and they pose less danger in any case .
9-174:Another issue is the type of ammunition used .
9-175:Irregular armies may use substandard, even hand manufactured bullets .
9-176:This effects the muzzle velocity of the weapon .
9-177:For weapon classification to work accurately, the system would need to be calibrated with the typical ammunition used by the given adversary. .
10 RELATED WORK :
10-1:Acoustic detection and recognition has been under research since the early fifties .
10-2:The area has a close relevance to the topic of supersonic flow mechanics [20] .
10-3:Fansler analyzed the complex near field pressure waves that occur within a foot of the muzzle blast .
10-4:Fansler"s work gives a good idea of the ideal muzzle blast pressure wave without contamination from echoes or propagation effects [4] .
10-5:Experiments with greater distances from the muzzle were conducted by Stoughton [18] .
10-6:The measurements of the ballistic shockwaves using calibrated pressure transducers at known locations, measured bullet speeds, and miss distances of 355 meters for 5.56 mm and 7.62 mm projectiles were made .
10-7:Results indicate that ground interaction becomes a problem for miss distances of 30 meters or larger .
10-8:Another area of research is the signal processing of gunfire acoustics .
10-9:The focus is on the robust detection and length estimation of small caliber acoustic shockwaves and muzzle blasts .
10-10:Possible techniques for classifying signals as either shockwaves or muzzle blasts includes short time Fourier Transform (STFT), the Smoothed Pseudo Wigner Ville distribution (SPWVD), and a discrete wavelet transformation .
10-11:Joint time frequency spectrograms are used to analyze the typical separation of the shockwave and muzzle blast transients in both time and frequency .
10-12:Mays concludes that the DWT is the best method for classifying signals as either shockwaves or muzzle blasts because it works well and is less expensive to compute than the SPWVD [10] .
10-13:The edges of the shockwave are typically well defined and the shockwave length is directly related to the bullet characteristics .
10-14:A paper by Sadler [14] compares two shockwave edge detection methods: a simple gradient based detector, and a multi scale wavelet detector .
10-15:It also demonstrates how the length of the shockwave, as determined by the edge detectors, can be used along with Whithams equations [20] to estimate the caliber of a projectile .
10-16:Note that the available computational performance on the sensor nodes, the limited wireless bandwidth and real time requirements render these approaches infeasible on our platform .
10-17:A related topic is the research and development of experimental and prototype shooter location systems .
10-18:Researchers at BBN have developed the Bullet Ears system [3] which has the capability to be installed in a fixed position or worn by soldiers .
10-19:The fixed system has tetrahedron shaped microphone arrays with 1.5 meter spacing .
10-20:The overall system consists of two to three of these arrays spaced 20 to 100 meters from each other .
10-21:The soldier worn system has 12 microphones as well as a GPS antenna and orientation sensors mounted on a helmet .
10-22:There is a low speed RF connection from the helmet to the processing body .
10-23:An extensive test has been conducted to measure the performance of both type of systems .
10-24:The fixed systems performance was one order of magnitude better in the angle calculations while their range performance where matched .
10-25:The angle accuracy of the fixed system was dominantly less than one degree while it was around five degrees for the helmet mounted one .
10-26:The range accuracy was around 5 percent for both of the systems .
10-27:The problem with this and similar centralized systems is the need of the one or handful of microphone arrays to be in line of sight of the shooter .
10-28:A sensor networked based solution has the advantage of widely distributed sensing for better coverage, multipath effect compensation and multiple simultaneous shot resolution [8] .
10-29:This is especially important for operation in acoustically reverberant urban areas .
10-30:Note that BBN"s current vehicle mounted system called BOOMERANG, a modified version of Bullet Ears, is currently used in Iraq [1] .
10-31:The company ShotSpotter specializes in law enforcement systems that report the location of gunfire to police within seconds .
10-32:The goal of the system is significantly different than that of military systems .
10-33:Shotspotter reports 25 m typical accuracy which is more than enough for police to 125 respond .
10-34:They are also manufacturing experimental soldier wearable and UAV mounted systems for military use [16], but no specifications or evaluation results are publicly available. .
11-1:The main contribution of this work is twofold
11-2:First, the performance of the overall distributed networked system is excellent
11-3:Most noteworthy are the trajectory accuracy of one degree, the correct caliber estimation rate of well over 90% and the close to 100% weapon classification rate for 4 of the 6 weapons tested
11-4:The system proved to be very robust when increasing the node location and orientation errors and decreasing the number of available sensors all the way down to a couple
11-5:The key factor behind this is the sensor fusion algorithm"s ability to reject erroneous measurements
11-6:It is also worth mentioning that the results presented here correspond to the first and only test of the system beyond 100 m and with six different weapons
11-7:We believe that with the lessons learned in the test, a consecutive field experiment could have showed significantly improved results especially in range estimation beyond 100 m and weapon classification for the remaining two weapons that were mistaken for each other the majority of the times during the test
11-8:Second, the performance of the system when used in standalone mode, that is, when single sensors alone provided localization, was also very good
11-9:While the overall localization rate of 42% per sensor for shots up to 130 m could be improved, the bearing accuracy of less than a degree and the average 5% range error are remarkable using the handmade prototypes of the low cost nodes
11-10:Note that 87% of the shots were successfully localized by at least one of the ten sensors utilized in standalone mode
11-11:We believe that the technology is mature enough that a next revision of the system could be a commercial one
11-12:However, important aspects of the system would still need to be worked on
11-13:We have not addresses power management yet
11-14:A current node runs on 4 AA batteries for about 12 hours of continuous operation
11-15:A deployable version of the sensor node would need to be asleep during normal operation and only wake up when an interesting event occurs
11-16:An analog trigger circuit could solve this problem, however, the system would miss the first shot
11-17:Instead, the acoustic channels would need to be sampled and stored in a circular buffer
11-18:The rest of the board could be turned off
11-19:When a trigger wakes up the board, the acoustic data would be immediately available
11-20:Experiments with a previous generation sensor board indicated that this could provide a 10x increase in battery life
11-21:Other outstanding issues include weatherproof packaging and ruggedization, as well as integration with current military infrastructure
11-22:10
11-23:REFERENCES
12-1:BBN technologies website
12-2:http:  www.bbn.com
12-3:E
12-4:Danicki
12-5:Acoustic sniper localization
12-6:Archives of Acoustics, 30(2):233 245, 2005
12-7:G
12-8:L
12-9:Duckworth et al
12-10:Fixed and wearable acoustic counter sniper systems for law enforcement
12-11:In E
12-12:M
12-13:Carapezza and D
12-14:B
12-15:Law, editors, Proc
12-16:SPIE Vol
12-17:3577, p
12-18:210 230, pages 210 230, Jan
12-19:1999
12-20:K
12-21:Fansler
12-22:Description of muzzle blast by modified scaling models
12-23:Shock and Vibration, 5(1):1 12, 1998
12-24:D
12-25:Gay, P
12-26:Levis, R
12-27:von Behren, M
12-28:Welsh, E
12-29:Brewer, and D
12-30:Culler
12-31:The nesC language: a holistic approach to networked embedded systems
12-32:Proceedings of Programming Language Design and Implementation (PLDI), June 2003
12-33:J
12-34:Hill, R
12-35:Szewczyk, A
12-36:Woo, S
12-37:Hollar, D
12-38:Culler, and K
12-39:Pister
12-40:System architecture directions for networked sensors
12-41:in Proc
12-42:of ASPLOS 2000, Nov
12-43:2000
12-44:B
12-45:Kus´y, G
12-46:Balogh, P
12-47:V¨olgyesi, J
12-48:Sallai, A
12-49:N´adas, A
12-50:L´edeczi, M
12-51:Mar´oti, and L
12-52:Meertens
12-53:Node density independent localization
12-54:Information Processing in Sensor Networks (IPSN 06) SPOTS Track, Apr
12-55:2006
12-56:A
12-57:L´edeczi, A
12-58:N´adas, P
12-59:V¨olgyesi, G
12-60:Balogh, B
12-61:Kus´y, J
12-62:Sallai, G
12-63:Pap, S
12-64:D´ora, K
12-65:Moln´ar, M
12-66:Mar´oti, and G
12-67:Simon
12-68:Countersniper system for urban warfare
12-69:ACM Transactions on Sensor Networks, 1(1):153 177, Nov
12-70:2005
12-71:M
12-72:Mar´oti
12-73:Directed flood routing framework for wireless sensor networks
12-74:In Proceedings of the 5th ACM IFIP USENIX International Conference on Middleware, pages 99 114, New York, NY, USA, 2004
12-75:Springer Verlag New York, Inc
12-76:B
12-77:Mays
12-78:Shockwave and muzzle blast classification via joint time frequency and wavelet analysis
12-79:Technical report, Army Research Lab Adelphi MD 20783 1197, Sept
12-80:2001
12-81:TinyOS Hardware Platforms
12-82:http:  tinyos.net scoop special hardware
12-83:Crossbow MICAz (MPR2400) Radio Module
12-84:http:  www.xbow.com Products productsdetails
12-85:aspx?sid=101
12-86:PicoBlaze User Resources
12-87:http:  www.xilinx.com ipcenter processor_ central picoblaze picoblaze_user_resources.htm
12-88:B
12-89:M
12-90:Sadler, T
12-91:Pham, and L
12-92:C
12-93:Sadler
12-94:Optimal and wavelet based shock wave detection and estimation
12-95:Acoustical Society of America Journal, 104:955 963, Aug
12-96:1998
12-97:J
12-98:Sallai, B
12-99:Kus´y, A
12-100:L´edeczi, and P
12-101:Dutta
12-102:On the scalability of routing integrated time synchronization
12-103:3rd European Workshop on Wireless Sensor Networks (EWSN 2006), Feb
12-104:2006
12-105:ShotSpotter website
12-106:http:   www.shotspotter.com products military.html
12-107:G
12-108:Simon, M
12-109:Mar´oti, A
12-110:L´edeczi, G
12-111:Balogh, B
12-112:Kus´y, A
12-113:N´adas, G
12-114:Pap, J
12-115:Sallai, and K
12-116:Frampton
12-117:Sensor network based countersniper system
12-118:In SenSys "04: Proceedings of the 2nd international conference on Embedded networked sensor systems, pages 1 12, New York, NY, USA, 2004
12-119:ACM Press
12-120:R
12-121:Stoughton
12-122:Measurements of small caliber ballistic shock waves in air
12-123:Acoustical Society of America Journal, 102:781 787, Aug
12-124:1997
12-125:B
12-126:A
12-127:Weiss, C
12-128:Schlenoff, M
12-129:Shneier, and A
12-130:Virts
12-131:Technology evaluations and performance metrics for soldier worn sensors for assist
12-132:In Performance Metrics for Intelligent Systems Workshop, Aug
12-133:2006
12-134:G
12-135:Whitham
12-136:Flow pattern of a supersonic projectile
12-137:Communications on pure and applied mathematics, 5(3):301, 1952
12-138:126
picture:
