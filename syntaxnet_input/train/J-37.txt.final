Finding Equilibria in Large Sequential Games of Imperfect 
content:
1 ABSTRACT :
1-1:Finding an equilibrium of an extensive form game of imperfect information is a fundamental problem in computational game theory, but current techniques do not scale to large games .
1-2:To address this, we introduce the ordered game isomorphism and the related ordered game isomorphic abstraction transformation .
1-3:For a multi player sequential game of imperfect information with observable actions and an ordered signal space, we prove that any Nash equilibrium in an abstracted smaller game, obtained by one or more applications of the transformation, can be easily converted into a Nash equilibrium in the original game .
1-4:We present an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively .
1-5:Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree .
1-6:It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree .
1-7:Using GameShrink, we find an equilibrium to a poker game with 3.1 billion nodes over four orders of magnitude more than in the largest poker game solved previously .
1-8:We discuss several electronic commerce applications for GameShrink .
1-9:To address even larger games, we introduce approximation methods that do not preserve equilibrium, but nevertheless yield (ex post) provably close to optimal strategies .
1-10:Categories and Subject Descriptors: I.2 [Artificial Intelligence], F .
1-11:[Theory of Computation], J.4 [Social and In environments with more than one agent, an agent"s outcome is generally affected by the actions of the other agent(s) .
1-12:Consequently, the optimal action of one agent can depend on the others .
1-13:Game theory provides a normative framework for analyzing such strategic situations .
1-14:In particular, it provides solution concepts that define what rational behavior is in such settings .
1-15:The most famous and important solution concept is that of Nash equilibrium [36] .
1-16:It is a strategy profile (one strategy for each agent) in which no agent has incentive to deviate to a different strategy .
1-17:However, for the concept to be operational, we need algorithmic techniques for finding an equilibrium .
1-18:Games can be classified as either games of perfect information or imperfect information .
1-19:Chess and Go are examples of the former, and, until recently, most game playing work has been on games of this type .
1-20:To compute an optimal strategy in a perfect information game, an agent traverses the game tree and evaluates individual nodes .
1-21:If the agent is able to traverse the entire game tree, she simply computes an optimal strategy from the bottom up, using the principle of backward induction.1 In computer science terms, this is done using minimax search (often in conjunction with αβ pruning to reduce the search tree size and thus enhance speed) .
1-22:Minimax search runs in linear time in the size of the game tree.2 The differentiating feature of games of imperfect information, such as poker, is that they are not fully observable: when it is an agent"s turn to move, she does not have access to all of the information about the world .
1-23:In such games, the decision of what to do at a point in time cannot generally be optimally made without considering decisions at all other points in time (including ones on other paths of play) because those other decisions affect the probabilities of being at different states at the current point in time .
1-24:Thus the algorithms for perfect information games do not solve games of imperfect information .
1-25:For sequential games with imperfect information, one could try to find an equilibrium using the normal (matrix) form, where every contingency plan of the agent is a pure strategy for the agent.3 Unfortunately (even if equivalent strategies 1 This actually yields a solution that satisfies not only the Nash equilibrium solution concept, but a stronger solution concept called subgame perfect Nash equilibrium [45] .
1-26:2 This type of algorithm still does not scale to huge trees (such as in chess or Go), but effective game playing agents can be developed even then by evaluating intermediate nodes using a heuristic evaluation and then treating those nodes as leaves .
1-27:3 An equilibrium in a normal form game with any 160 are replaced by a single strategy [27]) this representation is generally exponential in the size of the game tree [52] .
1-28:By observing that one needs to consider only sequences of moves rather than pure strategies [41, 46, 22, 52], one arrives at a more compact representation, the sequence form, which is linear in the size of the game tree.4 For 2 player games, there is a polynomial sized (in the size of the game tree) linear programming formulation (linear complementarity in the non zero sum case) based on the sequence form such that strategies for players 1 and 2 correspond to primal and dual variables .
1-29:Thus, the equilibria of reasonable sized 2 player games can be computed using this method [52, 24, 25].5 However, this approach still yields enormous (unsolvable) optimization problems for many real world games, such as poker .
1-30:1.1 Our approach In this paper, we take a different approach to tackling the difficult problem of equilibrium computation .
1-31:Instead of developing an equilibrium finding method per se, we instead develop a methodology for automatically abstracting games in such a way that any equilibrium in the smaller (abstracted) game corresponds directly to an equilibrium in the original game .
1-32:Thus, by computing an equilibrium in the smaller game (using any available equilibrium finding algorithm), we are able to construct an equilibrium in the original game .
1-33:The motivation is that an equilibrium for the smaller game can be computed drastically faster than for the original game .
1-34:To this end, we introduce games with ordered signals (Section 2), a broad class of games that has enough structure which we can exploit for abstraction purposes .
1-35:Instead of operating directly on the game tree (something we found to be technically challenging), we instead introduce the use of information filters (Section 2.1), which coarsen the information each player receives .
1-36:They are used in our analysis and abstraction algorithm .
1-37:By operating only in the space of filters, we are able to keep the strategic structure of the game intact, while abstracting out details of the game in a way that is lossless from the perspective of equilibrium finding .
1-38:We introduce the ordered game isomorphism to describe strategically symmetric situations and the ordered game isomorphic abstraction transformation to take advantange of such symmetries (Section 3) .
1-39:As our main equilibrium result we have the following: constant number of agents can be constructed in quasipolynomial time [31], but finding an exact equilibrium is PPAD complete even in a 2 player game [8] .
1-40:The most prevalent algorithm for finding an equilibrium in a 2 agent game is Lemke Howson [30], but it takes exponentially many steps in the worst case [44] .
1-41:For a survey of equilibrium computation in 2 player games, see [53] .
1-42:Recently, equilibriumfinding algorithms that enumerate supports (i.e., sets of pure strategies that are played with positive probability) have been shown efficient on many games [40], and efficient mixed integer programming algorithms that search in the space of supports have been developed [43] .
1-43:For more than two players, many algorithms have been proposed, but they currently only scale to very small games [19, 34, 40] .
1-44:4 There were also early techniques that capitalized in different ways on the fact that in many games the vast majority of pure strategies are not played in equilibrium [54, 23] .
1-45:5 Recently this approach was extended to handle computing sequential equilibria [26] as well [35] .
1-46:Theorem 2 Let Γ be a game with ordered signals, and let F be an information filter for Γ .
1-47:Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation, and let σ be a Nash equilibrium strategy profile of the induced game ΓF (i.e., the game Γ using the filter F ) .
1-48:If σ is constructed by using the corresponding strategies of σ , then σ is a Nash equilibrium of ΓF .
1-49:The proof of the theorem uses an equivalent characterization of Nash equilibria: σ is a Nash equilibrium if and only if there exist beliefs μ (players" beliefs about unknown information) at all points of the game reachable by σ such that σ is sequentially rational (i.e., a best response) given μ, where μ is updated using Bayes" rule .
1-50:We can then use the fact that σ is a Nash equilibrium to show that σ is a Nash equilibrium considering only local properties of the game .
1-51:We also give an algorithm, GameShrink, for abstracting the game using our isomorphism exhaustively (Section 4) .
1-52:Its complexity is ˜O(n2 ), where n is the number of nodes in a structure we call the signal tree .
1-53:It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in the size of the game tree .
1-54:We present several algorithmic and data structure related speed improvements (Section 4.1), and we demonstrate how a simple modification to our algorithm yields an approximation algorithm (Section 5) .
1-55:1.2 Electronic commerce applications Sequential games of imperfect information are ubiquitous, for example in negotiation and in auctions .
1-56:Often aspects of a player"s knowledge are not pertinent for deciding what action the player should take at a given point in the game .
1-57:On the trivial end, some aspects of a player"s knowledge are never pertinent (e.g., whether it is raining or not has no bearing on the bidding strategy in an art auction), and such aspects can be completely left out of the model specification .
1-58:However, some aspects can be pertinent in certain states of the game while they are not pertinent in other states, and thus cannot be left out of the model completely .
1-59:Furthermore, it may be highly non obvious which aspects are pertinent in which states of the game .
1-60:Our algorithm automatically discovers which aspects are irrelevant in different states, and eliminates those aspects of the game, resulting in a more compact, equivalent game representation .
1-61:One broad application area that has this property is sequential negotiation (potentially over multiple issues) .
1-62:Another broad application area is sequential auctions (potentially over multiple goods) .
1-63:For example, in those states of a 1 object auction where bidder A can infer that his valuation is greater than that of bidder B, bidder A can ignore all his other information about B"s signals, although that information would be relevant for inferring B"s exact valuation .
1-64:Furthermore, in some states of the auction, a bidder might not care which exact other bidders have which valuations, but cares about which valuations are held by the other bidders in aggregate (ignoring their identities) .
1-65:Many open cry sequential auction and negotiation mechanisms fall within the game model studied in this paper (specified in detail later), as do certain other games in electronic commerce, such as sequences of take it or leave it offers [42] .
1-66:Our techniques are in no way specific to an application .
1-67:The main experiment that we present in this paper is on 161 a recreational game .
1-68:We chose a particular poker game as the benchmark problem because it yields an extremely complicated and enormous game tree, it is a game of imperfect information, it is fully specified as a game (and the data is available), and it has been posted as a challenge problem by others [47] (to our knowledge no such challenge problem instances have been proposed for electronic commerce applications that require solving sequential games) .
1-69:1.3 Rhode Island Hold"em poker Poker is an enormously popular card game played around the world .
1-70:The 2005 World Series of Poker had over $103 million dollars in total prize money, including $56 million for the main event .
1-71:Increasingly, poker players compete in online casinos, and television stations regularly broadcast poker tournaments .
1-72:Poker has been identified as an important research area in AI due to the uncertainty stemming from opponents" cards, opponents" future actions, and chance moves, among other reasons [5] .
1-73:Almost since the field"s founding, game theory has been used to analyze different aspects of poker [28; 37; 3; 51, pp .
1-74:186 219] .
1-75:However, this work was limited to tiny games that could be solved by hand .
1-76:More recently, AI researchers have been applying the computational power of modern hardware to computing game theory based strategies for larger games .
1-77:Koller and Pfeffer determined solutions to poker games with up to 140,000 nodes using the sequence form and linear programming [25] .
1-78:Large scale approximations have been developed [4], but those methods do not provide any guarantees about the performance of the computed strategies .
1-79:Furthermore, the approximations were designed manually by a human expert .
1-80:Our approach yields an automated abstraction mechanism along with theoretical guarantees on the strategies" performance .
1-81:Rhode Island Hold"em was invented as a testbed for computational game playing [47] .
1-82:It was designed so that it was similar in style to Texas Hold"em, yet not so large that devising reasonably intelligent strategies would be impossible .
1-83:(The rules of Rhode Island Hold"em, as well as a discussion of how Rhode Island Hold"em can be modeled as a game with ordered signals, that is, it fits in our model, is available in an extended version of this paper [13].) We applied the techniques developed in this paper to find an exact (minimax) solution to Rhode Island Hold"em, which has a game tree exceeding 3.1 billion nodes .
1-84:Applying the sequence form to Rhode Island Hold"em directly without abstraction yields a linear program with 91,224,226 rows, and the same number of columns .
1-85:This is much too large for (current) linear programming algorithms to handle .
1-86:We used our GameShrink algorithm to reduce this with lossless abstraction, and it yielded a linear program with 1,237,238 rows and columns with 50,428,638 non zero coefficients .
1-87:We then applied iterated elimination of dominated strategies, which further reduced this to 1,190,443 rows and 1,181,084 columns .
1-88:(Applying iterated elimination of dominated strategies without GameShrink yielded 89,471,986 rows and 89,121,538 columns, which still would have been prohibitively large to solve.) GameShrink required less than one second to perform the shrinking (i.e., to compute all of the ordered game isomorphic abstraction transformations) .
1-89:Using a 1.65GHz IBM eServer p5 570 with 64 gigabytes of RAM (the linear program solver actually needed 25 gigabytes), we solved it in 7 days and 17 hours using the interior point barrier method of CPLEX version 9.1.2 .
1-90:We recently demonstrated our optimal Rhode Island Hold"em poker player at the AAAI 05 conference [14], and it is available for play on line at http: www.cs.cmu.edu ~gilpin gsi.html .
1-91:While others have worked on computer programs for playing Rhode Island Hold"em [47], no optimal strategy has been found before .
1-92:This is the largest poker game solved to date by over four orders of magnitude. .
2 GAMES WITH ORDERED SIGNALS :
2-1:We work with a slightly restricted class of games, as compared to the full generality of the extensive form .
2-2:This class, which we call games with ordered signals, is highly structured, but still general enough to capture a wide range of strategic situations .
2-3:A game with ordered signals consists of a finite number of rounds .
2-4:Within a round, the players play a game on a directed tree (the tree can be different in different rounds) .
2-5:The only uncertainty players face stems from private signals the other players have received and from the unknown future signals .
2-6:In other words, players observe each others" actions, but potentially not nature"s actions .
2-7:In each round, there can be public signals (announced to all players) and private signals (confidentially communicated to individual players) .
2-8:For simplicity, we assume as is the case in most recreational games that within each round, the number of private signals received is the same across players (this could quite likely be relaxed) .
2-9:We also assume that the legal actions that a player has are independent of the signals received .
2-10:For example, in poker, the legal betting actions are independent of the cards received .
2-11:Finally, the strongest assumption is that there is a partial ordering over sets of signals, and the payoffs are increasing (not necessarily strictly) in these signals .
2-12:For example, in poker, this partial ordering corresponds exactly to the ranking of card hands .
2-13:Definition 1 .
2-14:A game with ordered signals is a tuple Γ = I, G, L, Θ, κ, γ, p, , ω, u where: .
3 G = G1 :
3-1:, .
3-2:.
3-3:.
3-4:, Gr , Gj = ` V j , Ej ´ , is a finite collection of finite directed trees with nodes V j and edges Ej .
3-5:Let Zj denote the leaf nodes of Gj and let Nj (v) denote the outgoing neighbors of v ∈ V j .
3-6:Gj is the stage game for round j. .
4 L = L1 :
4-1:, .
4-2:.
4-3:.
4-4:, Lr , Lj : V j \ Zj → I indicates which player acts (chooses an outgoing edge) at each internal node in round j. .
5 Θ is a finite set of signals. :
5-1:.
6 κ = κ1 :
6-1:, .
6-2:.
6-3:.
6-4:, κr and γ = γ1 , .
6-5:.
6-6:.
6-7:, γr are vectors of nonnegative integers, where κj and γj denote the number of public and private signals (per player), respectively, revealed in round j .
6-8:Each signal θ ∈ Θ may only be revealed once, and in each round every player receives the same number of private signals, so we require Pr j=1 κj + nγj ≤ |Θ| .
6-9:The public information revealed in round j is αj ∈ Θκj and the public information revealed in all rounds up through round j is ˜αj = ` α1 , .
6-10:.
6-11:.
6-12:, αj ´ .
6-13:The private information revealed to player i ∈ I in round j is βj i ∈ Θγj and the private information revaled to player i ∈ I in all rounds up through round j is ˜βj i = ` β1 i , .
6-14:.
6-15:.
6-16:, βj i ´ .
6-17:We 162 also write ˜βj = ˜βj 1, .
6-18:.
6-19:.
6-20:, ˜βj n to represent all private information up through round j, and ˜β j i , ˜βj −i = ˜βj 1, .
6-21:.
6-22:.
6-23:, ˜βj i−1, ˜β j i , ˜βj i+1, .
6-24:.
6-25:.
6-26:, ˜βj n is ˜βj with ˜βj i replaced with ˜β j i .
6-27:The total information revealed up through round j, ˜αj , ˜βj , is said to be legal if no signals are repeated .
6-28:for all θ ∈ Θ .
6-29:Signals are drawn from Θ according to p without replacement, so if X is the set of signals already revealed, then p(x | X) = ( p(x)P y ∈X p(y) if x ∈ X 0 if x ∈ X .
6-30:for at least those pairs required by u. .
7 ω : :
7-1:rS j=1 Zj → {over, continue} is a mapping of terminal nodes within a stage game to one of two values: over, in which case the game ends, or continue, in which case the game continues to the next round .
7-2:Clearly, we require ω(z) = over for all z ∈ Zr .
7-3:Note that ω is independent of the signals .
7-4:Let ωj over = {z ∈ Zj | ω(z) = over} and ωj cont = {z ∈ Zj | ω(z) = continue}. .
8 u = (u1 :
8-1:, .
8-2:.
8-3:.
8-4:, ur ), uj : j−1 k=1 ωk cont × ωj over × j k=1 Θκk × n i=1 j k=1 Θγk → Rn is a utility function such that for every j, 1 ≤ j ≤ r, for every i ∈ I, and for every ˜z ∈ j−1 k=1 ωk cont × ωj over, at least one of the following two conditions holds: (a) Utility is signal independent: uj i (˜z, ϑ) = uj i (˜z, ϑ ) for all legal ϑ, ϑ ∈ j k=1 Θκk × n i=1 j k=1 Θγk .
8-5:(b) is defined for all legal signals (˜αj , ˜βj i ), (˜αj , ˜β j i ) through round j and a player"s utility is increasing in her private signals, everything else equal: ˜αj , ˜βj i ˜αj , ˜β j i =⇒ ui ˜z, ˜αj , ˜βj i , ˜βj −i ≥ ui ˜z, ˜αj , ˜β j i , ˜βj −i .
8-6:We will use the term game with ordered signals and the term ordered game interchangeably .
8-7:2.1 Information filters In this subsection, we define an information filter for ordered games .
8-8:Instead of completely revealing a signal (either public or private) to a player, the signal first passes through this filter, which outputs a coarsened signal to the player .
8-9:By varying the filter applied to a game, we are able to obtain a wide variety of games while keeping the underlying action space of the game intact .
8-10:We will use this when designing our abstraction techniques .
8-11:Formally, an information filter is as follows .
8-12:Definition 2 .
8-13:Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game .
8-14:Let Sj ⊆ j k=1 Θκk × j k=1 Θγk be the set of legal signals (i.e., no repeated signals) for one player through round j .
8-15:An information filter for Γ is a collection F = F1 , .
8-16:.
8-17:.
8-18:, Fr where each Fj is a function Fj : Sj → 2Sj such that each of the following conditions hold: .
9 (Truthfulness) (˜αj :
9-1:, ˜βj i ) ∈ Fj (˜αj , ˜βj i ) for all legal (˜αj , ˜βj i ). .
10 (Independence) The range of Fj :
10-1:is a partition of Sj .
10-2:distinguishable in round k, then they are distinguishable fpr each round j > k .
10-3:Let mj = Pj l=1 κl +γl .
10-4:We require that for all legal (θ1, .
10-5:.
10-6:.
10-7:, θmk , .
10-8:.
10-9:.
10-10:, θmj ) ⊆ Θ and (θ1, .
10-11:.
10-12:.
10-13:, θmk , .
10-14:.
10-15:.
10-16:, θmj ) ⊆ Θ: (θ1, .
10-17:.
10-18:.
10-19:, θmk ) ∈ Fk (θ1, .
10-20:.
10-21:.
10-22:, θmk ) =⇒ (θ1, .
10-23:.
10-24:.
10-25:, θmk , .
10-26:.
10-27:.
10-28:, θmj ) ∈ Fj (θ1, .
10-29:.
10-30:.
10-31:, θmk , .
10-32:.
10-33:.
10-34:, θmj ) .
10-35:A game with ordered signals Γ and an information filter F for Γ defines a new game ΓF .
10-36:We refer to such games as filtered ordered games .
10-37:We are left with the original game if we use the identity filter Fj ˜αj , ˜βj i = n ˜αj , ˜βj i o .
10-38:We have the following simple (but important) result: Proposition 1 .
10-39:A filtered ordered game is an extensive form game satisfying perfect recall .
10-40:A simple proof proceeds by constructing an extensive form game directly from the ordered game, and showing that it satisfies perfect recall .
10-41:In determining the payoffs in a game with filtered signals, we take the average over all real signals in the filtered class, weighted by the probability of each real signal occurring .
10-42:2.2 Strategies and Nash equilibrium We are now ready to define behavior strategies in the context of filtered ordered games .
10-43:Definition 3 .
10-44:A behavior strategy for player i in round j of Γ = I, G, L, Θ, κ, γ, p, , ω, u with information filter F is a probability distribution over possible actions, and is defined for each player i, each round j, and each v ∈ V j \Zj for Lj (v) = i: σj i,v : j−1 k=1 ωk cont×Range Fj → Δ n w ∈ V j | (v, w) ∈ Ej o .
10-45:(Δ(X) is the set of probability distributions over a finite set X.) A behavior strategy for player i in round j is σj i = (σj i,v1 , .
10-46:.
10-47:.
10-48:, σj i,vm ) for each vk ∈ V j \ Zj where Lj (vk) = i .
10-49:A behavior strategy for player i in Γ is σi = ` σ1 i , .
10-50:.
10-51:.
10-52:, σr i ´ .
10-53:A strategy profile is σ = (σ1, .
10-54:.
10-55:.
10-56:, σn) .
10-57:A strategy profile with σi replaced by σi is (σi, σ−i) = (σ1, .
10-58:.
10-59:.
10-60:, σi−1, σi, σi+1, .
10-61:.
10-62:.
10-63:, σn) .
10-64:By an abuse of notation, we will say player i receives an expected payoff of ui(σ) when all players are playing the strategy profile σ .
10-65:Strategy σi is said to be player i"s best response to σ−i if for all other strategies σi for player i we have ui(σi, σ−i) ≥ ui(σi, σ−i) .
10-66:σ is a Nash equilibrium if, for every player i, σi is a best response for σ−i .
10-67:A Nash equilibrium always exists in finite extensive form games [36], and one exists in behavior strategies for games with perfect recall [29] .
10-68:Using these observations, we have the following corollary to Proposition 1: 163 Corollary 1 .
10-69:For any filtered ordered game, a Nash equilibrium exists in behavior strateges. .
11 ABSTRACTIONS :
11-1:ABSTRACTIONS In this section, we present our main technique for reducing the size of games .
11-2:We begin by defining a filtered signal tree which represents all of the chance moves in the game .
11-3:The bold edges (i.e .
11-4:the first two levels of the tree) in the game trees in Figure 1 correspond to the filtered signal trees in each game .
11-5:Definition 4 .
11-6:Associated with every ordered game Γ = I, G, L, Θ, κ, γ, p, , ω, u and information filter F is a filtered signal tree, a directed tree in which each node corresponds to some revealed (filtered) signals and edges correspond to revealing specific (filtered) signals .
11-7:The nodes in the filtered signal tree represent the set of all possible revealed filtered signals (public and private) at some point in time .
11-8:The filtered public signals revealed in round j correspond to the nodes in the κj levels beginning at level Pj−1 k=1 ` κk + nγk ´ and the private signals revealed in round j correspond to the nodes in the nγj levels beginning at level Pj k=1 κk + Pj−1 k=1 nγk .
11-9:We denote children of a node x as N(x) .
11-10:In addition, we associate weights with the edges corresponding to the probability of the particular edge being chosen given that its parent was reached .
11-11:In many games, there are certain situations in the game that can be thought of as being strategically equivalent to other situations in the game .
11-12:By melding these situations together, it is possible to arrive at a strategically equivalent smaller game .
11-13:The next two definitions formalize this notion via the introduction of the ordered game isomorphic relation and the ordered game isomorphic abstraction transformation .
11-14:Definition 5 .
11-15:Two subtrees beginning at internal nodes x and y of a filtered signal tree are ordered game isomorphic if x and y have the same parent and there is a bijection f : N(x) → N(y), such that for w ∈ N(x) and v ∈ N(y), v = f(w) implies the weights on the edges (x, w) and (y, v) are the same and the subtrees beginning at w and v are ordered game isomorphic .
11-16:Two leaves (corresponding to filtered signals ϑ and ϑ up through round r) are ordered game isomorphic if for all ˜z ∈ r−1 j=1 ωj cont × ωr over, ur (˜z, ϑ) = ur (˜z, ϑ ) .
11-17:Definition 6 .
11-18:Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and let F be an information filter for Γ .
11-19:Let ϑ and ϑ be two nodes where the subtrees in the induced filtered signal tree corresponding to the nodes ϑ and ϑ are ordered game isomorphic, and ϑ and ϑ are at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk for some round is given by creating a new information filter F : F j ˜αj , ˜βj i = 8 < : Fj ˜αj , ˜βj i if ˜αj , ˜βj i ∈ ϑ ∪ ϑ ϑ ∪ ϑ if ˜αj , ˜βj i ∈ ϑ ∪ ϑ .
11-20:Figure 1 shows the ordered game isomorphic abstraction transformation applied twice to a tiny poker game .
11-21:Theorem 2, our main equilibrium result, shows how the ordered game isomorphic abstraction transformation can be used to compute equilibria faster .
11-22:Theorem 2 .
11-23:Let Γ = I, G, L, Θ, κ, γ, p, , ω, u be an ordered game and F be an information filter for Γ .
11-24:Let F be an information filter constructed from F by one application of the ordered game isomorphic abstraction transformation .
11-25:Let σ be a Nash equilibrium of the induced game ΓF .
11-26:If we take σj i,v ˜z, Fj ˜αj , ˜βj i = σ j i,v ˜z, F j ˜αj , ˜βj i , σ is a Nash equilibrium of ΓF .
11-27:Proof .
11-28:For an extensive form game, a belief system μ assigns a probability to every decision node x such thatP x∈h μ(x) = 1 for every information set h .
11-29:A strategy profile σ is sequentially rational at h given belief system μ if ui(σi, σ−i | h, μ) ≥ ui(τi, σ−i | h, μ) for all other strategies τi, where i is the player who controls equilibria dictates that σ is a Nash equilibrium if and only if there is a belief system μ such that for every information set h with Pr(h | σ) > 0, the following two conditions hold: (C1) σ is sequentially rational at h given μ; and (C2) μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h .
11-30:Since σ is a Nash equilibrium of Γ , there exists such a belief system μ for ΓF .
11-31:Using μ , we will construct a belief system μ for Γ and show that conditions C1 and C2 hold, thus supporting σ as a Nash equilibrium .
11-32:Fix some player i ∈ I .
11-33:Each of i"s information sets in some round j corresponds to filtered signals Fj ˜α∗j , ˜β∗j i , history in the first j − 1 rounds (z1, .
11-34:.
11-35:.
11-36:, zj−1) ∈ j−1 k=1 ωk cont, and history so far in round j, v ∈ V j \ Zj .
11-37:Let ˜z = (z1, .
11-38:.
11-39:.
11-40:, zj−1, v) represent all of the player actions leading to this information set .
11-41:Thus, we can uniquely specify this information set using the information Fj ˜α∗j , ˜β∗j i , ˜z .
11-42:Each node in an information set corresponds to the possible private signals the other players have received .
11-43:Denote by ˜β some legal (Fj (˜αj , ˜βj 1), .
11-44:.
11-45:.
11-46:, Fj (˜αj , ˜βj i−1), Fj (˜αj , ˜βj i+1), .
11-47:.
11-48:.
11-49:, Fj (˜αj , ˜βj n)) .
11-50:In other words, there exists (˜αj , ˜βj 1, .
11-51:.
11-52:.
11-53:, ˜βj n) such that (˜αj , ˜βj i ) ∈ Fj (˜α∗j , ˜β∗j i ), (˜αj , ˜βj k) ∈ Fj (˜αj , ˜βj k) for k = i, and no signals are repeated .
11-54:Using such a set of signals (˜αj , ˜βj 1, .
11-55:.
11-56:.
11-57:, ˜βj n), let ˆβ denote (F j (˜αj , ˜βj 1), .
11-58:.
11-59:.
11-60:, F j (˜αj , ˜βj i−1), F j (˜αj , ˜βj i+1), .
11-61:.
11-62:.
11-63:, F j (˜αj , ˜βj n) .
11-64:(We will abuse notation and write F j −i ˆβ = ˆβ .) We can now compute μ directly from μ : μ ˆβ | Fj ˜αj , ˜βj i , ˜z = 8 >>>>>>< >>>>>>: μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i or ˆβ = ˆβ p∗ μ ˆβ | F j ˜αj , ˜βj i , ˜z if Fj ˜αj , ˜βj i = F j ˜αj , ˜βj i and ˆβ = ˆβ 164 J1 J2 J2 K1 K1 K2 K2 c b C B F B f b c b C B F B f b c b C f b B BF c b C f b B BF c b C B F B f b c b C BF B f b c b C f b B BF c b C f b B BF c b C f b B BF c b C f b B BF c b C B F B f b c b C B F B f b 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 10 0 0 0 0 0 0 0 0 1 2 2 1 2 2 1 2 2 1 2 2 1 2 2 1 2 2 1 2 2 1 2 2 J1 K1 K2 J1 J2 K2 J1 J2 K1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 {{J1}, {J2}, {K1}, {K2}} {{J1,J2}, {K1}, {K2}} c b C BF B f b c b C f b B BF c b C B F B f b J1,J2 K1 K2 1 1 c b C f b B BF c b C BF B f b c b C BF B f b c b C B F B f b J1,J2 K1 K2 1 1 1 1 J1,J2 K2 J1,J2 K1 0 0 0 1 1 1 1 1 1 1 2 2 1 2 2 2 2 2 2 2 2 1 1 1 1 0 0 0 1 2 2 1 1 1 1 0 0 0 1 2 2 c b C B F B f b 1 10 0 0 c b B F B f b 1 1 1 2 2 c b C BF B f b 0 0 0 1 1 c b C BF B f b J1,J2 J1,J2 J1,J2K1,K2 K1,K2 K1,K2 1 1 1 2 2 2 2 2 2 {{J1,J2}, {K1,K2}} 1 1 1 1 1 4 1 4 1 4 1 4 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 3 1 4 1 41 2 1 3 1 3 1 3 1 32 3 1 32 3 1 2 1 2 1 3 2 3 2 3 1 3 Figure 1: GameShrink applied to a tiny two person four card (two Jacks and two Kings) poker game .
11-65:Next to each game tree is the range of the information filter F .
11-66:Dotted lines denote information sets, which are labeled by the controlling player .
11-67:Open circles are chance nodes with the indicated transition probabilities .
11-68:The root node is the chance node for player 1"s card, and the next level is for player 2"s card .
11-69:The payment from player 2 to player 1 is given below each leaf .
11-70:In this example, the algorithm reduces the game tree from 53 nodes to 19 nodes .
11-71:where p∗ = Pr(ˆβ | F j (˜αj , ˜β j i )) Pr(ˆβ | F j (˜αj , ˜β j i )) .
11-72:The following three claims show that μ as calculated above supports σ as a Nash equilibrium .
11-73:Claim 1 .
11-74:μ is a valid belief system for ΓF .
11-75:Claim 2 .
11-76:For all information sets h with Pr(h | σ) > 0, μ(x) = Pr(x | σ) Pr(h | σ) for all x ∈ h .
11-77:Claim 3 .
11-78:For all information sets h with Pr(h | σ) > 0, σ is sequentially rational at h given μ .
11-79:The proofs of Claims 1 3 are in an extended version of this paper [13] .
11-80:By Claims 1 and 2, we know that condition C2 holds .
11-81:By Claim 3, we know that condition C1 holds .
11-82:Thus, σ is a Nash equilibrium .
11-83:3.1 Nontriviality of generalizing beyond this model Our model does not capture general sequential games of imperfect information because it is restricted in two ways (as discussed above): 1) there is a special structure connecting the player actions and the chance actions (for one, the players are assumed to observe each others" actions, but nature"s actions might not be publicly observable), and 2) there is a common ordering of signals .
11-84:In this subsection we show that removing either of these conditions can make our technique invalid .
11-85:First, we demonstrate a failure when removing the first assumption .
11-86:Consider the game in Figure 2.6 Nodes a and b are in the same information set, have the same parent (chance) node, have isomorphic subtrees with the same payoffs, and nodes c and d also have similar structural properties .
11-87:By merging the subtrees beginning at a and b, we get the game on the right in Figure 2 .
11-88:In this game, player 1"s only Nash equilibrium strategy is to play left .
11-89:But in the original game, player 1 knows that node c will never be reached, and so should play right in that information set .
11-90:1 4 1 4 1 4 1 4 2 2 2 1 1 1 2 1 2 3 0 3 0 10 10 1 2 1 4 1 4 2 2 2 1 1 2 3 0 3 0 a b 2 2 2 10 10 c d Figure 2: Example illustrating difficulty in developing a theory of equilibrium preserving abstractions for general extensive form games .
11-91:Removing the second assumption (that the utility functions are based on a common ordering of signals) can also cause failure .
11-92:Consider a simple three card game with a deck containing two Jacks (J1 and J2) and a King (K), where player 1"s utility function is based on the ordering 6 We thank Albert Xin Jiang for providing this example .
11-93:165 K J1 ∼ J2 but player 2"s utility function is based on the ordering J2 K J1 .
11-94:It is easy to check that in the abstracted game (where Player 1 treats J1 and J2 as being equivalent) the Nash equilibrium does not correspond to a Nash equilibrium in the original game.7 .
12 GAME ISOMORPHIC ABSTRACTION :
12-1:ALGORITHM FOR COMPUTING ORDERED GAME ISOMORPHIC ABSTRACTION TRANSFORMATIONS This section presents an algorithm, GameShrink, for conducting the abstractions .
12-2:It only needs to analyze the signal tree discussed above, rather than the entire game tree .
12-3:We first present a subroutine that GameShrink uses .
12-4:It is a dynamic program for computing the ordered game isomorphic relation .
12-5:Again, it operates on the signal tree .
12-6:Algorithm 1 .
12-7:OrderedGameIsomorphic? (Γ, ϑ, ϑ ) (a) If ur (ϑ | ˜z) = ur (ϑ | ˜z) for all ˜z ∈ r−1 j=1 ωj cont × ωr over, then return true .
12-8:(b) Otherwise, return false .
12-9:N(ϑ) and V2 = N(ϑ ). .
13 For each v1 ∈ V1 and v2 ∈ V2: :
13-1:If OrderedGameIsomorphic? (Γ, v1, v2) Create edge (v1, v2) return false .
13-2:By evaluating this dynamic program from bottom to top, Algorithm 1 determines, in time polynomial in the size of the signal tree, whether or not any pair of equal depth nodes x and y are ordered game isomorphic .
13-3:We can further speed up this computation by only examining nodes with the same parent, since we know (from step 1) that no nodes with different parents are ordered game isomorphic .
13-4:The test in step 2(a) can be computed in O(1) time by consulting the relation from the specification of the game .
13-5:Each call to OrderedGameIsomorphic? performs at most one perfect matching computation on a bipartite graph with O(|Θ|) nodes and O(|Θ|2 ) edges (recall that Θ is the set of signals) .
13-6:Using the Ford Fulkerson algorithm [12] for finding a maximal matching, this takes O(|Θ|3 ) time .
13-7:Let S be the maximum number of signals possibly revealed in the game (e.g., in Rhode Island Hold"em, S = 4 because each of the two players has one card in the hand plus there are two cards on the table) .
13-8:The number of nodes, n, in the signal tree is O(|Θ|S For each pair of sibling nodes ϑ, ϑ at either levelPj−1 k=1 ` κk + nγk ´ or Pj k=1 κk + Pj−1 k=1 nγk in the filtered (according to F) signal tree: If OrderedGameIsomorphic?(Γ, ϑ, ϑ ), then Fj (ϑ) ← Fj (ϑ ) ← Fj (ϑ) ∪ Fj (ϑ ). .
14 Output F. :
14-1:Given as input an ordered game Γ, GameShrink applies the shrinking ideas presented above as aggressively as possible .
14-2:Once it finishes, there are no contractible nodes (since it compares every pair of nodes at each level of the signal tree), and it outputs the corresponding information filter F .
14-3:The correctness of GameShrink follows by a repeated application of Theorem 2 .
14-4:Thus, we have the following result: Theorem 3 .
14-5:GameShrink finds all ordered game isomorphisms and applies the associated ordered game isomorphic abstraction transformations .
14-6:Furthermore, for any Nash equilibrium, σ , of the abstracted game, the strategy profile constructed for the original game from σ is a Nash equilibrium .
14-7:The dominating factor in the run time of GameShrink is in the rth iteration of the main for loop .
14-8:There are at most 166 `|Θ| S ´ S! nodes at this level, where we again take S to be the maximum number of signals possibly revealed in the game .
14-9:Thus, the inner for loop executes O „`|Θ| S ´ S! 2 « times .
14-10:As discussed in the next subsection, we use a union find data structure to represent the information filter F .
14-11:Each iteration of the inner for loop possibly performs a union operation on the data structure; performing M operations on a union find data structure containing N elements takes O(α(M, N)) amortized time per operation, where α(M, N) is the inverse Ackermann"s function [1, 49] (which grows extremely slowly) .
14-12:Thus, the total time for GameShrink is O „`|Θ| S ´ S! 2 α „`|Θ| S ´ S! 2 , |Θ|S «« .
14-13:By the inequality `n k ´ ≤ nk k! , this is O ` (|Θ|S )2 α ` (|Θ|S )2 , |Θ|S ´´ .
14-14:Again, although this is exponential in S, it is ˜O(n2 ), where n is the number of nodes in the signal tree .
14-15:Furthermore, GameShrink tends to actually run in sublinear time and space in the size of the game tree because the signal tree is significantly smaller than the game tree in most nontrivial games, as discussed above .
14-16:4.1 Efficiency enhancements We designed several speed enhancement techniques for GameShrink, and all of them are incorporated into our implementation .
14-17:One technique is the use of the union find data structure for storing the information filter F .
14-18:This data structure uses time almost linear in the number of operations [49] .
14-19:Initially each node in the signalling tree is its own set (this corresponds to the identity information filter); when two nodes are contracted they are joined into a new set .
14-20:Upon termination, the filtered signals for the abstracted game correspond exactly to the disjoint sets in the data structure .
14-21:This is an efficient method of recording contractions within the game tree, and the memory requirements are only linear in the size of the signal tree .
14-22:Determining whether two nodes are ordered game isomorphic requires us to determine if a bipartite graph has a perfect matching .
14-23:We can eliminate some of these computations by using easy to check necessary conditions for the ordered game isomorphic relation to hold .
14-24:One such condition is to check that the nodes have the same number of chances as being ranked (according to ) higher than, lower than, and the same as the opponents .
14-25:We can precompute these frequencies for every game tree node .
14-26:This substantially speeds up GameShrink, and we can leverage this database across multiple runs of the algorithm (for example, when trying different abstraction levels; see next section) .
14-27:The indices for this database depend on the private and public signals, but not the order in which they were revealed, and thus two nodes may have the same corresponding database entry .
14-28:This makes the database significantly more compact .
14-29:(For example in Texas Hold"em, the database is reduced by a factor `50 3 ´`47 1 ´`46 1 ´ `50 5 ´ = 20.) We store the histograms in a 2 dimensional database .
14-30:The first dimension is indexed by the private signals, the second by the public signals .
14-31:The problem of computing the index in (either) one of the dimensions is exactly the problem of computing a bijection between all subsets of size r from a set of size n and integers in ˆ 0, .
14-32:.
14-33:.
14-34:, `n r ´ − 1 ˜ .
14-35:We efficiently compute this using the subsets" colexicographical ordering [6] .
14-36:Let {c1, .
14-37:.
14-38:.
14-39:, cr}, ci ∈ {0, .
14-40:.
14-41:.
14-42:, n − 1}, denote the r signals and assume that ci < ci+1 .
14-43:We compute a unique index for this set of signals as follows: index(c1, .
14-44:.
14-45:.
14-46:, cr) = Pr i=1 `ci i ´ . .
15 APPROXIMATION METHODS :
15-1:Some games are too large to compute an exact equilibrium, even after using the presented abstraction technique .
15-2:This section discusses general techniques for computing approximately optimal strategy profiles .
15-3:For a two player game, we can always evaluate the worst case performance of a strategy, thus providing some objective evaluation of the strength of the strategy .
15-4:To illustrate this, suppose we know player 2"s planned strategy for some game .
15-5:We can then fix the probabilities of player 2"s actions in the game tree as if they were chance moves .
15-6:Then player 1 is faced with a single agent decision problem, which can be solved bottomup, maximizing expected payoff at every node .
15-7:Thus, we can objectively determine the expected worst case performance of player 2"s strategy .
15-8:This will be most useful when we want to evaluate how well a given strategy performs when we know that it is not an equilibrium strategy .
15-9:(A variation of this technique may also be applied in n person games where only one player"s strategies are held fixed.) This technique provides ex post guarantees about the worst case performance of a strategy, and can be used independently of the method that is used to compute the strategies .
15-10:5.1 State space approximations By slightly modifying GameShrink, we can obtain an algorithm that yields even smaller game trees, at the expense of losing the equilibrium guarantees of Theorem 2 .
15-11:Instead of requiring the payoffs at terminal nodes to match exactly, we can instead compute a penalty that increases as the difference in utility between two nodes increases .
15-12:There are many ways in which the penalty function could be defined and implemented .
15-13:One possibility is to create edge weights in the bipartite graphs used in Algorithm 1, and then instead of requiring perfect matchings in the unweighted graph we would instead require perfect matchings with low cost (i.e., only consider two nodes to be ordered game isomorphic if the corresponding bipartite graph has a perfect matching with cost below some threshold) .
15-14:Thus, with this threshold as a parameter, we have a knob to turn that in one extreme (threshold = 0) yields an optimal abstraction and in the other extreme (threshold = ∞) yields a highly abstracted game (this would in effect restrict players to ignoring all signals, but still observing actions) .
15-15:This knob also begets an anytime algorithm .
15-16:One can solve increasingly less abstracted versions of the game, and evaluate the quality of the solution at every iteration using the ex post method discussed above .
15-17:5.2 Algorithmic approximations In the case of two player zero sum games, the equilibrium computation can be modeled as a linear program (LP), which can in turn be solved using the simplex method .
15-18:This approach has inherent features which we can leverage into desirable properties in the context of solving games .
15-19:In the LP, primal solutions correspond to strategies of player 2, and dual solutions correspond to strategies of player simplex and the dual simplex .
15-20:The primal simplex maintains primal feasibility and proceeds by finding better and better primal solutions until the dual solution vector is feasible, 167 at which point optimality has been reached .
15-21:Analogously, the dual simplex maintains dual feasibility and proceeds by finding increasingly better dual solutions until the primal solution vector is feasible .
15-22:(The dual simplex method can be thought of as running the primal simplex method on the dual problem.) Thus, the primal and dual simplex methods serve as anytime algorithms (for a given abstraction) for players 2 and 1, respectively .
15-23:At any point in time, they can output the best strategies found so far .
15-24:Also, for any feasible solution to the LP, we can get bounds on the quality of the strategies by examining the primal and dual solutions .
15-25:(When using the primal simplex method, dual solutions may be read off of the LP tableau.) Every feasible solution of the dual yields an upper bound on the optimal value of the primal, and vice versa [9, p .
15-26:57] .
15-27:Thus, without requiring further computation, we get lower bounds on the expected utility of each agent"s strategy against that agent"s worst case opponent .
15-28:One problem with the simplex method is that it is not a primal dual algorithm, that is, it does not maintain both primal and dual feasibility throughout its execution .
15-29:(In fact, it only obtains primal and dual feasibility at the very end of execution.) In contrast, there are interior point methods for linear programming that maintain primal and dual feasibility throughout the execution .
15-30:For example, many interiorpoint path following algorithms have this property [55, Ch .
15-31:5] .
15-32:We observe that running such a linear programming method yields a method for finding equilibria (i.e., strategy profiles in which no agent can increase her expected utility by more than by deviating) .
15-33:A threshold on can also be used as a termination criterion for using the method as an anytime algorithm .
15-34:Furthermore, interior point methods in this class have polynomial time worst case run time, as opposed to the simplex algorithm, which takes exponentially many steps in the worst case. .
16 Abstraction techniques have been used in artificial :
16-1:Functions that transform extensive form games have been introduced [50, 11] .
16-2:In contrast to our work, those approaches were not for making the game smaller and easier to solve .
16-3:The main result is that a game can be derived from another by a sequence of those transformations if and only if the games have the same pure reduced normal form .
16-4:The pure reduced normal form is the extensive form game represented as a game in normal form where duplicates of pure strategies (i.e., ones with identical payoffs) are removed and players essentially select equivalence classes of strategies [27] .
16-5:An extension to that work shows a similar result, but for slightly different transformations and mixed reduced normal form games [21] .
16-6:Modern treatments of this prior work on game transformations exist [38, Ch .
16-7:6], [10] .
16-8:The recent notion of weak isomorphism in extensive form games [7] is related to our notion of restricted game isomorphism .
16-9:The motivation of that work was to justify solution concepts by arguing that they are invariant with respect to isomorphic transformations .
16-10:Indeed, the author shows, among other things, that many solution concepts, including Nash, perfect, subgame perfect, and sequential equilibrium, are invariant with respect to weak isomorphisms .
16-11:However, that definition requires that the games to be tested for weak isomorphism are of the same size .
16-12:Our focus is totally different: we find strategically equivalent smaller games .
16-13:Also, their paper does not provide algorithms .
16-14:Abstraction techniques have been used in artificial intelligence research before .
16-15:In contrast to our work, most (but not all) research involving abstraction has been for singleagent problems (e.g .
16-16:[20, 32]) .
16-17:Furthermore, the use of abstraction typically leads to sub optimal solutions, unlike the techniques presented in this paper, which yield optimal solutions .
16-18:A notable exception is the use of abstraction to compute optimal strategies for the game of Sprouts [2] .
16-19:However, a significant difference to our work is that Sprouts is a game of perfect information .
16-20:One of the first pieces of research to use abstraction in multi agent settings was the development of partition search, which is the algorithm behind GIB, the world"s first expertlevel computer bridge player [17, 18] .
16-21:In contrast to other game tree search algorithms which store a particular game position at each node of the search tree, partition search stores groups of positions that are similar .
16-22:(Typically, the similarity of two game positions is computed by ignoring the less important components of each game position and then checking whether the abstracted positions are similar in some domain specific expert defined sense to each other.) Partition search can lead to substantial speed improvements over α β search .
16-23:However, it is not game theory based (it does not consider information sets in the game tree), and thus does not solve for the equilibrium of a game of imperfect information, such as poker.8 Another difference is that the abstraction is defined by an expert human while our abstractions are determined automatically .
16-24:There has been some research on the use of abstraction for imperfect information games .
16-25:Most notably, Billings et al [4] describe a manually constructed abstraction for Texas Hold"em poker, and include promising results against expert players .
16-26:However, this approach has significant drawbacks .
16-27:First, it is highly specialized for Texas Hold"em .
16-28:Second, a large amount of expert knowledge and effort was used in constructing the abstraction .
16-29:Third, the abstraction does not preserve equilibrium: even if applied to a smaller game, it might not yield a game theoretic equilibrium .
16-30:Promising ideas for abstraction in the context of general extensive form games have been described in an extended abstract [39], but to our knowledge, have not been fully developed. .
17-1:We introduced the ordered game isomorphic abstraction transformation and gave an algorithm, GameShrink, for abstracting the game using the isomorphism exhaustively
17-2:We proved that in games with ordered signals, any Nash equilibrium in the smaller abstracted game maps directly to a Nash equilibrium in the original game
17-3:The complexity of GameShrink is ˜O(n2 ), where n is the number of nodes in the signal tree
17-4:It is no larger than the game tree, and on nontrivial games it is drastically smaller, so GameShrink has time and space complexity sublinear in 8 Bridge is also a game of imperfect information, and partition search does not find the equilibrium for that game either
17-5:Instead, partition search is used in conjunction with statistical sampling to simulate the uncertainty in bridge
17-6:There are also other bridge programs that use search techniques for perfect information games in conjunction with statistical sampling and expert defined abstraction [48]
17-7:Such (non game theoretic) techniques are unlikely to be competitive in poker because of the greater importance of information hiding and bluffing
17-8:168 the size of the game tree
17-9:Using GameShrink, we found a minimax equilibrium to Rhode Island Hold"em, a poker game with 3.1 billion nodes in the game tree over four orders of magnitude more than in the largest poker game solved previously
17-10:To further improve scalability, we introduced an approximation variant of GameShrink, which can be used as an anytime algorithm by varying a parameter that controls the coarseness of abstraction
17-11:We also discussed how (in a two player zero sum game), linear programming can be used in an anytime manner to generate approximately optimal strategies of increasing quality
17-12:The method also yields bounds on the suboptimality of the resulting strategies
17-13:We are currently working on using these techniques for full scale 2 player limit Texas Hold"em poker, a highly popular card game whose game tree has about 1018 nodes
17-14:That game tree size has required us to use the approximation version of GameShrink (as well as round based abstraction) [16, 15]
17-15:poker
17-16:In Computers and Games, pages 333 345
17-17:Springer Verlag, 2001
17-18:[48] S
17-19:J
17-20:J
17-21:Smith, D
17-22:S
17-23:Nau, and T
17-24:Throop
17-25:Computer bridge: A big win for AI planning
17-26:AI Magazine, 19(2):93 105, 1998
17-27:[49] R
17-28:E
17-29:Tarjan
17-30:Efficiency of a good but not linear set union algorithm
17-31:Journal of the ACM, 22(2):215 225, 1975
17-32:[50] F
17-33:Thompson
17-34:Equivalence of games in extensive form
17-35:RAND Memo RM 759, The RAND Corporation, Jan
17-36:1952
17-37:[51] J
17-38:von Neumann and O
17-39:Morgenstern
17-40:Theory of games and economic behavior
17-41:Princeton University Press, 1947
17-42:[52] B
17-43:von Stengel
17-44:Efficient computation of behavior strategies
17-45:Games and Economic Behavior, 14(2):220 246, 1996
17-46:[53] B
17-47:von Stengel
17-48:Computing equilibria for two person games
17-49:In Handbook of Game Theory, volume 3
17-50:North Holland, Amsterdam, 2002
17-51:[54] R
17-52:Wilson
17-53:Computing equilibria of two person games from the extensive form
17-54:Management Science, 18(7):448 460, 1972
17-55:[55] S
17-56:J
17-57:Wright
17-58:Primal Dual Interior Point Methods
17-59:SIAM, 1997
17-60:169
18-1:W
18-2:Ackermann
18-3:Zum Hilbertschen Aufbau der reellen Zahlen
18-4:Math
18-5:Annalen, 99:118 133, 1928
18-6:D
18-7:Applegate, G
18-8:Jacobson, and D
18-9:Sleator
18-10:Computer analysis of sprouts
18-11:Technical Report CMU CS 91 144, 1991
18-12:R
18-13:Bellman and D
18-14:Blackwell
18-15:Some two person games involving bluffing
18-16:PNAS, 35:600 605, 1949
18-17:D
18-18:Billings, N
18-19:Burch, A
18-20:Davidson, R
18-21:Holte, J
18-22:Schaeffer, T
18-23:Schauenberg, and D
18-24:Szafron
18-25:Approximating game theoretic optimal strategies for full scale poker
18-26:In IJCAI, 2003
18-27:D
18-28:Billings, A
18-29:Davidson, J
18-30:Schaeffer, and D
18-31:Szafron
18-32:The challenge of poker
18-33:Artificial Intelligence, 134:201 240, 2002
18-34:B
18-35:Bollob´as
18-36:Combinatorics
18-37:Cambridge University Press, 1986
18-38:A
18-39:Casajus
18-40:Weak isomorphism of extensive games
18-41:Mathematical Social Sciences, 46:267 290, 2003
18-42:X
18-43:Chen and X
18-44:Deng
18-45:Settling the complexity of 2 player Nash equilibrium
18-46:ECCC, Report No
18-47:150, 2005
18-48:V
18-49:Chv´atal
18-50:Linear Programming
18-51:W
18-52:H
18-53:Freeman & Co., 1983
18-54:B
18-55:P
18-56:de Bruin
18-57:Game transformations and game equivalence
18-58:Technical note x 1999 01, University of Amsterdam, Institute for Logic, Language, and Computation, 1999
18-59:S
18-60:Elmes and P
18-61:J
18-62:Reny
18-63:On the strategic equivalence of extensive form games
18-64:J
18-65:of Economic Theory, 62:1 23, 1994
18-66:L
18-67:R
18-68:Ford, Jr
18-69:and D
18-70:R
18-71:Fulkerson
18-72:Flows in Networks
18-73:Princeton University Press, 1962
18-74:A
18-75:Gilpin and T
18-76:Sandholm
18-77:Finding equilibria in large sequential games of imperfect information
18-78:Technical Report CMU CS 05 158, Carnegie Mellon University, 2005
18-79:A
18-80:Gilpin and T
18-81:Sandholm
18-82:Optimal Rhode Island Hold"em poker
18-83:In AAAI, pages 1684 1685, Pittsburgh, PA, USA, 2005
18-84:A
18-85:Gilpin and T
18-86:Sandholm
18-87:A competitive Texas Hold"em poker player via automated abstraction and real time equilibrium computation
18-88:Mimeo, 2006
18-89:A
18-90:Gilpin and T
18-91:Sandholm
18-92:A Texas Hold"em poker player based on automated abstraction and real time equilibrium computation
18-93:In AAMAS, Hakodate, Japan, 2006
18-94:M
18-95:L
18-96:Ginsberg
18-97:Partition search
18-98:In AAAI, pages 228 233, Portland, OR, 1996
18-99:M
18-100:L
18-101:Ginsberg
18-102:GIB: Steps toward an expert level bridge playing program
18-103:In IJCAI, Stockholm, Sweden, 1999
18-104:S
18-105:Govindan and R
18-106:Wilson
18-107:A global Newton method to compute Nash equilibria
18-108:J
18-109:of Econ
18-110:Theory, 110:65 86, 2003
18-111:C
18-112:A
18-113:Knoblock
18-114:Automatically generating abstractions for planning
18-115:Artificial Intelligence, 68(2):243 302, 1994
18-116:E
18-117:Kohlberg and J. F
18-118:Mertens
18-119:On the strategic stability of equilibria
18-120:Econometrica, 54:1003 1037, 1986
18-121:D
18-122:Koller and N
18-123:Megiddo
18-124:The complexity of two person zero sum games in extensive form
18-125:Games and Economic Behavior, 4(4):528 552, Oct
18-126:1992
18-127:D
18-128:Koller and N
18-129:Megiddo
18-130:Finding mixed strategies with small supports in extensive form games
18-131:International Journal of Game Theory, 25:73 92, 1996
18-132:D
18-133:Koller, N
18-134:Megiddo, and B
18-135:von Stengel
18-136:Efficient computation of equilibria for extensive two person games
18-137:Games and Economic Behavior, 14(2):247 259, 1996
18-138:D
18-139:Koller and A
18-140:Pfeffer
18-141:Representations and solutions for game theoretic problems
18-142:Artificial Intelligence, 94(1):167 215, July 1997
18-143:D
18-144:M
18-145:Kreps and R
18-146:Wilson
18-147:Sequential equilibria
18-148:Econometrica, 50(4):863 894, 1982
18-149:H
18-150:W
18-151:Kuhn
18-152:Extensive games
18-153:PNAS, 36:570 576, 1950
18-154:H
18-155:W
18-156:Kuhn
18-157:A simplified two person poker
18-158:In Contributions to the Theory of Games, volume 1 of Annals of Mathematics Studies, 24, pages 97 103
18-159:Princeton University Press, 1950
18-160:H
18-161:W
18-162:Kuhn
18-163:Extensive games and the problem of information
18-164:In Contributions to the Theory of Games, volume 2 of Annals of Mathematics Studies, 28, pages 193 216
18-165:Princeton University Press, 1953
18-166:C
18-167:Lemke and J
18-168:Howson
18-169:Equilibrium points of bimatrix games
18-170:Journal of the Society for Industrial and Applied Mathematics, 12:413 423, 1964
18-171:R
18-172:Lipton, E
18-173:Markakis, and A
18-174:Mehta
18-175:Playing large games using simple strategies
18-176:In ACM EC, pages 36 41, 2003
18-177:C. L
18-178:Liu and M
18-179:Wellman
18-180:On state space abstraction for anytime evaluation of Bayesian networks
18-181:SIGART Bulletin, 7(2):50 57, 1996
18-182:A
18-183:Mas Colell, M
18-184:Whinston, and J
18-185:R
18-186:Green
18-187:Microeconomic Theory
18-188:Oxford University Press, 1995
18-189:R
18-190:D
18-191:McKelvey and A
18-192:McLennan
18-193:Computation of equilibria in finite games
18-194:In Handbook of Computational Economics, volume 1, pages 87 142
18-195:Elsevier, 1996
18-196:P
18-197:B
18-198:Miltersen and T
18-199:B
18-200:Sørensen
18-201:Computing sequential equilibria for two player games
18-202:In SODA, pages 107 116, 2006
18-203:J
18-204:Nash
18-205:Equilibrium points in n person games
18-206:Proc
18-207:of the National Academy of Sciences, 36:48 49, 1950
18-208:J
18-209:F
18-210:Nash and L
18-211:S
18-212:Shapley
18-213:A simple three person poker game
18-214:In Contributions to the Theory of Games, volume 1, pages 105 116
18-215:Princeton University Press, 1950
18-216:A
18-217:Perea
18-218:Rationality in extensive form games
18-219:Kluwer Academic Publishers, 2001
18-220:A
18-221:Pfeffer, D
18-222:Koller, and K
18-223:Takusagawa
18-224:State space approximations for extensive form games, July 2000
18-225:Talk given at the First International Congress of the Game Theory Society, Bilbao, Spain
18-226:R
18-227:Porter, E
18-228:Nudelman, and Y
18-229:Shoham
18-230:Simple search methods for finding a Nash equilibrium
18-231:In AAAI, pages 664 669, San Jose, CA, USA, 2004
18-232:I
18-233:Romanovskii
18-234:Reduction of a game with complete memory to a matrix game
18-235:Soviet Mathematics, 3:678 681, 1962
18-236:T
18-237:Sandholm and A
18-238:Gilpin
18-239:Sequences of take it or leave it offers: Near optimal auctions without full valuation revelation
18-240:In AAMAS, Hakodate, Japan, 2006
18-241:T
18-242:Sandholm, A
18-243:Gilpin, and V
18-244:Conitzer
18-245:Mixed integer programming methods for finding Nash equilibria
18-246:In AAAI, pages 495 501, Pittsburgh, PA, USA, 2005
18-247:R
18-248:Savani and B
18-249:von Stengel
18-250:Exponentially many steps for finding a Nash equilibrium in a bimatrix game
18-251:In FOCS, pages 258 267, 2004
18-252:R
18-253:Selten
18-254:Spieltheoretische behandlung eines oligopolmodells mit nachfragetr¨agheit
18-255:Zeitschrift f¨ur die gesamte Staatswissenschaft, 12:301 324, 1965
18-256:R
18-257:Selten
18-258:Evolutionary stability in extensive two person games  correction and further development
18-259:Mathematical Social Sciences, 16:223 266, 1988
picture:
