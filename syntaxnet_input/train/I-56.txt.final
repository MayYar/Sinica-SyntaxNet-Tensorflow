Unifying Distributed Constraint Algorithms in a BDI 
content:
1 ABSTRACT :
1-1:This paper presents a novel, unified distributed constraint satisfaction framework based on automated negotiation .
1-2:The Distributed Constraint Satisfaction Problem is one that entails several agents to search for an agreement, which is a consistent combination of actions that satisfies their mutual constraints in a shared environment .
1-3:By anchoring the DCSP search on automated negotiation, we show that several well known DCSP algorithms are actually mechanisms that can reach agreements through a common Belief Desire Intention protocol, but using different strategies .
1-4:A major motivation for this BDI framework is that it not only provides a conceptually clearer understanding of existing DCSP algorithms from an agent model perspective, but also opens up the opportunities to extend and develop new strategies for DCSP .
1-5:To this end, a new strategy called Unsolicited Mutual Advice is proposed .
1-6:Performance evaluation shows that the UMA strategy can outperform some existing mechanisms in terms of computational cycles .
1-7:I.2.11 [Distributed Artificial Intelligence]: Intelligent .
2 INTRODUCTION :
2-1:At the core of many emerging distributed applications is the distributed constraint satisfaction problem one which involves finding a consistent combination of actions (abstracted as domain values) to satisfy the constraints among multiple agents in a shared environment .
2-2:Important application examples include distributed resource allocation [1] and distributed scheduling [2] .
2-3:Many important algorithms, such as distributed breakout [3], asynchronous backtracking [4], asynchronous partial overlay [5] and asynchronous weak commitment [4], have been developed to address the DCSP and provide the agent solution basis for its applications .
2-4:Broadly speaking, these algorithms are based on two different approaches, either extending from classical backtracking algorithms [6] or introducing mediation among the agents .
2-5:While there has been no lack of efforts in this promising research field, especially in dealing with outstanding issues such as resource restrictions (e.g., limits on time and communication) [7] and privacy requirements [8], there is unfortunately no conceptually clear treatment to prise open the model theoretic workings of the various agent algorithms that have been developed .
2-6:As a result, for instance, a deeper intellectual understanding on why one algorithm is better than the other, beyond computational issues, is not possible .
2-7:In this paper, we present a novel, unified distributed constraint satisfaction framework based on automated negotiation [9] .
2-8:Negotiation is viewed as a process of several agents searching for a solution called an agreement .
2-9:The search can be realized via a negotiation mechanism (or algorithm) by which the agents follow a high level protocol prescribing the rules of interactions, using a set of strategies devised to select their own preferences at each negotiation step .
2-10:Anchoring the DCSP search on automated negotiation, we show in this paper that several well known DCSP algorithms [3] are actually mechanisms that share the same Belief DesireIntention interaction protocol to reach agreements, but use different action or value selection strategies .
2-11:The proposed framework provides not only a clearer understanding of existing DCSP algorithms from a unified BDI agent perspective, but also opens up the opportunities to extend and develop new strategies for DCSP .
2-12:To this end, a new strategy called Unsolicited Mutual Advice is proposed .
2-13:Our performance evaluation shows that UMA can outperform ABT and AWC in terms of the average number of computational cycles for both the sparse and critical coloring problems [6] .
2-14:The rest of this paper is organized as follows .
2-15:In Section 2, we provide a formal overview of DCSP .
2-16:Section 3 presents a BDI negotiation model by which a DCSP agent reasons .
2-17:Section 4 presents the existing algorithms ABT, AWC and DBO as different strategies formalized on a common protocol .
2-18:A new strategy called Unsolicited Mutual Advice is proposed in Section 5; our empirical results and discussion attempt to highlight the merits of the new strategy over existing ones .
2-19:Section 6 concludes the paper and points to some future work. .
3 DCSP: PROBLEM FORMALIZATION :
3-1:The DCSP [4] considers the following environment .
3-2:• There are n agents with k variables x0, x1, · · · , xk−1, n ≤ k, which have values in domains D1, D2, · · · , Dk, respectively .
3-3:We define a partial function B over the productrange {0, 1, .
3-4:.
3-5:.
3-6:, (n−1)}×{0, 1, .
3-7:.
3-8:.
3-9:, (k −1)} such that, that variable xj belongs to agent i is denoted by B(i, j)! .
3-10:The exclamation mark ‘!" means ‘is defined" .
3-11:• There are m constraints c0, c1, · · · cm−1 to be conjunctively satisfied .
3-12:In a similar fashion as defined for B(i, j), we use E(l, j)!, (0 ≤ l < m, 0 ≤ j < k), to denote that xj is relevant to the constraint cl .
3-13:The DCSP may be formally stated as follows .
3-14:Problem Statement: ∀i, j (0 ≤ i < n)(0 ≤ j < k) where B(i, j)!, find the assignment xj = dj ∈ Dj such that ∀l (0 ≤ l < m) where E(l, j)!, cl is satisfied .
3-15:A constraint may consist of different variables belonging to different agents .
3-16:An agent cannot change or modify the assignment values of other agents" variables .
3-17:Therefore, in cooperatively searching for a DCSP solution, the agents would need to communicate with one another, and adjust and re adjust their own variable assignments in the process .
3-18:2.1 DCSP Agent Model In general, all DCSP agents must cooperatively interact, and essentially perform the assignment and reassignment of domain values to variables to resolve all constraint violations .
3-19:If the agents succeed in their resolution, a solution is found .
3-20:In order to engage in cooperative behavior, a DCSP agent needs five fundamental parameters, namely, (i) a variable [4] or a variable set [10], (ii) domains, (iii) priority, (iv) a neighbor list and (v) a constraint list .
3-21:Each variable assumes a range of values called a domain .
3-22:A domain value, which usually abstracts an action, is a possible option that an agent may take .
3-23:Each agent has an assigned priority .
3-24:These priority values help decide the order in which they revise or modify their variable assignments .
3-25:An agent"s priority may be fixed (static) or changing (dynamic) when searching for a solution .
3-26:If an agent has more than one variable, each variable can be assigned a different priority, to help determine which variable assignment the agent should modify first .
3-27:An agent which shares the same constraint with another agent is called the latter"s neighbor .
3-28:Each agent needs to refer to its list of neighbors during the search process .
3-29:This list may also be kept unchanged or updated accordingly in runtime .
3-30:Similarly, each agent maintains a constraint list .
3-31:The agent needs to ensure that there is no violation of the constraints in this list .
3-32:Constraints can be added or removed from an agent"s constraint list in runtime .
3-33:As with an agent, a constraint can also be associated with a priority value .
3-34:Constraints with a high priority are said to be more important than constraints with a lower priority .
3-35:To distinguish it from the priority of an agent, the priority of a constraint is called its weight. .
4 THE BDI NEGOTIATION MODEL :
4-1:The BDI model originates with the work of M .
4-2:Bratman [11] .
4-3:According to [12, Ch.1], the BDI architecture is based on a philosophical model of human practical reasoning, and draws out the process of reasoning by which an agent decides which actions to perform at consecutive moments when pursuing certain goals .
4-4:Grounding the scope to the DCSP framework, the common goal of all agents is finding a combination of domain values to satisfy a set of predefined constraints .
4-5:In automated negotiation [9], such a solution is called an agreement among the agents .
4-6:Within this scope, we found that we were able to unearth the generic behavior of a DCSP agent and formulate it in a negotiation protocol, prescribed using the powerful concepts of BDI .
4-7:Thus, our proposed negotiation model can be said to combine the BDI concepts with automated negotiation in a multiagent framework, allowing us to conceptually separate DCSP mechanisms into a common BDI interaction protocol and the adopted strategies .
4-8:3.1 The generic protocol Figure 1 shows the basic reasoning steps in an arbitrary round of negotiation that constitute the new protocol .
4-9:The solid line indicates the common component or transition which always exists regardless of the strategy used .
4-10:The dotted line indicates the Percept Belief Desire Intention Mediation Execution P B D I I I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 1: The BDI interaction protocol component or transition which may or may not appear depending on the adopted strategy .
4-11:Two types of messages are exchanged through this protocol, namely, the info message and the negotiation message .
4-12:An info message perceived is a message sent by another agent .
4-13:The message will contain the current selected values and priorities of the variables of that sending agent .
4-14:The main purpose of this message is to update the agent about the current environment .
4-15:Info message is sent out at the end of one negotiation round (also called a negotiation cycle), and received at the beginning of next round .
4-16:A negotiation message is a message which may be sent within a round .
4-17:This message is for mediation purposes .
4-18:The agent may put different contents into this type of message as long as it is agreed among the group .
4-19:The format of the negotiation message and when it is to be sent out are subject to the strategy .
4-20:A negotiation message can be sent out at the end of one reasoning step and received at the beginning of the next step .
4-21:Mediation is a step of the protocol that depends on whether the agent"s interaction with others is synchronous or asynchronous .
4-22:In synchronous mechanism, mediation is required in every negotiation round .
4-23:In an asynchronous one, mediation is needed only in a negotiation round when the agent receives a negotiation message .
4-24:A more in depth view of this mediation step is provided later in this section .
4-25:The BDI protocol prescribes the skeletal structure for DCSP negotiation .
4-26:We will show in Section 4 that several well known DCSP mechanisms all inherit this generic model .
4-27:The details of the six main reasoning steps for the protocol (see Figure 1) are described as follows for a DCSP agent .
4-28:For a conceptually clearer description, we assume that there is only one variable per agent .
4-29:• Percept .
4-30:In this step, the agent receives info messages from its neighbors in the environment, and using its Percept function, returns an image P .
4-31:This image contains the current values assigned to the variables of all agents in its neighbor list .
4-32:The image P will drive the agent"s actions in subsequent steps .
4-33:The agent also updates its constraint list C using some criteria of the adopted strategy .
4-34:• Belief .
4-35:Using the image P and constraint list C, the agent will check if there is any violated constraint .
4-36:If there is no violation, the agent will believe it is choosing a correct option and therefore will take no action .
4-37:The agent will do nothing if it is in a local stable state a snapshot of the variables assignments of the agent and all its neighbors by which they satisfy their shared constraints .
4-38:When all agents are in their local stable states, the whole environment is said to be in a global stable state and an agreeThe Sixth Intl .
4-39:Joint Conf .
4-40:on Autonomous Agents and Multi Agent Systems (AAMAS 07) 525 ment is found .
4-41:In case the agent finds its value in conflict with some of its neighbors", i.e., the combination of values assigned to the variables leads to a constraint violation, the agent will first try to reassign its own variable using a specific strategy .
4-42:If it finds a suitable option which meets some criteria of the adopted strategy, the agent will believe it should change to the new option .
4-43:However it does not always happen that an agent can successfully find such an option .
4-44:If no option can be found, the agent will believe it has no option, and therefore will request its neighbors to reconsider their variable assignments .
4-45:To summarize, there are three types of beliefs that a DCSP agent can form: (i) it can change its variable assignment to improve the current situation, (ii) it cannot change its variable assignment and some constraints violations cannot be resolved and (iii) it need not change its variable assignment as all the constraints are satisfied .
4-46:Once the beliefs are formed, the agent will determine its desires, which are the options that attempt to resolve the current constraint violations .
4-47:• Desire .
4-48:If the agent takes Belief (i), it will generate a list of its own suitable domain values as its desire set .
4-49:If the agent takes Belief (ii), it cannot ascertain its desire set, but will generate a sublist of agents from its neighbor list, whom it will ask to reconsider their variable assignments .
4-50:How this sublist is created depends on the strategy devised for the agent .
4-51:In this situation, the agent will use a virtual desire set that it determines based on its adopted strategy .
4-52:If the agent takes Belief (iii), it will have no desire to revise its domain value, and hence no intention .
4-53:• Intention .
4-54:The agent will select a value from its desire set as its intention .
4-55:An intention is the best desired option that the agent assigns to its variable .
4-56:The criteria for selecting a desire as the agent"s intention depend on the strategy used .
4-57:Once the intention is formed, the agent may either proceed to the execution step, or undergo mediation .
4-58:Again, the decision to do so is determined by some criteria of the adopted strategy .
4-59:• Mediation .
4-60:This is an important function of the agent .
4-61:Since, if the agent executes its intention without performing intention mediation with its neighbors, the constraint violation between the agents may not be resolved .
4-62:Take for example, suppose two agents have variables, x1 and x2, associated with the same domain {1, 2}, and their shared constraint is (x1 + x2 = 3) .
4-63:Then if both the variables are initialized with value 1, they will both concurrently switch between the values 2 and 1 in the absence of mediation between them .
4-64:There are two types of mediation: local mediation and group mediation .
4-65:In the former, the agents exchange their intentions .
4-66:When an agent receives another"s intention which conflicts with its own, the agent must mediate between the intentions, by either changing its own intention or informing the other agent to change its intention .
4-67:In the latter, there is an agent which acts as a group mediator .
4-68:This mediator will collect the intentions from the group a union of the agent and its neighbors and determine which intention is to be executed .
4-69:The result of this mediation is passed back to the agents in the group .
4-70:Following mediation, the agent may proceed to the next reasoning step to execute its intention or begin a new negotiation round .
4-71:• Execution .
4-72:This is the last step of a negotiation round .
4-73:The agent will execute by updating its variable assignment if the intention obtained at this step is its own .
4-74:Following execution, the agent will inform its neighbors about its new variable assignment and updated priority .
4-75:To do so, the agent will send out an info message .
4-76:3.2 The strategy A strategy plays an important role in the negotiation process .
4-77:Within the protocol, it will often determine the efficiency of the Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 2: BDI protocol with Asynchronous Backtracking strategy search process in terms of computational cycles and message communication costs .
4-78:The design space when devising a strategy is influenced by the following dimensions: (i) asynchronous or synchronous, (ii) dynamic or static priority, (iii) dynamic or static constraint weight, (iv) number of negotiation messages to be communicated, (v) the negotiation message format and (vi) the completeness property .
4-79:In other words, these dimensions provide technical considerations for a strategy design. .
5 DCSP ALGORITHMS: BDI PROTOCOL + STRATEGIES :
5-1:+ STRATEGIES In this section, we apply the proposed BDI negotiation model presented in Section 3 to expose the BDI protocol and the different strategies used for three well known algorithms, ABT, AWC and DBO .
5-2:All these algorithms assume that there is only one variable per agent .
5-3:Under our framework, we call the strategies applied the ABT, AWC and DBO strategies, respectively .
5-4:To describe each strategy formally, the following mathematical notations are used: • n is the number of agents, m is the number of constraints; • xi denotes the variable held by agent i, (0 ≤ i < n); • Di denotes the domain of variable xi; Fi denotes the neighbor list of agent i; Ci denotes its constraint list; • pi denotes the priority of agent i; and Pi = {(xj = vj, pj = k) | agent j ∈ Fi, vj ∈ Dj is the current value assigned to xj and the priority value k is a positive integer } is the perception of agent i; • wl denotes the weight of constraint l, (0 ≤ l < m); • Si(v) is the total weight of the violated constraints in Ci when its variable has the value v ∈ Di .
5-5:4.1 Asynchronous Backtracking Figure 2 presents the BDI negotiation model incorporating the Asynchronous Backtracking strategy .
5-6:As mentioned in Section 3, for an asynchronous mechanism that ABT is, the mediation step is needed only in a negotiation round when an agent receives a negotiation message .
5-7:For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI driven ABT strategy is described as follows .
5-8:Step 1 Percept: Update Pi upon receiving the info messages from the neighbors (in Fi) .
5-9:Update Ci to be the list of 526 The Sixth Intl .
5-10:Joint Conf .
5-11:on Autonomous Agents and Multi Agent Systems (AAMAS 07) constraints which only consists of agents in Fi that have equal or higher priority than this agent .
5-12:Step 2 Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an optimal option, i.e., if (Si(vi) = 0 or vi is in bad values list) and (∃a ∈ Di)(Si(a) = 0) and a is not in a list of domain values called bad values list .
5-13:Initially this list is empty and it will be cleared when a neighbor of higher priority changes its variable assignment .
5-14:• bi = 1 when it cannot find an optimal option, i.e., if (∀a ∈ Di)(Si(a) = 0) or a is in bad values list .
5-15:• bi = 2 when its current variable assignment is an optimal option, i.e., if Si(vi) = 0 and vi is not in bad value list .
5-16:Step 3 Desire: The desire function GD (bi) will return a desire set denoted by DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and a is not in the bad value list } .
5-17:• If bi = 1, then DS = ∅, the agent also finds agent k which is determined by {k | pk = min(pj) with agent j ∈ Fi and pk > pi } .
5-18:• If bi = 2, then DS = ∅ .
5-19:Step 4 Intention: The intention function GI will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention .
5-20:• If DS = ∅, then assign nil as the intention (to denote its lack thereof) .
5-21:Step 5 Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value .
5-22:• If bi = 1, agent i will send a negotiation message to agent k, then remove k from Fi and begin its next negotiation round .
5-23:The negotiation message will contain the list of variable assignments of those agents in its neighbor list Fi that have a higher priority than agent i in the current image Pi .
5-24:Mediation: When agent i receives a negotiation message, several sub steps are carried out, as follows: • If the list of agents associated with the negotiation message contains agents which are not in Fi, it will add these agents to Fi, and request these agents to add itself to their neighbor lists .
5-25:The request is considered as a type of negotiation message .
5-26:• Agent i will first check if the sender agent is updated with its current value vi .
5-27:The agent will add vi to its bad values list if it is so, or otherwise send its current value to the sender agent .
5-28:Following this step, agent i proceeds to the next negotiation round .
5-29:4.2 Asynchronous Weak Commitment Search Figure 3 presents the BDI negotiation model incorporating the Asynchronous Weak Commitment strategy .
5-30:The model is similar to that of incorporating the ABT strategy (see Figure 2) .
5-31:This is not surprising; AWC and ABT are found to be strategically similar, differing only in the details of some reasoning steps .
5-32:The distinguishing point of AWC is that when the agent cannot find a suitable variable assignment, it will change its priority to the highest among its group members ({i} ∪ Fi) .
5-33:For agent i, beginning initially with (wl = 1, (0 ≤ l < m); pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI driven AWC strategy is described as follows .
5-34:Step 1 Percept: This step is identical to the Percept step of ABT .
5-35:Step 2 Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: Percept Belief Desire Intention Mediation Execution P B D I Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Figure 3: BDI protocol with Asynchronous WeakCommitment strategy • bi = 0 when the agent can find an optimal option i.e., if (Si(vi) = 0 or the assignment xi = vi and the current variables assignments of the neighbors in Fi who have higher priority form a nogood [4]) stored in a list called nogood list and ∃a ∈ Di, Si(a) = 0 (initially the list is empty) .
5-36:• bi = 1 when the agent cannot find any optimal option i.e., if ∀a ∈ Di, Si(a) = 0 .
5-37:• bi = 2 when the current assignment is an optimal option i.e., if Si(vi) = 0 and the current state is not a nogood in nogood list .
5-38:Step 3 Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | (a = vi), (Si(a) = 0) and the number of constraint violations with lower priority agents is minimized } .
5-39:• If bi = 1, then DS = {a | a ∈ Di and the number of violations of all relevant constraints is minimized } .
5-40:• If bi = 2, then DS = ∅ .
5-41:Following, if bi = 1, agent i will find a list Ki of higher priority neighbors, defined by Ki = {k | agent k ∈ Fi and pk > pi} .
5-42:Step 4 Intention: This step is similar to the Intention step of ABT .
5-43:However, for this strategy, the negotiation message will contain the variable assignments (of the current image Pi) for all the agents in Ki .
5-44:This list of assignment is considered as a nogood .
5-45:If the same negotiation message had been sent out before, agent i will have nil intention .
5-46:Otherwise, the agent will send the message and save the nogood in the nogood list .
5-47:Step 5 Execution: • If agent i has a domain value as its intention, the agent will update its variable assignment with this value .
5-48:• If bi = 1, it will send the negotiation message to its neighbors in Ki, and set pi = max{pj} + 1, with agent j ∈ Fi .
5-49:Mediation: This step is identical to the Mediation step of ABT, except that agent i will now add the nogood contained in the negotiation message received to its own nogood list .
5-50:4.3 Distributed Breakout Figure 4 presents the BDI negotiation model incorporating the Distributed Breakout strategy .
5-51:Essentially, by this synchronous strategy, each agent will search iteratively for improvement by reducing the total weight of the violated constraints .
5-52:The iteration will continue until no agent can improve further, at which time if some constraints remain violated, the weights of The Sixth Intl .
5-53:Joint Conf .
5-54:on Autonomous Agents and Multi Agent Systems (AAMAS 07) 527 Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Figure 4: BDI protocol with Distributed Breakout strategy these constraints will be increased by 1 to help ‘breakout" from a local minimum .
5-55:For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI driven DBO strategy is described as follows .
5-56:Step 1 Percept: Update Pi upon receiving the info messages from the neighbors (in Fi) .
5-57:Update Ci to be the list of its relevant constraints .
5-58:Step 2 Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) .
5-59:• bi = 1 when it cannot find any option to improve situation, i.e., if ∀a ∈ Di, a = vi, Si(a) ≥ Si(vi) .
5-60:• bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0 .
5-61:Step 3 Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi)−Si(a)) is maximized } .
5-62:(max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines the maximal reduction in constraint violations) .
5-63:• Otherwise, DS = ∅ .
5-64:Step 4 Intention: The intention function GI will return an intention, decided as follows: • If DS = ∅, then select an arbitrary value (say, vi) from DS as the intention .
5-65:• If DS = ∅, then assign nil as the intention .
5-66:Following, agent i will send its intention to all its neighbors .
5-67:In return, it will receive intentions from these agents before proceeding to Mediation step .
5-68:Mediation: Agent i receives all the intentions from its neighbors .
5-69:If it finds that the intention received from a neighbor agent j is associated with hmax j > hmax i , the agent will automatically cancel its current intention .
5-70:Step 5 Execution: • If agent i did not cancel its intention, it will update its variable assignment with the intended value .
5-71:Percept Belief Desire Intention Mediation Execution P B D I I A Info Message Info Message Negotiation Message Negotiation Message Negotiation Message Negotiation Message Figure 5: BDI protocol with Unsolicited Mutual Advice strategy • If all intentions received and its own one are nil intention, the agent will increase the weight of each currently violated constraint by 1. .
6 THE UMA STRATEGY :
6-1:Figure 5 presents the BDI negotiation model incorporating the Unsolicited Mutual Advice(UMA) strategy .
6-2:Unlike when using the strategies of the previous section, a DCSP agent using UMA will not only send out a negotiation message when concluding its Intention step, but also when concluding its Desire step .
6-3:The negotiation message that it sends out to conclude the Desire step constitutes an unsolicited advice for all its neighbors .
6-4:In turn, the agent will wait to receive unsolicited advices from all its neighbors, before proceeding on to determine its intention .
6-5:For agent i, beginning initially with (wl = 1, (0 ≤ l < m), pi = i, (0 ≤ i < n)) and Fi contains all the agents who share the constraints with agent i, its BDI driven UMA strategy is described as follows .
6-6:Step 1 Percept: Update Pi upon receiving the info messages from the neighbors (in Fi) .
6-7:Update Ci to be the list of constraints relevant to agent i .
6-8:Step 2 Belief: The belief function GB (Pi,Ci) will return a value bi ∈ {0, 1, 2}, decided as follows: • bi = 0 when agent i can find an option to reduce the number violations of the constraints in Ci, i.e., if ∃a ∈ Di, Si(a) < Si(vi) and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in a list called bad states list (initially this list is empty) .
6-9:• bi = 1 when it cannot find a value a such as a ∈ Di, Si(a) < Si(vi), and the assignment xi = a and the current variable assignments of its neighbors do not form a local state stored in the bad states list .
6-10:• bi = 2 when its current assignment is an optimal option, i.e., if Si(vi) = 0 .
6-11:Step 3 Desire: The desire function GD (bi) will return a desire set DS, decided as follows: • If bi = 0, then DS = {a | a = vi, Si(a) < Si(vi) and (Si(vi) − Si(a)) is maximized } and the assignment xi = a and the current variable assignments of agent i"s neighbors do not form a state in the bad states list .
6-12:In this case, DS is called a set of voluntary desires .
6-13:max{(Si(vi)−Si(a))} will be referenced by hmax i in subsequent steps, and it defines 528 The Sixth Intl .
6-14:Joint Conf .
6-15:on Autonomous Agents and Multi Agent Systems (AAMAS 07) the maximal reduction in constraint violations .
6-16:It is also referred to as an improvement) .
6-17:• If bi = 1, then DS = {a | a = vi, Si(a) is minimized } and the assignment xi = a and the current variable assignments of agent i"s neighbors do not form a state in the bad states list .
6-18:In this case, DS is called a set of reluctant desires • If bi = 2, then DS = ∅ .
6-19:Following, if bi = 0, agent i will send a negotiation message containing hmax i to all its neighbors .
6-20:This message is called a voluntary advice .
6-21:If bi = 1, agent i will send a negotiation message called change advice to the neighbors in Fi who share the violated constraints with agent i .
6-22:Agent i receives advices from all its neighbors and stores them in a list called A, before proceeding to the next step .
6-23:Step 4 Intention: The intention function GI (DS, A) will return an intention, decided as follows: • If there is a voluntary advice from an agent j which is associated with hmax j > hmax i , assign nil as the intention .
6-24:• If DS = ∅, DS is a set of voluntary desires and hmax i is the biggest improvement among those associated with the voluntary advices received, select an arbitrary value (say, vi) from DS as the intention .
6-25:This intention is called a voluntary intention .
6-26:• If DS = ∅, DS is a set of reluctant desires and agent i receives some change advices, select an arbitrary value (say, vi) from DS as the intention .
6-27:This intention is called reluctant intention .
6-28:• If DS = ∅, then assign nil as the intention .
6-29:Following, if the improvement hmax i is the biggest improvement and equal to some improvements associated with the received voluntary advices, agent i will send its computed intention to all its neighbors .
6-30:If agent i has a reluctant intention, it will also send this intention to all its neighbors .
6-31:In both cases, agent i will attach the number of received change advices in the current negotiation round with its intention .
6-32:In return, agent i will receive the intentions from its neighbors before proceeding to Mediation step .
6-33:Mediation: If agent i does not send out its intention before this step, i.e., the agent has either a nil intention or a voluntary intention with biggest improvement, it will proceed to next step .
6-34:Otherwise, agent i will select the best intention among all the intentions received, including its own (if any) .
6-35:The criteria to select the best intention are listed, applied in descending order of importance as follows .
6-36:• A voluntary intention is preferred over a reluctant intention .
6-37:• A voluntary intention (if any) with biggest improvement is selected .
6-38:• If there is no voluntary intention, the reluctant intention with the lowest number of constraint violations is selected .
6-39:• The intention from an agent who has received a higher number of change advices in the current negotiation round is selected .
6-40:• Intention from an agent with highest priority is selected .
6-41:If the selected intention is not agent i"s intention, it will cancel its intention .
6-42:Step 5 Execution: If agent i does not cancel its intention, it will update its variable assignment with the intended value .
6-43:Termination Condition: Since each agent does not have full information about the global state, it may not know when it has reached a solution, i.e., when all the agents are in a global stable state .
6-44:Hence an observer is needed that will keep track of the negotiation messages communicated in the environment .
6-45:Following a certain period of time when there is no more message communication (and this happens when all the agents have no more intention to update their variable assignments), the observer will inform the agents in the environment that a solution has been found .
6-46:1 2 3 4 5 6 7 8 9 10 Figure 6: Example problem 5.1 An Example To illustrate how UMA works, consider a 2 color graph problem [6] as shown in Figure 6 .
6-47:In this example, each agent has a color variable representing a node .
6-48:There are 10 color variables sharing the same domain {Black, White} .
6-49:The following records the outcome of each step in every negotiation round executed .
6-50:Round 1: Step 1 Percept: Each agent obtains the current color assignments of those nodes (agents) adjacent to it, i.e., its neighbors" .
6-51:Step 2 Belief: Agents which have positive improvements are agent 1 (this agent believes it should change its color to White), agent 2 (this believes should change its color to White), agent 7 (this agent believes it should change its color to Black) and agent 10 (this agent believes it should change its value to Black) .
6-52:In this negotiation round, the improvements achieved by these agents are 1 .
6-53:Agents which do not have any improvements are agents 4, 5 and 8 .
6-54:Agents 3, 6 and 9 need not change as all their relevant constraints are satisfied .
6-55:Step 3 Desire: Agents 1, 2, 7 and 10 have the voluntary desire (White color for agents 1, 2 and Black color for agents 7, 10) .
6-56:These agents will send the voluntary advices to all their neighbors .
6-57:Meanwhile, agents 4, 5 and 8 have the reluctant desires (White color for agent 4 and Black color for agents 5, 8) .
6-58:Agent 4 will send a change advice to agent 2 as agent 2 is sharing the violated constraint with it .
6-59:Similarly, agents 5 and 8 will send change advices to agents 7 and 10 respectively .
6-60:Agents 3, 6 and 9 do not have any desire to update their color assignments .
6-61:Step 4 Intention: Agents 2, 7 and 10 receive the change advices from agents 4, 5 and 8, respectively .
6-62:They form their voluntary intentions .
6-63:Agents 4, 5 and 8 receive the voluntary advices from agents 2, 7 and 10, hence they will not have any intention .
6-64:Agents 3, 6 and 9 do not have any intention .
6-65:Following, the intention from the agents will be sent to all their neighbors .
6-66:Mediation: Agent 1 finds that the intention from agent 2 is better than its intention .
6-67:This is because, although both agents have voluntary intentions with improvement of 1, agent 2 has received one change advice from agent 4 while agent 1 has not received any .
6-68:Hence agent 1 cancels its intention .
6-69:Agent 2 will keep its intention .
6-70:Agents 7 and 10 keep their intentions since none of their neighbors has an intention .
6-71:The rest of the agents do nothing in this step as they do not have any intention .
6-72:Step 5 Execution: Agent 2 changes its color to White .
6-73:Agents 7 and 10 change their colors to Black .
6-74:The new state after round 1 is shown in Figure 7 .
6-75:Round 2: Step 1 Percept: The agents obtain the current color assignments of their neighbors .
6-76:Step 2 Belief: Agent 3 is the only agent who has a positive improvement which is 1 .
6-77:It believes it should change its The Sixth Intl .
6-78:Joint Conf .
6-79:on Autonomous Agents and Multi Agent Systems (AAMAS 07) 529 1 2 3 4 5 6 7 8 9 10 Figure 7: The graph after round 1 color to Black .
6-80:Agent 2 does not have any positive improvement .
6-81:The rest of the agents need not make any change as all their relevant constraints are satisfied .
6-82:They will have no desire, and hence no intention .
6-83:Step 3 Desire: Agent 3 desires to change its color to Black voluntarily, hence it sends out a voluntary advice to its neighbor, i.e., agent 2 .
6-84:Agent 2 does not have any value for its reluctant desire set as the only option, Black color, will bring agent 2 and its neighbors to the previous state which is known to be a bad state .
6-85:Since agent 2 is sharing the constraint violation with agent 3, it sends a change advice to agent 3 .
6-86:Step 4 Intention: Agent 3 will have a voluntary intention while agent 2 will not have any intention as it receives the voluntary advice from agent 3 .
6-87:Mediation: Agent 3 will keep its intention as its only neighbor, agent 2, does not have any intention .
6-88:Step 5 Execution: Agent 3 changes its color to Black .
6-89:The new state after round 2 is shown in Figure 8 .
6-90:Round 3: In this round, every agent finds that it has no desire and hence no intention to revise its variable assignment .
6-91:Following, with no more negotiation message communication in the environment, the observer will inform all the agents that a solution has been found .
6-92:2 3 4 5 6 7 8 91 10 Figure 8: The solution obtained 5.2 Performance Evaluation To facilitate credible comparisons with existing strategies, we measured the execution time in terms of computational cycles as defined in [4], and built a simulator that could reproduce the published results for ABT and AWC .
6-93:The definition of a computational cycle is as follows .
6-94:• In one cycle, each agent receives all the incoming messages, performs local computation and sends out a reply .
6-95:• A message which is sent at time t will be received at time t + 1 .
6-96:The network delay is neglected .
6-97:• Each agent has it own clock .
6-98:The initial clock"s value is outgoing message and use the time stamp in the incoming message to update their own clock"s value .
6-99:Four benchmark problems [6] were considered, namely, n queens and node coloring for sparse, dense and critical graphs .
6-100:For each problem, a finite number of test cases were generated for various problem sizes n .
6-101:The maximum execution time was set to 0 200 400 600 800 1000 10 50 100 Number of queens Cycles Asynchronous Backtracking Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 9: Relationship between execution time and problem size 10000 cycles for node coloring for critical graphs and 1000 cycles for other problems .
6-102:The simulator program was terminated after this period and the algorithm was considered to fail a test case if it did not find a solution by then .
6-103:In such a case, the execution time for the test was counted as 1000 cycles .
6-104:5.2.1 Evaluation with n queens problem The n queens problem is a traditional problem of constraint satisfaction .
6-105:10 test cases were generated for each problem size n ∈ {10, 50 and 100} .
6-106:Figure 9 shows the execution time for different problem sizes when ABT, AWC and UMA were run .
6-107:5.2.2 Evaluation with graph coloring problem The graph coloring problem can be characterized by three parameters: (i) the number of colors k, the number of nodes agents n and the number of links m .
6-108:Based on the ratio m n, the problem can be classified into three types [3]: (i) sparse (with m n = 2), (ii) critical (with m n = 2.7 or 4.7) and (iii) dense (with m n = (n − 1) 4) .
6-109:For this problem, we did not include ABT in our empirical results as its failure rate was found to be very high .
6-110:This poor performance of ABT was expected since the graph coloring problem is more difficult than the n queens problem, on which ABT already did not perform well (see Figure 9) .
6-111:The sparse and dense (coloring) problem types are relatively easy while the critical type is difficult to solve .
6-112:In the experiments, we fix k = 3 .
6-113:10 test cases were created using the method described in [13] for each value of n ∈ {60, 90, 120}, for each problem type .
6-114:The simulation results for each type of problem are shown in Figures 10 12 .
6-115:0 40 80 120 160 200 60 90 120 150 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 10: Comparison between AWC and UMA (sparse graph coloring) 5.3 Discussion 5.3.1 Comparison with ABT and AWC 530 The Sixth Intl .
6-116:Joint Conf .
6-117:on Autonomous Agents and Multi Agent Systems (AAMAS 07) 0 1000 2000 3000 4000 5000 6000 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 11: Comparison between AWC and UMA (critical graph coloring) 0 10 20 30 40 50 60 90 120 Number of Nodes Cycles Asynchronous Weak Commitment Unsolicited Mutual Advice Figure 12: Comparison between AWC and UMA (dense graph coloring) Figure 10 shows that the average performance of UMA is slightly better than AWC for the sparse problem .
6-118:UMA outperforms AWC in solving the critical problem as shown in Figure 11 .
6-119:It was observed that the latter strategy failed in some test cases .
6-120:However, as seen in Figure 12, both the strategies are very efficient when solving the dense problem, with AWC showing slightly better performance .
6-121:The performance of UMA, in the worst (time complexity) case, is similar to that of all evaluated strategies .
6-122:The worst case occurs when all the possible global states of the search are reached .
6-123:Since only a few agents have the right to change their variable assignments in a negotiation round, the number of redundant computational cycles and info messages is reduced .
6-124:As we observe from the backtracking in ABT and AWC, the difference in the ordering of incoming messages can result in a different number of computational cycles to be executed by the agents .
6-125:5.3.2 Comparison with DBO The computational performance of UMA is arguably better than DBO for the following reasons: • UMA can guarantee that there will be a variable reassignment following every negotiation round whereas DBO cannot .
6-126:• UMA introduces one more communication round trip (that of sending a message and awaiting a reply) than DBO, which occurs due to the need to communicate unsolicited advices .
6-127:Although this increases the communication cost per negotiation round, we observed from our simulations that the overall communication cost incurred by UMA is lower due to the significantly lower number of negotiation rounds .
6-128:• Using UMA, in the worst case, an agent will only take 2 or 3 communication round trips per negotiation round, following which the agent or its neighbor will do a variable assignment update .
6-129:Using DBO, this number of round trips is uncertain as each agent might have to increase the weights of the violated constraints until an agent has a positive improvement; this could result in a infinite loop [3]. .
7-1:Applying automated negotiation to DCSP, this paper has proposed a protocol that prescribes the generic reasoning of a DCSP agent in a BDI architecture
7-2:Our work shows that several wellknown DCSP algorithms, namely ABT, AWC and DBO, can be described as mechanisms sharing the same proposed protocol, and only differ in the strategies employed for the reasoning steps per negotiation round as governed by the protocol
7-3:Importantly, this means that it might furnish a unified framework for DCSP that not only provides a clearer BDI agent theoretic view of existing DCSP approaches, but also opens up the opportunities to enhance or develop new strategies
7-4:Towards the latter, we have proposed and formulated a new strategy  the UMA strategy
7-5:Empirical results and our discussion suggest that UMA is superior to ABT, AWC and DBO in some specific aspects
7-6:It was observed from our simulations that UMA possesses the completeness property
7-7:Future work will attempt to formally establish this property, as well as formalize other existing DSCP algorithms as BDI negotiation mechanisms, including the recent endeavor that employs a group mediator [5]
7-8:The idea of DCSP agents using different strategies in the same environment will also be investigated.
8-1:P
8-2:J
8-3:Modi, H
8-4:Jung, M
8-5:Tambe, W. M
8-6:Shen, and S
8-7:Kulkarni, Dynamic distributed resource allocation: A distributed constraint satisfaction approach, in Lecture Notes in Computer Science, 2001, p
8-8:264
8-9:H
8-10:Schlenker and U
8-11:Geske, Simulating large railway networks using distributed constraint satisfaction, in 2nd IEEE International Conference on Industrial Informatics (INDIN 04), 2004, pp
8-12:441 446
8-13:M
8-14:Yokoo, Distributed Constraint Satisfaction : Foundations of Cooperation in Multi Agent Systems
8-15:Springer Verlag, 2000, springer Series on Agent Technology
8-16:M
8-17:Yokoo, E
8-18:H
8-19:Durfee, T
8-20:Ishida, and K
8-21:Kuwabara, The distributed constraint satisfaction problem : Formalization and algorithms, IEEE Transactions on Knowledge and Data Engineering, vol
8-22:10, no
8-23:5, pp
8-24:673 685, September October 1998
8-25:R
8-26:Mailler and V
8-27:Lesser, Using cooperative mediation to solve distributed constraint satisfaction problems, in Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS 04), 2004, pp
8-28:446 453
8-29:E
8-30:Tsang, Foundation of Constraint Satisfaction
8-31:Academic Press, 1993
8-32:R
8-33:Mailler, R
8-34:Vincent, V
8-35:Lesser, T
8-36:Middlekoop, and J
8-37:Shen, Soft Real Time, Cooperative Negotiation for Distributed Resource Allocation, AAAI Fall Symposium on Negotiation Methods for Autonomous Cooperative Systems, November 2001
8-38:M
8-39:Yokoo, K
8-40:Suzuki, and K
8-41:Hirayama, Secure distributed constraint satisfaction: Reaching agreement without revealing private information, Artificial Intelligence, vol
8-42:161, no
8-43:1 2, pp
8-44:229 246, 2005
8-45:J
8-46:S
8-47:Rosenschein and G
8-48:Zlotkin, Rules of Encounter
8-49:The MIT Press, 1994
8-50:M
8-51:Yokoo and K
8-52:Hirayama, Distributed constraint satisfaction algorithm for complex local problems, in Proceedings of the Third International Conference on Multiagent Systems (ICMAS 98), 1998, pp
8-53:372 379
8-54:M
8-55:E
8-56:Bratman, Intentions, Plans and Practical Reason
8-57:Harvard University Press, Cambridge, M.A, 1987
8-58:G
8-59:Weiss, Ed., Multiagent System : A Modern Approach to Distributed Artificial Intelligence
8-60:The MIT Press, London, U.K, 1999
8-61:S
8-62:Minton, M
8-63:D
8-64:Johnson, A
8-65:B
8-66:Philips, and P
8-67:Laird, Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems, Artificial Intelligence, vol
8-68:e58, no
8-69:1 3, pp
8-70:161 205, 1992
8-71:The Sixth Intl
8-72:Joint Conf
8-73:on Autonomous Agents and Multi Agent Systems (AAMAS 07) 531
picture:
