2.1 The General Setting A principal employs a set of agents N of size n .
Each agent i ? N has a possible set of actions Ai, and a cost (effort) ci(ai) ? 0 for each possible action ai ? Ai (ci 
The actions of all players determine, in a probabilistic way, a contractible outcome o ? O, according to a success function t 
.
.
¡Ñ An ¡÷ £G(O) (where £G(O) denotes the set of probability distributions on O) .
A technology is a pair, (t, c), of a success function, t, and cost functions, c = (c1, c2, .
.
.
, cn) .
The principal has a certain value for each possible outcome, given by the function v 
As we will only consider risk neutral players in this paper5 , we will also treat v as a function on £G(O), by taking simple expected value .
Actions of the players are invisible, but the final outcome o is visible to him and to others (in particular the court), and he may design enforceable contracts based on the final outcome .
Thus the contract for agent i is a function (payment) pi 
Given this setting, the agents have been put in a game, where the utility of agent i under the vector of actions a = (a1, .
.
.
, an) is given by ui(a) = pi(t(a))?ci(ai) .
The agents will be assumed to reach Nash equilibrium, if such equilibrium exists .
The principal"s problem (which is our problem in this paper) is how to design the contracts pi as to maximize his own expected utility u(a) = v(t(a)) ? P i pi(t(a)), where the actions a1, .
.
.
, an are at Nash equilibrium .
In the case of multiple Nash equilibria we let the principal choose the equilibrium, thus focusing on the best Nash equilibrium .
A variant, which is similar in spirit to strong implementation in mechanism design would be to take the worst Nash equilibrium, or even, stronger yet, to require that only a single equilibrium exists .
Finally, the social welfare for a ? A is u(a) + P i?N ui(a) = v(t(a)) ? P i?N ci(ai) .
2.2 The Binary Outcome Binary Action Model We wish to concentrate on the complexities introduced by the combinatorial structure of the success function t, we restrict ourselves to a simpler setting that seems to focus more clearly on the structure of t .
A similar model was used in [12] .
We first restrict the action spaces to have only two states (binary action)
The cost function of agent i is now just a scalar ci > 0 denoting the cost of exerting high effort (where the low effort has cost 0) .
The vector of costs is c = (c1, c2, .
.
.
, cn), 5 The risk averse case would obviously be a natural second step in the research of this model, as has been for noncombinatorial scenarios .
20 and we use the notation (t, c) to denote a technology in such a binary outcome model .
We then restrict the outcome space to have only two states (binary outcome)
The principal"s value for a successful project is given by a scalar v > 0 (where the value of project failure is 0) .
We assume that the principal can pay the agents but not fine them (known as the limited liability constraint) .
The contract to agent i is thus now given by a scalar value pi ? 0 that denotes the payment that i gets in case of project success .
If the project fails, the agent gets 0 .
When the lowest cost action has zero cost (as we assume), this immediately implies that the participation constraint holds .
At this point the success function t becomes a function t 
.
.
, an) denotes the probability of project success where players with ai = 0 do not exert effort and incur no cost, and players with ai = 1 do exert effort and incur a cost of ci .
As we wish to concentrate on motivating agents, rather than on the coordination between agents, we assume that more effort by an agent always leads to a better probability of success, i.e .
that the success function t is strictly monotone .
Formally, if we denote by a?i ? A?i the (n ? 1)dimensional vector of the actions of all agents excluding agent i .
i.e., a?i = (a1, .
.
.
, ai?1, ai+1, .
.
.
, an), then a success function must satisfy
.
.
, 0) > 0) .
Definition 1 .
The marginal contribution of agent i, denoted by £Gi, is the difference between the probability of success when i exerts effort and when he shirks .
£Gi(a?i) = t(1, a?i) ? t(0, a?i) Note that since t is monotone, £Gi is a strictly positive function .
At this point we can already make some simple observations .
The best action, ai ? Ai, of agent i can now be easily determined as a function of what the others do, a?i ? A?i, and his contract pi .
Claim 1 .
Given a profile of actions a?i, agent i"s best strategy is ai = 1 if pi ? ci £Gi(a?i) , and is ai = 0 if pi ? ci £Gi(a?i) .
(In the case of equality the agent is indifferent between the two alternatives.) As pi ? ci £Gi(a?i) if and only if ui(1, a?i) = pi ¡Pt(1, a?i)?ci ? pi ¡Pt(0, a?i) = ui(0, a?i), i"s best strategy is to choose ai = 1 in this case .
This allows us to specify the contracts that are the principal"s optimal, for inducing a given equilibrium .
Observation 1 .
The best contracts (for the principal) that induce a ? A as an equilibrium are pi = 0 for agent i who exerts no effort (ai = 0), and pi = ci £Gi(a?i) for agent i who exerts effort (ai = 1) .
In this case, the expected utility of agent i who exerts effort is ci ¡P t(1,a?i) £Gi(a?i) ? 1 , and 0 for an agent who shirk .
The principal"s expected utility is given by u(a, v) = (v?P)¡Pt(a), where P is the total payment in case of success, given by P = P i|ai=1 ci £Gi(a?i) .
We say that the principal contracts with agent i if pi > 0 (and ai = 1 in the equilibrium a ? A) .
The principal"s goal is to maximize his utility given his value v, i.e .
to determine the profile of actions a? ? A, which gives the highest value of u(a, v) in equilibrium .
Choosing a ? A corresponds to choosing a set S of agents that exert effort (S = {i|ai = 1}) .
We call the set of agents S? that the principal contracts with in a? (S? = {i|a? i = 1}) an optimal contract for the principal at value v .
We sometimes abuse notation and denote t(S) instead of t(a), when S is exactly the set of agents that exert effort in a ? A .
A natural yardstick by which to measure this decision is the non strategic case, i.e .
when the agents need not be motivated but are rather controlled directly by the principal (who also bears their costs) .
In this case the principal will simply choose the profile a ? A that optimizes the social welfare (global efficiency), t(a) ¡P v ? P i|ai=1 ci .
The worst ratio between the social welfare in this non strategic case and the social welfare for the profile a ? A chosen by the principal in the agency case, may be termed the price of unaccountability .
Given a technology (t, c), let S? (v) denote the optimal contract in the agency case and let S? ns(v) denote an optimal contract in the non strategic case, when the principal"s value is v .
The social welfare for value v when the set S of agents is contracted is t(S) ¡P v ? P i?S ci (in both the agency and non strategic cases) .
Definition 2 .
The price of unaccountability POU(t, c) of a technology (t, c) is defined as the worst ratio (over v) between the total social welfare in the non strategic case and the agency case
When the technology (t, c) is clear in the context we will use POU to denote the price of unaccountability for technology (t, c) .
Note that the POU is at least 1 for any technology .
As we would like to focus on results that derived from properties of the success function, in most of the paper we will deal with the case where all agents have an identical cost c, that is ci = c for all i ? N .
We denote a technology (t, c) with identical costs by (t, c) .
For the simplicity of the presentation, we sometimes use the term technology function to refer to the success function of the technology .
2.3 Structured Technology Functions In order to be more concrete, we will especially focus on technology functions whose structure can be described easily as being derived from independent agent tasks we call these structured technology functions .
This subclass will first give us some natural examples of technology function, and will also provide a succinct and natural way to represent the technology functions .
In a structured technology function, each individual succeeds or fails in his own task independently .
The project"s success or failure depends, possibly in a complex way, on the set of successful sub tasks .
Thus we will assume a monotone Boolean function f 
Additionally there are constants 0 < £^i < £_i < 1, where £^i denotes the probability of success for agent i if he does not exert effort, and £_i (> £^i) denotes the probability of success if he does exert effort .
In order to reduce the number of parameters, we will restrict our attention to the case where £^1 = .
.
.
= £^n = £^ and £_1 = .
.
.
= £_n = 1 ? £^ thus leaving ourselves with a single parameter £^ s.t .
0 < £^ < 1 2 .
Under this structure, the technology function t is defined by t(a1, .
.
.
, an) being the probability that f(x1, .
.
.
, xn) = 1 where the bits x1, .
.
.
, xn are chosen according to the following distribution
if ai = 1, then xi = 1 with probability 1 ? £^ and xi = 0 with probability £^ .
We denote x = (x1, .
.
.
, xn) .
The question of the representation of the technology function is now reduced to that of representing the underlying monotone Boolean function f .
In the most general case, the function f can be given by a general monotone Boolean circuit .
An especially natural sub class of functions in the structured technologies setting would be functions that can be represented as a read once network a graph with a given source and sink, where every edge is labeled by a different player .
The project succeeds if the edges that belong to player"s whose task succeeded form a path between the source and the sink6 .
A few simple examples should be in order here
Thus the project succeeds only if all agents succeed in their tasks .
This is shown graphically as a read once network in Figure 1(a) .
If m agents exert effort ( P i ai = m), then t(a) = tm = £^n?m (1 ? £^)m .
E.g .
for two players, the technology function t(a1a2) = ta1+a2 is given by t0 = t(00) = £^2 , t1 = t(01) = t(10) = £^(1 ? £^), and t2 = t(11) = (1 ? £^)2 .
disjunction of xi (f(x) = W i?N xi) .
Thus the project succeeds if at least one of the agents succeed in their tasks .
This is shown graphically as a read once network in Figure 1(b) .
If m agents exert effort, then tm = 1 ? £^m (1 ? £^)n?m .E.g .
for two players, the technology function is given by t(00) = 1 ? (1 ? £^)2 , t(01) = t(10) = 1 ? £^(1 ? £^), and t(11) = 1 ? £^2 .
logical disjunction of conjunctions .
In the simplest case of equal length clauses (denote by nc the number of clauses and by nl their length), f(x) = Wnc j=1( Vnl k=1 xj k) .
Thus the project succeeds if in at least one clause all agents succeed in their tasks .
This is shown graphically as a read once network in Figure 2(a) .
If mi agents on path i exert effort, then t(m1, ..., mnc ) = 1 ? Q i(1 ? £^nl?mi (1 ? £^)mi TECHNOLOGIES A success function t is called anonymous if it is symmetric with respect to the players .
I.e .
t(a1, .
.
.
, an) depends only on P i?N ai (the number of agents that exert effort) .
A technology (t, c) is anonymous if t is anonymous and the cost c is identical to all agents .
Of the examples presented above, the AND, OR, and majority technologies were anonymous (but not AOO and OOA) .
As for an anonymous t only the number of agents that exert effort is important, we can shorten the notations and denote tm = t(1m , 0n?m ), £Gm = tm+1 ? tm, pm = c £Gm?1 and um = tm ¡P (v ? m ¡P pm), for the case of identical cost c .
22 v 3 0 gamma 200 150 0.4 100 50 0.3 0 0.20.10 2 1 0 3 12000 6000 8000 4000 2000 gamma 0 0.4 0.45 10000 0.3 0.350.250.2 Figure 3
AND technology
OR technology
3.1 AND and OR Technologies Let us start with a direct and full analysis of the AND and OR technologies for two players for the case £^ = 1 4 and c = 1 .
Example 1 .
AND technology with two agents, c = 1, £^ = 1 4
The principal has 3 possibilities
Let us write down the expressions for his utility in these 3 cases
? 1 Agent
? 2 Agents
Notice that the option of contracting with one agent is always inferior to either contracting with both or with none, and will never be taken by the principal .
The principal will contract with no agent when v < 6, with both agents whenever v > 6, and with either non or both for v = 6 .
This should be contrasted with the non strategic case in which the principal completely controls the agents (and bears their costs) and thus simply optimizes globally .
In this case the principal will make both agents exert effort whenever v ? (non strategic case) would give a global utility of 6 ¡P 9 16 ? 2 = 11 8 while the principal"s decision (in the agency case) would give a global utility of 3 8, giving a ratio of 11 3 .
It turns out that this is the worst price of unaccountability in this example, and it is obtained exactly at the transition point of the agency case, as we show below .
Example 2 .
OR technology with two agents, c = 1, £^ = 1 4
Let us write down the expressions for the principal"s utility in these three cases
? 1 Agent
? 2 Agents
Now contracting with one agent is better than contracting with none whenever v > 52 9 (and is equivalent for v = 52 9), and contracting with both agents is better than contracting with one agent whenever v > 128 3 (and is equivalent for v = 128 3), thus the principal will contract with no agent for 0 ? v ? 52 9, with one agent for 52 9 ? v ? 128 3, and with both agents for v ? 128 3 .
In the non strategic case, in comparison, the principal will make a single agent exert effort for v > 8 3, and the second one exert effort as well when v > 8 .
It turns out that the price of unaccountability here is 19 13, and is achieved at v = 52 9, which is exactly the transition point from 0 to 1 contracted agents in the agency case .
This is not a coincidence that in both the AND and OR technologies the POU is obtained for v that is a transition point (see full proof in [2]) .
Lemma 1 .
For any given technology (t, c) the price of unaccountability POU(t, c) is obtained at some value v which is a transition point, of either the agency or the non strategic cases .
Proof sketch
For any value lower than the first transition point, 0 agents are contracted in both cases, and the social welfare ratio is 1 .
Similarly, for any value higher than the last transition point, n agents are contracted in both cases, and the social welfare ratio is 1 .
Thus, we can focus on the interval between the first and last transition points .
Between any pair of consecutive points, the social welfare ratio is between two linear functions of v (the optimal contracts are fixed on such a segment) .
We then show that for each segment, the suprimum ratio is obtained at an end point of the segment (a transition point) .
As there are finitely many such points, the global suprimum is obtained at the transition point with the maximal social welfare ratio .
2 We already see a qualitative difference between the AND and OR technologies (even with 2 agents)
Figure 3 shows the same phenomena for AND and OR technologies with 3 players .
Theorem 1 .
For any anonymous AND technology7 
7 AND technology with any number of agents n and any £^, and any identical cost c .
8 v? is a function of n, £^, c .
23 ? the price of unaccountability is obtained at the transition point of the agency case, and is POU = ` 1 £^ ? 1 ?n?1 + (1 ? £^ 1 ? £^ ) Proof sketch
Thus, the optimal contract corresponds to the maximum over a set of linear functions .
Let v? denote the point at which the principal is indifferent between contracting with 0 or n agents .
In [2] we show that at v?, the principal"s utility from contracting with 0 (or n) agents is higher than his utility when contracting with any number of agents k ? {1, .
.
.
, n ? 1} .
As the number of contracted agents is monotonic non decreasing in the value (due to Lemma 3), for any v < v?, contracting with 0 agents is optimal, and for any v > v?, contracting with n agents is optimal .
This is true for both the agency and the non strategic cases .
As in both cases there is a single transition point, the claim about the price of unaccountability for AND technology is proved as a special case of Lemma 2 below .
For AND technology tn?1 t0 = (1?£^)n?1 ¡P£^ £^n = 1 £^ ? 1 n?1 and tn?1 tn = (1?£^)n?1 ¡P£^ (1?£^)n = £^ 1?£^ , and the expressions for the POU follows .
2 In [2] we present a general characterization of technologies with a single transition in the agency and the non strategic cases, and provide a full proof of Theorem 1 as a special case .
The property of a single transition occurs in both the agency and the non strategic cases, where the transition occurs at a smaller value of v in the non strategic case .
Notice that the POU is not bounded across the AND family of technologies (for various n, £^) as POU ¡÷ ¡Û either if £^ ¡÷ 0 (for any given n ? 2) or n ¡÷ ¡Û (for any fixed £^ ? (0, 1 2 )) .
Next we consider the OR technology and show that it exhibits all n transitions .
Theorem 2 .
For any anonymous OR technology, there exist finite positive values v1 < v2 < .
.
.
< vn such that for any v s.t .
vk < v < vk+1, contracting with exactly k agents is optimal (for v < v1, no agent is contracted, and for v > vn, all n agents are contracted) .
For v = vk, the principal is indifferent between contracting with k ? 1 or k agents .
Proof sketch
We then show that for any k, vk < vk+1 .
As the number of contracted agents is monotonic non decreasing in the value (due to Lemma 3), v1 < v2 < .
.
.
< vn is a sufficient condition for the theorem to hold .
2 The same behavior occurs in both the agency and the nonstrategic case .
This characterization is a direct corollary of a more general characterization given in [2] .
While in the AND technology we were able to fully determine the POU analytically, the OR technology is more difficult to analyze .
Open Question 1 .
What is the POU for OR with n > 2 agents? Is it bounded by a constant for every n? We are only able to determine the POU of the OR technology for the case of two agents [2] .
Even for the 2 agents case we already observe a qualitative difference between the POU in the AND and OR technologies .
Observation 2 .
While in the AND technology the POU for n = 2 is not bounded from above (for £^ ¡÷ 0), the highest POU in OR technology with two agents is 2 (for £^ ¡÷ 0) .
3.2 What Determines the Transitions? Theorems 1 and 2 say that both the AND and OR technologies exhibit the same transition behavior (changes of the optimal contract) in the agency and the non strategic cases .
However, this is not true in general .
In [2] we provide a full characterization of the sufficient and necessary conditions for general anonymous technologies to have a single transition and all n transitions .
We find that the conditions in the agency case are different than the ones in the non strategic case .
We are able to determine the POU for any anonymous technology that exhibits a single transition in both the agency and the non strategic cases (see full proof in [2]) .
Lemma 2 .
For any anonymous technology that has a single transition in both the agency and the non strategic cases, the POU is given by
Proof sketch
Thus, there exists a region in which the optimal numbers of contracted agents in the agency and the non strategic cases are 0 and n, respectively .
By Lemma 1 the POU is obtained at a transition point .
As the social welfare ratio is decreasing in v in this region, the POU is obtained at the higher value, that is, at the transition point of the agency case .
The transition point in the agency case is the point at which the principal is indifferent between contracting with 0 and with n agents, v? = c¡Pn tn?t0 ¡P tn tn?tn?1 .
Substituting the transition point of the agency case into the POU expression yields the required expression .
POU = v? ¡P tn ? c ¡P n v? ¡P t0 = 1 + tn?1 t0 ? tn?1 tn 2 3.3 The MAJORITY Technology The project under the MAJORITY function succeeds if the majority of the agents succeed in their tasks (see Section 2.3) .
We are unable to characterize the transition behavior of the MAJORITY technology analytically .
Figure 4 presents the optimal number of contracted agents as a function of v and £^, for n = 5 .
The phenomena that we observe in this example (and others that we looked at) leads us to the following conjecture .
Conjecture 1 .
For any Majority technology (any n, £^ and c), there exists l, 1 ? l ? n 2 such that the first transition is from 0 to l agents, and then all the remaining n ? l transitions exist .
24 4 5 3 1 0 2 400 0 0.3 100 gamma 0.2 300 0.450.25 200 v 500 0.35 0.4 Figure 4
As £^ decreases the first transition is at a lower value and to a higher number of agents .
For any sufficiently small £^, the first transition is to 3 = 5 2 agents, and for any sufficiently large £^, the first transition is to 1 agents .
For any £^, the first transition is never to more than 3 agents, and after the first transition we see all following possible transitions .
Moreover, for any fixed c, n, l = 1 when £^ is close enough to 1 2 , l is a non decreasing function of £^ (with image {1, .
.
.
, n 2 }), and l = n 2 when £^ is close enough to 0. .
