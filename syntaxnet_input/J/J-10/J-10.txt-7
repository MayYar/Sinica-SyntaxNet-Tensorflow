CONCLUSION The goal of this paper is to explore the factors that drive a user to submit a particular rating, rather than the incentives that encouraged him to submit a report in the first place
For that we use two additional sources of information besides the vector of numerical ratings
Using simple natural language processing algorithms, we were able to establish a correlation between the weight of a certain feature in the textual comment accompanying the review, and the noise present in the numerical rating
Specifically, it seems that users who discuss amply a certain feature are likely to agree on a common rating
This observation allows the construction of feature by feature estimators of quality that have a lower variance, and are hopefully less noisy
Nevertheless, further evidence is required to support the intuition that ratings corresponding to high weights are expert opinions that deserve to be given higher priority when computing estimates of quality
Second, we emphasize the dependence of ratings on previous reports
Previous reports create an expectation of quality which affects the subjective perception of the user
We validate two facts about the hotel reviews we collected from TripAdvisor
Intuitively, the perception of quality (and consequently the rating) depends on how well the actual experience of the user meets her expectation
Second, we include evidence from the textual comments, and find that when users devote a large fraction of the text to discussing a certain feature, they are likely to motivate a divergent rating (i.e., a rating that does not conform to the prior expectation)
Intuitively, this supports the hypothesis that review forums act as discussion groups where users are keen on presenting and motivating their own opinion
We have captured the empirical evidence in a behavior model that predicts the ratings submitted by the users
The final rating depends, as expected, on the true observation, and on the gap between the observation and the expectation
The gap tends to have a bigger influence when an important fraction of the textual comment is dedicated to discussing a certain feature
The proposed model was validated on the empirical data and provides better estimates of the ratings actually submitted
One assumption that we make is about the existence of an objective quality value vf for the feature f
This is rarely true, especially over large spans of time
Other explanations might account for the correlation of ratings with past reports
For example, if ef (i) reflects the true value of f at a point in time, the difference in the ratings following high and low expectations can be explained by hotel revenue models that are maximized when the value is modified accordingly
However, the idea that variation in ratings is not primarily a function of variation in value turns out to be a useful one
Our approach to approximate this elusive "objective value" is by no means perfect, but conforms neatly to the idea behind the model
A natural direction for future work is to examine concrete applications of our results
Significant improvements of quality estimates are likely to be obtained by incorporating all empirical evidence about rating behavior
Exactly how different factors affect the decisions of the users is not clear
The answer might depend on the particular application, context and culture.
